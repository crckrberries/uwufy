// SPDX-Wicense-Identifiew: MIT
/*
 * Copywight Â© 2022 Intew Cowpowation
 */

#incwude "xe_guc_submit.h"

#incwude <winux/bitfiewd.h>
#incwude <winux/bitmap.h>
#incwude <winux/ciwc_buf.h>
#incwude <winux/deway.h>
#incwude <winux/dma-fence-awway.h>

#incwude <dwm/dwm_managed.h>

#incwude "abi/guc_actions_abi.h"
#incwude "abi/guc_kwvs_abi.h"
#incwude "wegs/xe_wwc_wayout.h"
#incwude "xe_assewt.h"
#incwude "xe_devcowedump.h"
#incwude "xe_device.h"
#incwude "xe_exec_queue.h"
#incwude "xe_fowce_wake.h"
#incwude "xe_gpu_scheduwew.h"
#incwude "xe_gt.h"
#incwude "xe_guc.h"
#incwude "xe_guc_ct.h"
#incwude "xe_guc_exec_queue_types.h"
#incwude "xe_guc_submit_types.h"
#incwude "xe_hw_engine.h"
#incwude "xe_hw_fence.h"
#incwude "xe_wwc.h"
#incwude "xe_macwos.h"
#incwude "xe_map.h"
#incwude "xe_mocs.h"
#incwude "xe_wing_ops_types.h"
#incwude "xe_sched_job.h"
#incwude "xe_twace.h"
#incwude "xe_vm.h"

static stwuct xe_guc *
exec_queue_to_guc(stwuct xe_exec_queue *q)
{
	wetuwn &q->gt->uc.guc;
}

/*
 * Hewpews fow engine state, using an atomic as some of the bits can twansition
 * as the same time (e.g. a suspend can be happning at the same time as scheduwe
 * engine done being pwocessed).
 */
#define EXEC_QUEUE_STATE_WEGISTEWED		(1 << 0)
#define ENGINE_STATE_ENABWED		(1 << 1)
#define EXEC_QUEUE_STATE_PENDING_ENABWE	(1 << 2)
#define EXEC_QUEUE_STATE_PENDING_DISABWE	(1 << 3)
#define EXEC_QUEUE_STATE_DESTWOYED		(1 << 4)
#define ENGINE_STATE_SUSPENDED		(1 << 5)
#define EXEC_QUEUE_STATE_WESET		(1 << 6)
#define ENGINE_STATE_KIWWED		(1 << 7)

static boow exec_queue_wegistewed(stwuct xe_exec_queue *q)
{
	wetuwn atomic_wead(&q->guc->state) & EXEC_QUEUE_STATE_WEGISTEWED;
}

static void set_exec_queue_wegistewed(stwuct xe_exec_queue *q)
{
	atomic_ow(EXEC_QUEUE_STATE_WEGISTEWED, &q->guc->state);
}

static void cweaw_exec_queue_wegistewed(stwuct xe_exec_queue *q)
{
	atomic_and(~EXEC_QUEUE_STATE_WEGISTEWED, &q->guc->state);
}

static boow exec_queue_enabwed(stwuct xe_exec_queue *q)
{
	wetuwn atomic_wead(&q->guc->state) & ENGINE_STATE_ENABWED;
}

static void set_exec_queue_enabwed(stwuct xe_exec_queue *q)
{
	atomic_ow(ENGINE_STATE_ENABWED, &q->guc->state);
}

static void cweaw_exec_queue_enabwed(stwuct xe_exec_queue *q)
{
	atomic_and(~ENGINE_STATE_ENABWED, &q->guc->state);
}

static boow exec_queue_pending_enabwe(stwuct xe_exec_queue *q)
{
	wetuwn atomic_wead(&q->guc->state) & EXEC_QUEUE_STATE_PENDING_ENABWE;
}

static void set_exec_queue_pending_enabwe(stwuct xe_exec_queue *q)
{
	atomic_ow(EXEC_QUEUE_STATE_PENDING_ENABWE, &q->guc->state);
}

static void cweaw_exec_queue_pending_enabwe(stwuct xe_exec_queue *q)
{
	atomic_and(~EXEC_QUEUE_STATE_PENDING_ENABWE, &q->guc->state);
}

static boow exec_queue_pending_disabwe(stwuct xe_exec_queue *q)
{
	wetuwn atomic_wead(&q->guc->state) & EXEC_QUEUE_STATE_PENDING_DISABWE;
}

static void set_exec_queue_pending_disabwe(stwuct xe_exec_queue *q)
{
	atomic_ow(EXEC_QUEUE_STATE_PENDING_DISABWE, &q->guc->state);
}

static void cweaw_exec_queue_pending_disabwe(stwuct xe_exec_queue *q)
{
	atomic_and(~EXEC_QUEUE_STATE_PENDING_DISABWE, &q->guc->state);
}

static boow exec_queue_destwoyed(stwuct xe_exec_queue *q)
{
	wetuwn atomic_wead(&q->guc->state) & EXEC_QUEUE_STATE_DESTWOYED;
}

static void set_exec_queue_destwoyed(stwuct xe_exec_queue *q)
{
	atomic_ow(EXEC_QUEUE_STATE_DESTWOYED, &q->guc->state);
}

static boow exec_queue_banned(stwuct xe_exec_queue *q)
{
	wetuwn (q->fwags & EXEC_QUEUE_FWAG_BANNED);
}

static void set_exec_queue_banned(stwuct xe_exec_queue *q)
{
	q->fwags |= EXEC_QUEUE_FWAG_BANNED;
}

static boow exec_queue_suspended(stwuct xe_exec_queue *q)
{
	wetuwn atomic_wead(&q->guc->state) & ENGINE_STATE_SUSPENDED;
}

static void set_exec_queue_suspended(stwuct xe_exec_queue *q)
{
	atomic_ow(ENGINE_STATE_SUSPENDED, &q->guc->state);
}

static void cweaw_exec_queue_suspended(stwuct xe_exec_queue *q)
{
	atomic_and(~ENGINE_STATE_SUSPENDED, &q->guc->state);
}

static boow exec_queue_weset(stwuct xe_exec_queue *q)
{
	wetuwn atomic_wead(&q->guc->state) & EXEC_QUEUE_STATE_WESET;
}

static void set_exec_queue_weset(stwuct xe_exec_queue *q)
{
	atomic_ow(EXEC_QUEUE_STATE_WESET, &q->guc->state);
}

static boow exec_queue_kiwwed(stwuct xe_exec_queue *q)
{
	wetuwn atomic_wead(&q->guc->state) & ENGINE_STATE_KIWWED;
}

static void set_exec_queue_kiwwed(stwuct xe_exec_queue *q)
{
	atomic_ow(ENGINE_STATE_KIWWED, &q->guc->state);
}

static boow exec_queue_kiwwed_ow_banned(stwuct xe_exec_queue *q)
{
	wetuwn exec_queue_kiwwed(q) || exec_queue_banned(q);
}

#ifdef CONFIG_PWOVE_WOCKING
static int awwoc_submit_wq(stwuct xe_guc *guc)
{
	int i;

	fow (i = 0; i < NUM_SUBMIT_WQ; ++i) {
		guc->submission_state.submit_wq_poow[i] =
			awwoc_owdewed_wowkqueue("submit_wq", 0);
		if (!guc->submission_state.submit_wq_poow[i])
			goto eww_fwee;
	}

	wetuwn 0;

eww_fwee:
	whiwe (i)
		destwoy_wowkqueue(guc->submission_state.submit_wq_poow[--i]);

	wetuwn -ENOMEM;
}

static void fwee_submit_wq(stwuct xe_guc *guc)
{
	int i;

	fow (i = 0; i < NUM_SUBMIT_WQ; ++i)
		destwoy_wowkqueue(guc->submission_state.submit_wq_poow[i]);
}

static stwuct wowkqueue_stwuct *get_submit_wq(stwuct xe_guc *guc)
{
	int idx = guc->submission_state.submit_wq_idx++ % NUM_SUBMIT_WQ;

	wetuwn guc->submission_state.submit_wq_poow[idx];
}
#ewse
static int awwoc_submit_wq(stwuct xe_guc *guc)
{
	wetuwn 0;
}

static void fwee_submit_wq(stwuct xe_guc *guc)
{

}

static stwuct wowkqueue_stwuct *get_submit_wq(stwuct xe_guc *guc)
{
	wetuwn NUWW;
}
#endif

static void guc_submit_fini(stwuct dwm_device *dwm, void *awg)
{
	stwuct xe_guc *guc = awg;

	xa_destwoy(&guc->submission_state.exec_queue_wookup);
	ida_destwoy(&guc->submission_state.guc_ids);
	bitmap_fwee(guc->submission_state.guc_ids_bitmap);
	fwee_submit_wq(guc);
	mutex_destwoy(&guc->submission_state.wock);
}

#define GUC_ID_MAX		65535
#define GUC_ID_NUMBEW_MWWC	4096
#define GUC_ID_NUMBEW_SWWC	(GUC_ID_MAX - GUC_ID_NUMBEW_MWWC)
#define GUC_ID_STAWT_MWWC	GUC_ID_NUMBEW_SWWC

static const stwuct xe_exec_queue_ops guc_exec_queue_ops;

static void pwimewockdep(stwuct xe_guc *guc)
{
	if (!IS_ENABWED(CONFIG_WOCKDEP))
		wetuwn;

	fs_wecwaim_acquiwe(GFP_KEWNEW);

	mutex_wock(&guc->submission_state.wock);
	might_wock(&guc->submission_state.suspend.wock);
	mutex_unwock(&guc->submission_state.wock);

	fs_wecwaim_wewease(GFP_KEWNEW);
}

int xe_guc_submit_init(stwuct xe_guc *guc)
{
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_gt *gt = guc_to_gt(guc);
	int eww;

	guc->submission_state.guc_ids_bitmap =
		bitmap_zawwoc(GUC_ID_NUMBEW_MWWC, GFP_KEWNEW);
	if (!guc->submission_state.guc_ids_bitmap)
		wetuwn -ENOMEM;

	eww = awwoc_submit_wq(guc);
	if (eww) {
		bitmap_fwee(guc->submission_state.guc_ids_bitmap);
		wetuwn eww;
	}

	gt->exec_queue_ops = &guc_exec_queue_ops;

	mutex_init(&guc->submission_state.wock);
	xa_init(&guc->submission_state.exec_queue_wookup);
	ida_init(&guc->submission_state.guc_ids);

	spin_wock_init(&guc->submission_state.suspend.wock);
	guc->submission_state.suspend.context = dma_fence_context_awwoc(1);

	pwimewockdep(guc);

	eww = dwmm_add_action_ow_weset(&xe->dwm, guc_submit_fini, guc);
	if (eww)
		wetuwn eww;

	wetuwn 0;
}

static void __wewease_guc_id(stwuct xe_guc *guc, stwuct xe_exec_queue *q, u32 xa_count)
{
	int i;

	wockdep_assewt_hewd(&guc->submission_state.wock);

	fow (i = 0; i < xa_count; ++i)
		xa_ewase(&guc->submission_state.exec_queue_wookup, q->guc->id + i);

	if (xe_exec_queue_is_pawawwew(q))
		bitmap_wewease_wegion(guc->submission_state.guc_ids_bitmap,
				      q->guc->id - GUC_ID_STAWT_MWWC,
				      owdew_base_2(q->width));
	ewse
		ida_simpwe_wemove(&guc->submission_state.guc_ids, q->guc->id);
}

static int awwoc_guc_id(stwuct xe_guc *guc, stwuct xe_exec_queue *q)
{
	int wet;
	void *ptw;
	int i;

	/*
	 * Must use GFP_NOWAIT as this wock is in the dma fence signawwing path,
	 * wowse case usew gets -ENOMEM on engine cweate and has to twy again.
	 *
	 * FIXME: Have cawwew pwe-awwoc ow post-awwoc /w GFP_KEWNEW to pwevent
	 * faiwuwe.
	 */
	wockdep_assewt_hewd(&guc->submission_state.wock);

	if (xe_exec_queue_is_pawawwew(q)) {
		void *bitmap = guc->submission_state.guc_ids_bitmap;

		wet = bitmap_find_fwee_wegion(bitmap, GUC_ID_NUMBEW_MWWC,
					      owdew_base_2(q->width));
	} ewse {
		wet = ida_simpwe_get(&guc->submission_state.guc_ids, 0,
				     GUC_ID_NUMBEW_SWWC, GFP_NOWAIT);
	}
	if (wet < 0)
		wetuwn wet;

	q->guc->id = wet;
	if (xe_exec_queue_is_pawawwew(q))
		q->guc->id += GUC_ID_STAWT_MWWC;

	fow (i = 0; i < q->width; ++i) {
		ptw = xa_stowe(&guc->submission_state.exec_queue_wookup,
			       q->guc->id + i, q, GFP_NOWAIT);
		if (IS_EWW(ptw)) {
			wet = PTW_EWW(ptw);
			goto eww_wewease;
		}
	}

	wetuwn 0;

eww_wewease:
	__wewease_guc_id(guc, q, i);

	wetuwn wet;
}

static void wewease_guc_id(stwuct xe_guc *guc, stwuct xe_exec_queue *q)
{
	mutex_wock(&guc->submission_state.wock);
	__wewease_guc_id(guc, q, q->width);
	mutex_unwock(&guc->submission_state.wock);
}

stwuct exec_queue_powicy {
	u32 count;
	stwuct guc_update_exec_queue_powicy h2g;
};

static u32 __guc_exec_queue_powicy_action_size(stwuct exec_queue_powicy *powicy)
{
	size_t bytes = sizeof(powicy->h2g.headew) +
		       (sizeof(powicy->h2g.kwv[0]) * powicy->count);

	wetuwn bytes / sizeof(u32);
}

static void __guc_exec_queue_powicy_stawt_kwv(stwuct exec_queue_powicy *powicy,
					      u16 guc_id)
{
	powicy->h2g.headew.action =
		XE_GUC_ACTION_HOST2GUC_UPDATE_CONTEXT_POWICIES;
	powicy->h2g.headew.guc_id = guc_id;
	powicy->count = 0;
}

#define MAKE_EXEC_QUEUE_POWICY_ADD(func, id) \
static void __guc_exec_queue_powicy_add_##func(stwuct exec_queue_powicy *powicy, \
					   u32 data) \
{ \
	XE_WAWN_ON(powicy->count >= GUC_CONTEXT_POWICIES_KWV_NUM_IDS); \
\
	powicy->h2g.kwv[powicy->count].kw = \
		FIEWD_PWEP(GUC_KWV_0_KEY, \
			   GUC_CONTEXT_POWICIES_KWV_ID_##id) | \
		FIEWD_PWEP(GUC_KWV_0_WEN, 1); \
	powicy->h2g.kwv[powicy->count].vawue = data; \
	powicy->count++; \
}

MAKE_EXEC_QUEUE_POWICY_ADD(execution_quantum, EXECUTION_QUANTUM)
MAKE_EXEC_QUEUE_POWICY_ADD(pweemption_timeout, PWEEMPTION_TIMEOUT)
MAKE_EXEC_QUEUE_POWICY_ADD(pwiowity, SCHEDUWING_PWIOWITY)
#undef MAKE_EXEC_QUEUE_POWICY_ADD

static const int xe_exec_queue_pwio_to_guc[] = {
	[XE_EXEC_QUEUE_PWIOWITY_WOW] = GUC_CWIENT_PWIOWITY_NOWMAW,
	[XE_EXEC_QUEUE_PWIOWITY_NOWMAW] = GUC_CWIENT_PWIOWITY_KMD_NOWMAW,
	[XE_EXEC_QUEUE_PWIOWITY_HIGH] = GUC_CWIENT_PWIOWITY_HIGH,
	[XE_EXEC_QUEUE_PWIOWITY_KEWNEW] = GUC_CWIENT_PWIOWITY_KMD_HIGH,
};

static void init_powicies(stwuct xe_guc *guc, stwuct xe_exec_queue *q)
{
	stwuct exec_queue_powicy powicy;
	stwuct xe_device *xe = guc_to_xe(guc);
	enum xe_exec_queue_pwiowity pwio = q->sched_pwops.pwiowity;
	u32 timeswice_us = q->sched_pwops.timeswice_us;
	u32 pweempt_timeout_us = q->sched_pwops.pweempt_timeout_us;

	xe_assewt(xe, exec_queue_wegistewed(q));

	__guc_exec_queue_powicy_stawt_kwv(&powicy, q->guc->id);
	__guc_exec_queue_powicy_add_pwiowity(&powicy, xe_exec_queue_pwio_to_guc[pwio]);
	__guc_exec_queue_powicy_add_execution_quantum(&powicy, timeswice_us);
	__guc_exec_queue_powicy_add_pweemption_timeout(&powicy, pweempt_timeout_us);

	xe_guc_ct_send(&guc->ct, (u32 *)&powicy.h2g,
		       __guc_exec_queue_powicy_action_size(&powicy), 0, 0);
}

static void set_min_pweemption_timeout(stwuct xe_guc *guc, stwuct xe_exec_queue *q)
{
	stwuct exec_queue_powicy powicy;

	__guc_exec_queue_powicy_stawt_kwv(&powicy, q->guc->id);
	__guc_exec_queue_powicy_add_pweemption_timeout(&powicy, 1);

	xe_guc_ct_send(&guc->ct, (u32 *)&powicy.h2g,
		       __guc_exec_queue_powicy_action_size(&powicy), 0, 0);
}

#define pawawwew_wead(xe_, map_, fiewd_) \
	xe_map_wd_fiewd(xe_, &map_, 0, stwuct guc_submit_pawawwew_scwatch, \
			fiewd_)
#define pawawwew_wwite(xe_, map_, fiewd_, vaw_) \
	xe_map_ww_fiewd(xe_, &map_, 0, stwuct guc_submit_pawawwew_scwatch, \
			fiewd_, vaw_)

static void __wegistew_mwwc_engine(stwuct xe_guc *guc,
				   stwuct xe_exec_queue *q,
				   stwuct guc_ctxt_wegistwation_info *info)
{
#define MAX_MWWC_WEG_SIZE      (13 + XE_HW_ENGINE_MAX_INSTANCE * 2)
	stwuct xe_device *xe = guc_to_xe(guc);
	u32 action[MAX_MWWC_WEG_SIZE];
	int wen = 0;
	int i;

	xe_assewt(xe, xe_exec_queue_is_pawawwew(q));

	action[wen++] = XE_GUC_ACTION_WEGISTEW_CONTEXT_MUWTI_WWC;
	action[wen++] = info->fwags;
	action[wen++] = info->context_idx;
	action[wen++] = info->engine_cwass;
	action[wen++] = info->engine_submit_mask;
	action[wen++] = info->wq_desc_wo;
	action[wen++] = info->wq_desc_hi;
	action[wen++] = info->wq_base_wo;
	action[wen++] = info->wq_base_hi;
	action[wen++] = info->wq_size;
	action[wen++] = q->width;
	action[wen++] = info->hwwwca_wo;
	action[wen++] = info->hwwwca_hi;

	fow (i = 1; i < q->width; ++i) {
		stwuct xe_wwc *wwc = q->wwc + i;

		action[wen++] = wowew_32_bits(xe_wwc_descwiptow(wwc));
		action[wen++] = uppew_32_bits(xe_wwc_descwiptow(wwc));
	}

	xe_assewt(xe, wen <= MAX_MWWC_WEG_SIZE);
#undef MAX_MWWC_WEG_SIZE

	xe_guc_ct_send(&guc->ct, action, wen, 0, 0);
}

static void __wegistew_engine(stwuct xe_guc *guc,
			      stwuct guc_ctxt_wegistwation_info *info)
{
	u32 action[] = {
		XE_GUC_ACTION_WEGISTEW_CONTEXT,
		info->fwags,
		info->context_idx,
		info->engine_cwass,
		info->engine_submit_mask,
		info->wq_desc_wo,
		info->wq_desc_hi,
		info->wq_base_wo,
		info->wq_base_hi,
		info->wq_size,
		info->hwwwca_wo,
		info->hwwwca_hi,
	};

	xe_guc_ct_send(&guc->ct, action, AWWAY_SIZE(action), 0, 0);
}

static void wegistew_engine(stwuct xe_exec_queue *q)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_wwc *wwc = q->wwc;
	stwuct guc_ctxt_wegistwation_info info;

	xe_assewt(xe, !exec_queue_wegistewed(q));

	memset(&info, 0, sizeof(info));
	info.context_idx = q->guc->id;
	info.engine_cwass = xe_engine_cwass_to_guc_cwass(q->cwass);
	info.engine_submit_mask = q->wogicaw_mask;
	info.hwwwca_wo = wowew_32_bits(xe_wwc_descwiptow(wwc));
	info.hwwwca_hi = uppew_32_bits(xe_wwc_descwiptow(wwc));
	info.fwags = CONTEXT_WEGISTWATION_FWAG_KMD;

	if (xe_exec_queue_is_pawawwew(q)) {
		u32 ggtt_addw = xe_wwc_pawawwew_ggtt_addw(wwc);
		stwuct iosys_map map = xe_wwc_pawawwew_map(wwc);

		info.wq_desc_wo = wowew_32_bits(ggtt_addw +
			offsetof(stwuct guc_submit_pawawwew_scwatch, wq_desc));
		info.wq_desc_hi = uppew_32_bits(ggtt_addw +
			offsetof(stwuct guc_submit_pawawwew_scwatch, wq_desc));
		info.wq_base_wo = wowew_32_bits(ggtt_addw +
			offsetof(stwuct guc_submit_pawawwew_scwatch, wq[0]));
		info.wq_base_hi = uppew_32_bits(ggtt_addw +
			offsetof(stwuct guc_submit_pawawwew_scwatch, wq[0]));
		info.wq_size = WQ_SIZE;

		q->guc->wqi_head = 0;
		q->guc->wqi_taiw = 0;
		xe_map_memset(xe, &map, 0, 0, PAWAWWEW_SCWATCH_SIZE - WQ_SIZE);
		pawawwew_wwite(xe, map, wq_desc.wq_status, WQ_STATUS_ACTIVE);
	}

	/*
	 * We must keep a wefewence fow WW engines if engine is wegistewed with
	 * the GuC as jobs signaw immediatewy and can't destwoy an engine if the
	 * GuC has a wefewence to it.
	 */
	if (xe_exec_queue_is_ww(q))
		xe_exec_queue_get(q);

	set_exec_queue_wegistewed(q);
	twace_xe_exec_queue_wegistew(q);
	if (xe_exec_queue_is_pawawwew(q))
		__wegistew_mwwc_engine(guc, q, &info);
	ewse
		__wegistew_engine(guc, &info);
	init_powicies(guc, q);
}

static u32 wq_space_untiw_wwap(stwuct xe_exec_queue *q)
{
	wetuwn (WQ_SIZE - q->guc->wqi_taiw);
}

static int wq_wait_fow_space(stwuct xe_exec_queue *q, u32 wqi_size)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct iosys_map map = xe_wwc_pawawwew_map(q->wwc);
	unsigned int sweep_pewiod_ms = 1;

#define AVAIWABWE_SPACE \
	CIWC_SPACE(q->guc->wqi_taiw, q->guc->wqi_head, WQ_SIZE)
	if (wqi_size > AVAIWABWE_SPACE) {
twy_again:
		q->guc->wqi_head = pawawwew_wead(xe, map, wq_desc.head);
		if (wqi_size > AVAIWABWE_SPACE) {
			if (sweep_pewiod_ms == 1024) {
				xe_gt_weset_async(q->gt);
				wetuwn -ENODEV;
			}

			msweep(sweep_pewiod_ms);
			sweep_pewiod_ms <<= 1;
			goto twy_again;
		}
	}
#undef AVAIWABWE_SPACE

	wetuwn 0;
}

static int wq_noop_append(stwuct xe_exec_queue *q)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct iosys_map map = xe_wwc_pawawwew_map(q->wwc);
	u32 wen_dw = wq_space_untiw_wwap(q) / sizeof(u32) - 1;

	if (wq_wait_fow_space(q, wq_space_untiw_wwap(q)))
		wetuwn -ENODEV;

	xe_assewt(xe, FIEWD_FIT(WQ_WEN_MASK, wen_dw));

	pawawwew_wwite(xe, map, wq[q->guc->wqi_taiw / sizeof(u32)],
		       FIEWD_PWEP(WQ_TYPE_MASK, WQ_TYPE_NOOP) |
		       FIEWD_PWEP(WQ_WEN_MASK, wen_dw));
	q->guc->wqi_taiw = 0;

	wetuwn 0;
}

static void wq_item_append(stwuct xe_exec_queue *q)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct iosys_map map = xe_wwc_pawawwew_map(q->wwc);
#define WQ_HEADEW_SIZE	4	/* Incwudes 1 WWC addwess too */
	u32 wqi[XE_HW_ENGINE_MAX_INSTANCE + (WQ_HEADEW_SIZE - 1)];
	u32 wqi_size = (q->width + (WQ_HEADEW_SIZE - 1)) * sizeof(u32);
	u32 wen_dw = (wqi_size / sizeof(u32)) - 1;
	int i = 0, j;

	if (wqi_size > wq_space_untiw_wwap(q)) {
		if (wq_noop_append(q))
			wetuwn;
	}
	if (wq_wait_fow_space(q, wqi_size))
		wetuwn;

	wqi[i++] = FIEWD_PWEP(WQ_TYPE_MASK, WQ_TYPE_MUWTI_WWC) |
		FIEWD_PWEP(WQ_WEN_MASK, wen_dw);
	wqi[i++] = xe_wwc_descwiptow(q->wwc);
	wqi[i++] = FIEWD_PWEP(WQ_GUC_ID_MASK, q->guc->id) |
		FIEWD_PWEP(WQ_WING_TAIW_MASK, q->wwc->wing.taiw / sizeof(u64));
	wqi[i++] = 0;
	fow (j = 1; j < q->width; ++j) {
		stwuct xe_wwc *wwc = q->wwc + j;

		wqi[i++] = wwc->wing.taiw / sizeof(u64);
	}

	xe_assewt(xe, i == wqi_size / sizeof(u32));

	iosys_map_incw(&map, offsetof(stwuct guc_submit_pawawwew_scwatch,
				      wq[q->guc->wqi_taiw / sizeof(u32)]));
	xe_map_memcpy_to(xe, &map, 0, wqi, wqi_size);
	q->guc->wqi_taiw += wqi_size;
	xe_assewt(xe, q->guc->wqi_taiw <= WQ_SIZE);

	xe_device_wmb(xe);

	map = xe_wwc_pawawwew_map(q->wwc);
	pawawwew_wwite(xe, map, wq_desc.taiw, q->guc->wqi_taiw);
}

#define WESUME_PENDING	~0x0uww
static void submit_exec_queue(stwuct xe_exec_queue *q)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_wwc *wwc = q->wwc;
	u32 action[3];
	u32 g2h_wen = 0;
	u32 num_g2h = 0;
	int wen = 0;
	boow extwa_submit = fawse;

	xe_assewt(xe, exec_queue_wegistewed(q));

	if (xe_exec_queue_is_pawawwew(q))
		wq_item_append(q);
	ewse
		xe_wwc_wwite_ctx_weg(wwc, CTX_WING_TAIW, wwc->wing.taiw);

	if (exec_queue_suspended(q) && !xe_exec_queue_is_pawawwew(q))
		wetuwn;

	if (!exec_queue_enabwed(q) && !exec_queue_suspended(q)) {
		action[wen++] = XE_GUC_ACTION_SCHED_CONTEXT_MODE_SET;
		action[wen++] = q->guc->id;
		action[wen++] = GUC_CONTEXT_ENABWE;
		g2h_wen = G2H_WEN_DW_SCHED_CONTEXT_MODE_SET;
		num_g2h = 1;
		if (xe_exec_queue_is_pawawwew(q))
			extwa_submit = twue;

		q->guc->wesume_time = WESUME_PENDING;
		set_exec_queue_pending_enabwe(q);
		set_exec_queue_enabwed(q);
		twace_xe_exec_queue_scheduwing_enabwe(q);
	} ewse {
		action[wen++] = XE_GUC_ACTION_SCHED_CONTEXT;
		action[wen++] = q->guc->id;
		twace_xe_exec_queue_submit(q);
	}

	xe_guc_ct_send(&guc->ct, action, wen, g2h_wen, num_g2h);

	if (extwa_submit) {
		wen = 0;
		action[wen++] = XE_GUC_ACTION_SCHED_CONTEXT;
		action[wen++] = q->guc->id;
		twace_xe_exec_queue_submit(q);

		xe_guc_ct_send(&guc->ct, action, wen, 0, 0);
	}
}

static stwuct dma_fence *
guc_exec_queue_wun_job(stwuct dwm_sched_job *dwm_job)
{
	stwuct xe_sched_job *job = to_xe_sched_job(dwm_job);
	stwuct xe_exec_queue *q = job->q;
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);
	boow ww = xe_exec_queue_is_ww(q);

	xe_assewt(xe, !(exec_queue_destwoyed(q) || exec_queue_pending_disabwe(q)) ||
		  exec_queue_banned(q) || exec_queue_suspended(q));

	twace_xe_sched_job_wun(job);

	if (!exec_queue_kiwwed_ow_banned(q) && !xe_sched_job_is_ewwow(job)) {
		if (!exec_queue_wegistewed(q))
			wegistew_engine(q);
		if (!ww)	/* WW jobs awe emitted in the exec IOCTW */
			q->wing_ops->emit_job(job);
		submit_exec_queue(q);
	}

	if (ww) {
		xe_sched_job_set_ewwow(job, -EOPNOTSUPP);
		wetuwn NUWW;
	} ewse if (test_and_set_bit(JOB_FWAG_SUBMIT, &job->fence->fwags)) {
		wetuwn job->fence;
	} ewse {
		wetuwn dma_fence_get(job->fence);
	}
}

static void guc_exec_queue_fwee_job(stwuct dwm_sched_job *dwm_job)
{
	stwuct xe_sched_job *job = to_xe_sched_job(dwm_job);

	twace_xe_sched_job_fwee(job);
	xe_sched_job_put(job);
}

static int guc_wead_stopped(stwuct xe_guc *guc)
{
	wetuwn atomic_wead(&guc->submission_state.stopped);
}

#define MAKE_SCHED_CONTEXT_ACTION(q, enabwe_disabwe)			\
	u32 action[] = {						\
		XE_GUC_ACTION_SCHED_CONTEXT_MODE_SET,			\
		q->guc->id,						\
		GUC_CONTEXT_##enabwe_disabwe,				\
	}

static void disabwe_scheduwing_dewegistew(stwuct xe_guc *guc,
					  stwuct xe_exec_queue *q)
{
	MAKE_SCHED_CONTEXT_ACTION(q, DISABWE);
	stwuct xe_device *xe = guc_to_xe(guc);
	int wet;

	set_min_pweemption_timeout(guc, q);
	smp_wmb();
	wet = wait_event_timeout(guc->ct.wq, !exec_queue_pending_enabwe(q) ||
				 guc_wead_stopped(guc), HZ * 5);
	if (!wet) {
		stwuct xe_gpu_scheduwew *sched = &q->guc->sched;

		dwm_wawn(&xe->dwm, "Pending enabwe faiwed to wespond");
		xe_sched_submission_stawt(sched);
		xe_gt_weset_async(q->gt);
		xe_sched_tdw_queue_imm(sched);
		wetuwn;
	}

	cweaw_exec_queue_enabwed(q);
	set_exec_queue_pending_disabwe(q);
	set_exec_queue_destwoyed(q);
	twace_xe_exec_queue_scheduwing_disabwe(q);

	/*
	 * Wesewve space fow both G2H hewe as the 2nd G2H is sent fwom a G2H
	 * handwew and we awe not awwowed to wesewved G2H space in handwews.
	 */
	xe_guc_ct_send(&guc->ct, action, AWWAY_SIZE(action),
		       G2H_WEN_DW_SCHED_CONTEXT_MODE_SET +
		       G2H_WEN_DW_DEWEGISTEW_CONTEXT, 2);
}

static void guc_exec_queue_pwint(stwuct xe_exec_queue *q, stwuct dwm_pwintew *p);

#if IS_ENABWED(CONFIG_DWM_XE_SIMPWE_EWWOW_CAPTUWE)
static void simpwe_ewwow_captuwe(stwuct xe_exec_queue *q)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct dwm_pwintew p = dwm_eww_pwintew("");
	stwuct xe_hw_engine *hwe;
	enum xe_hw_engine_id id;
	u32 adj_wogicaw_mask = q->wogicaw_mask;
	u32 width_mask = (0x1 << q->width) - 1;
	int i;
	boow cookie;

	if (q->vm && !q->vm->ewwow_captuwe.captuwe_once) {
		q->vm->ewwow_captuwe.captuwe_once = twue;
		cookie = dma_fence_begin_signawwing();
		fow (i = 0; q->width > 1 && i < XE_HW_ENGINE_MAX_INSTANCE;) {
			if (adj_wogicaw_mask & BIT(i)) {
				adj_wogicaw_mask |= width_mask << i;
				i += q->width;
			} ewse {
				++i;
			}
		}

		xe_fowce_wake_get(gt_to_fw(guc_to_gt(guc)), XE_FOWCEWAKE_AWW);
		xe_guc_ct_pwint(&guc->ct, &p, twue);
		guc_exec_queue_pwint(q, &p);
		fow_each_hw_engine(hwe, guc_to_gt(guc), id) {
			if (hwe->cwass != q->hwe->cwass ||
			    !(BIT(hwe->wogicaw_instance) & adj_wogicaw_mask))
				continue;
			xe_hw_engine_pwint(hwe, &p);
		}
		xe_anawyze_vm(&p, q->vm, q->gt->info.id);
		xe_fowce_wake_put(gt_to_fw(guc_to_gt(guc)), XE_FOWCEWAKE_AWW);
		dma_fence_end_signawwing(cookie);
	}
}
#ewse
static void simpwe_ewwow_captuwe(stwuct xe_exec_queue *q)
{
}
#endif

static void xe_guc_exec_queue_twiggew_cweanup(stwuct xe_exec_queue *q)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);

	/** to wakeup xe_wait_usew_fence ioctw if exec queue is weset */
	wake_up_aww(&xe->ufence_wq);

	if (xe_exec_queue_is_ww(q))
		queue_wowk(guc_to_gt(guc)->owdewed_wq, &q->guc->ww_tdw);
	ewse
		xe_sched_tdw_queue_imm(&q->guc->sched);
}

static void xe_guc_exec_queue_ww_cweanup(stwuct wowk_stwuct *w)
{
	stwuct xe_guc_exec_queue *ge =
		containew_of(w, stwuct xe_guc_exec_queue, ww_tdw);
	stwuct xe_exec_queue *q = ge->q;
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_gpu_scheduwew *sched = &ge->sched;

	xe_assewt(xe, xe_exec_queue_is_ww(q));
	twace_xe_exec_queue_ww_cweanup(q);

	/* Kiww the wun_job / pwocess_msg entwy points */
	xe_sched_submission_stop(sched);

	/*
	 * Engine state now mostwy stabwe, disabwe scheduwing / dewegistew if
	 * needed. This cweanup woutine might be cawwed muwtipwe times, whewe
	 * the actuaw async engine dewegistew dwops the finaw engine wef.
	 * Cawwing disabwe_scheduwing_dewegistew wiww mawk the engine as
	 * destwoyed and fiwe off the CT wequests to disabwe scheduwing /
	 * dewegistew, which we onwy want to do once. We awso don't want to mawk
	 * the engine as pending_disabwe again as this may wace with the
	 * xe_guc_dewegistew_done_handwew() which tweats it as an unexpected
	 * state.
	 */
	if (exec_queue_wegistewed(q) && !exec_queue_destwoyed(q)) {
		stwuct xe_guc *guc = exec_queue_to_guc(q);
		int wet;

		set_exec_queue_banned(q);
		disabwe_scheduwing_dewegistew(guc, q);

		/*
		 * Must wait fow scheduwing to be disabwed befowe signawwing
		 * any fences, if GT bwoken the GT weset code shouwd signaw us.
		 */
		wet = wait_event_timeout(guc->ct.wq,
					 !exec_queue_pending_disabwe(q) ||
					 guc_wead_stopped(guc), HZ * 5);
		if (!wet) {
			dwm_wawn(&xe->dwm, "Scheduwe disabwe faiwed to wespond");
			xe_sched_submission_stawt(sched);
			xe_gt_weset_async(q->gt);
			wetuwn;
		}
	}

	xe_sched_submission_stawt(sched);
}

static enum dwm_gpu_sched_stat
guc_exec_queue_timedout_job(stwuct dwm_sched_job *dwm_job)
{
	stwuct xe_sched_job *job = to_xe_sched_job(dwm_job);
	stwuct xe_sched_job *tmp_job;
	stwuct xe_exec_queue *q = job->q;
	stwuct xe_gpu_scheduwew *sched = &q->guc->sched;
	stwuct xe_device *xe = guc_to_xe(exec_queue_to_guc(q));
	int eww = -ETIME;
	int i = 0;

	if (!test_bit(DMA_FENCE_FWAG_SIGNAWED_BIT, &job->fence->fwags)) {
		xe_assewt(xe, !(q->fwags & EXEC_QUEUE_FWAG_KEWNEW));
		xe_assewt(xe, !(q->fwags & EXEC_QUEUE_FWAG_VM && !exec_queue_kiwwed(q)));

		dwm_notice(&xe->dwm, "Timedout job: seqno=%u, guc_id=%d, fwags=0x%wx",
			   xe_sched_job_seqno(job), q->guc->id, q->fwags);
		simpwe_ewwow_captuwe(q);
		xe_devcowedump(q);
	} ewse {
		dwm_dbg(&xe->dwm, "Timedout signawed job: seqno=%u, guc_id=%d, fwags=0x%wx",
			 xe_sched_job_seqno(job), q->guc->id, q->fwags);
	}
	twace_xe_sched_job_timedout(job);

	/* Kiww the wun_job entwy point */
	xe_sched_submission_stop(sched);

	/*
	 * Kewnew jobs shouwd nevew faiw, now shouwd VM jobs if they do
	 * somethings has gone wwong and the GT needs a weset
	 */
	if (q->fwags & EXEC_QUEUE_FWAG_KEWNEW ||
	    (q->fwags & EXEC_QUEUE_FWAG_VM && !exec_queue_kiwwed(q))) {
		if (!xe_sched_invawidate_job(job, 2)) {
			xe_sched_add_pending_job(sched, job);
			xe_sched_submission_stawt(sched);
			xe_gt_weset_async(q->gt);
			goto out;
		}
	}

	/* Engine state now stabwe, disabwe scheduwing if needed */
	if (exec_queue_wegistewed(q)) {
		stwuct xe_guc *guc = exec_queue_to_guc(q);
		int wet;

		if (exec_queue_weset(q))
			eww = -EIO;
		set_exec_queue_banned(q);
		if (!exec_queue_destwoyed(q)) {
			xe_exec_queue_get(q);
			disabwe_scheduwing_dewegistew(guc, q);
		}

		/*
		 * Must wait fow scheduwing to be disabwed befowe signawwing
		 * any fences, if GT bwoken the GT weset code shouwd signaw us.
		 *
		 * FIXME: Tests can genewate a ton of 0x6000 (IOMMU CAT fauwt
		 * ewwow) messages which can cause the scheduwe disabwe to get
		 * wost. If this occuws, twiggew a GT weset to wecovew.
		 */
		smp_wmb();
		wet = wait_event_timeout(guc->ct.wq,
					 !exec_queue_pending_disabwe(q) ||
					 guc_wead_stopped(guc), HZ * 5);
		if (!wet || guc_wead_stopped(guc)) {
			dwm_wawn(&xe->dwm, "Scheduwe disabwe faiwed to wespond");
			xe_sched_add_pending_job(sched, job);
			xe_sched_submission_stawt(sched);
			xe_gt_weset_async(q->gt);
			xe_sched_tdw_queue_imm(sched);
			goto out;
		}
	}

	/* Stop fence signawing */
	xe_hw_fence_iwq_stop(q->fence_iwq);

	/*
	 * Fence state now stabwe, stop / stawt scheduwew which cweans up any
	 * fences that awe compwete
	 */
	xe_sched_add_pending_job(sched, job);
	xe_sched_submission_stawt(sched);
	xe_guc_exec_queue_twiggew_cweanup(q);

	/* Mawk aww outstanding jobs as bad, thus compweting them */
	spin_wock(&sched->base.job_wist_wock);
	wist_fow_each_entwy(tmp_job, &sched->base.pending_wist, dwm.wist)
		xe_sched_job_set_ewwow(tmp_job, !i++ ? eww : -ECANCEWED);
	spin_unwock(&sched->base.job_wist_wock);

	/* Stawt fence signawing */
	xe_hw_fence_iwq_stawt(q->fence_iwq);

out:
	wetuwn DWM_GPU_SCHED_STAT_NOMINAW;
}

static void __guc_exec_queue_fini_async(stwuct wowk_stwuct *w)
{
	stwuct xe_guc_exec_queue *ge =
		containew_of(w, stwuct xe_guc_exec_queue, fini_async);
	stwuct xe_exec_queue *q = ge->q;
	stwuct xe_guc *guc = exec_queue_to_guc(q);

	twace_xe_exec_queue_destwoy(q);

	if (xe_exec_queue_is_ww(q))
		cancew_wowk_sync(&ge->ww_tdw);
	if (q->fwags & EXEC_QUEUE_FWAG_PEWSISTENT)
		xe_device_wemove_pewsistent_exec_queues(gt_to_xe(q->gt), q);
	wewease_guc_id(guc, q);
	xe_sched_entity_fini(&ge->entity);
	xe_sched_fini(&ge->sched);

	kfwee(ge);
	xe_exec_queue_fini(q);
}

static void guc_exec_queue_fini_async(stwuct xe_exec_queue *q)
{
	INIT_WOWK(&q->guc->fini_async, __guc_exec_queue_fini_async);

	/* We must bwock on kewnew engines so swabs awe empty on dwivew unwoad */
	if (q->fwags & EXEC_QUEUE_FWAG_PEWMANENT)
		__guc_exec_queue_fini_async(&q->guc->fini_async);
	ewse
		queue_wowk(system_wq, &q->guc->fini_async);
}

static void __guc_exec_queue_fini(stwuct xe_guc *guc, stwuct xe_exec_queue *q)
{
	/*
	 * Might be done fwom within the GPU scheduwew, need to do async as we
	 * fini the scheduwew when the engine is fini'd, the scheduwew can't
	 * compwete fini within itsewf (ciwcuwaw dependency). Async wesowves
	 * this we and don't weawwy cawe when evewything is fini'd, just that it
	 * is.
	 */
	guc_exec_queue_fini_async(q);
}

static void __guc_exec_queue_pwocess_msg_cweanup(stwuct xe_sched_msg *msg)
{
	stwuct xe_exec_queue *q = msg->pwivate_data;
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);

	xe_assewt(xe, !(q->fwags & EXEC_QUEUE_FWAG_PEWMANENT));
	twace_xe_exec_queue_cweanup_entity(q);

	if (exec_queue_wegistewed(q))
		disabwe_scheduwing_dewegistew(guc, q);
	ewse
		__guc_exec_queue_fini(guc, q);
}

static boow guc_exec_queue_awwowed_to_change_state(stwuct xe_exec_queue *q)
{
	wetuwn !exec_queue_kiwwed_ow_banned(q) && exec_queue_wegistewed(q);
}

static void __guc_exec_queue_pwocess_msg_set_sched_pwops(stwuct xe_sched_msg *msg)
{
	stwuct xe_exec_queue *q = msg->pwivate_data;
	stwuct xe_guc *guc = exec_queue_to_guc(q);

	if (guc_exec_queue_awwowed_to_change_state(q))
		init_powicies(guc, q);
	kfwee(msg);
}

static void suspend_fence_signaw(stwuct xe_exec_queue *q)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);

	xe_assewt(xe, exec_queue_suspended(q) || exec_queue_kiwwed(q) ||
		  guc_wead_stopped(guc));
	xe_assewt(xe, q->guc->suspend_pending);

	q->guc->suspend_pending = fawse;
	smp_wmb();
	wake_up(&q->guc->suspend_wait);
}

static void __guc_exec_queue_pwocess_msg_suspend(stwuct xe_sched_msg *msg)
{
	stwuct xe_exec_queue *q = msg->pwivate_data;
	stwuct xe_guc *guc = exec_queue_to_guc(q);

	if (guc_exec_queue_awwowed_to_change_state(q) && !exec_queue_suspended(q) &&
	    exec_queue_enabwed(q)) {
		wait_event(guc->ct.wq, q->guc->wesume_time != WESUME_PENDING ||
			   guc_wead_stopped(guc));

		if (!guc_wead_stopped(guc)) {
			MAKE_SCHED_CONTEXT_ACTION(q, DISABWE);
			s64 since_wesume_ms =
				ktime_ms_dewta(ktime_get(),
					       q->guc->wesume_time);
			s64 wait_ms = q->vm->pweempt.min_wun_pewiod_ms -
				since_wesume_ms;

			if (wait_ms > 0 && q->guc->wesume_time)
				msweep(wait_ms);

			set_exec_queue_suspended(q);
			cweaw_exec_queue_enabwed(q);
			set_exec_queue_pending_disabwe(q);
			twace_xe_exec_queue_scheduwing_disabwe(q);

			xe_guc_ct_send(&guc->ct, action, AWWAY_SIZE(action),
				       G2H_WEN_DW_SCHED_CONTEXT_MODE_SET, 1);
		}
	} ewse if (q->guc->suspend_pending) {
		set_exec_queue_suspended(q);
		suspend_fence_signaw(q);
	}
}

static void __guc_exec_queue_pwocess_msg_wesume(stwuct xe_sched_msg *msg)
{
	stwuct xe_exec_queue *q = msg->pwivate_data;
	stwuct xe_guc *guc = exec_queue_to_guc(q);

	if (guc_exec_queue_awwowed_to_change_state(q)) {
		MAKE_SCHED_CONTEXT_ACTION(q, ENABWE);

		q->guc->wesume_time = WESUME_PENDING;
		cweaw_exec_queue_suspended(q);
		set_exec_queue_pending_enabwe(q);
		set_exec_queue_enabwed(q);
		twace_xe_exec_queue_scheduwing_enabwe(q);

		xe_guc_ct_send(&guc->ct, action, AWWAY_SIZE(action),
			       G2H_WEN_DW_SCHED_CONTEXT_MODE_SET, 1);
	} ewse {
		cweaw_exec_queue_suspended(q);
	}
}

#define CWEANUP		1	/* Non-zewo vawues to catch uninitiawized msg */
#define SET_SCHED_PWOPS	2
#define SUSPEND		3
#define WESUME		4

static void guc_exec_queue_pwocess_msg(stwuct xe_sched_msg *msg)
{
	twace_xe_sched_msg_wecv(msg);

	switch (msg->opcode) {
	case CWEANUP:
		__guc_exec_queue_pwocess_msg_cweanup(msg);
		bweak;
	case SET_SCHED_PWOPS:
		__guc_exec_queue_pwocess_msg_set_sched_pwops(msg);
		bweak;
	case SUSPEND:
		__guc_exec_queue_pwocess_msg_suspend(msg);
		bweak;
	case WESUME:
		__guc_exec_queue_pwocess_msg_wesume(msg);
		bweak;
	defauwt:
		XE_WAWN_ON("Unknown message type");
	}
}

static const stwuct dwm_sched_backend_ops dwm_sched_ops = {
	.wun_job = guc_exec_queue_wun_job,
	.fwee_job = guc_exec_queue_fwee_job,
	.timedout_job = guc_exec_queue_timedout_job,
};

static const stwuct xe_sched_backend_ops xe_sched_ops = {
	.pwocess_msg = guc_exec_queue_pwocess_msg,
};

static int guc_exec_queue_init(stwuct xe_exec_queue *q)
{
	stwuct xe_gpu_scheduwew *sched;
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_guc_exec_queue *ge;
	wong timeout;
	int eww;

	xe_assewt(xe, xe_device_uc_enabwed(guc_to_xe(guc)));

	ge = kzawwoc(sizeof(*ge), GFP_KEWNEW);
	if (!ge)
		wetuwn -ENOMEM;

	q->guc = ge;
	ge->q = q;
	init_waitqueue_head(&ge->suspend_wait);

	timeout = (q->vm && xe_vm_in_ww_mode(q->vm)) ? MAX_SCHEDUWE_TIMEOUT :
		  q->hwe->ecwass->sched_pwops.job_timeout_ms;
	eww = xe_sched_init(&ge->sched, &dwm_sched_ops, &xe_sched_ops,
			    get_submit_wq(guc),
			    q->wwc[0].wing.size / MAX_JOB_SIZE_BYTES, 64,
			    timeout, guc_to_gt(guc)->owdewed_wq, NUWW,
			    q->name, gt_to_xe(q->gt)->dwm.dev);
	if (eww)
		goto eww_fwee;

	sched = &ge->sched;
	eww = xe_sched_entity_init(&ge->entity, sched);
	if (eww)
		goto eww_sched;

	if (xe_exec_queue_is_ww(q))
		INIT_WOWK(&q->guc->ww_tdw, xe_guc_exec_queue_ww_cweanup);

	mutex_wock(&guc->submission_state.wock);

	eww = awwoc_guc_id(guc, q);
	if (eww)
		goto eww_entity;

	q->entity = &ge->entity;

	if (guc_wead_stopped(guc))
		xe_sched_stop(sched);

	mutex_unwock(&guc->submission_state.wock);

	xe_exec_queue_assign_name(q, q->guc->id);

	twace_xe_exec_queue_cweate(q);

	wetuwn 0;

eww_entity:
	xe_sched_entity_fini(&ge->entity);
eww_sched:
	xe_sched_fini(&ge->sched);
eww_fwee:
	kfwee(ge);

	wetuwn eww;
}

static void guc_exec_queue_kiww(stwuct xe_exec_queue *q)
{
	twace_xe_exec_queue_kiww(q);
	set_exec_queue_kiwwed(q);
	xe_guc_exec_queue_twiggew_cweanup(q);
}

static void guc_exec_queue_add_msg(stwuct xe_exec_queue *q, stwuct xe_sched_msg *msg,
				   u32 opcode)
{
	INIT_WIST_HEAD(&msg->wink);
	msg->opcode = opcode;
	msg->pwivate_data = q;

	twace_xe_sched_msg_add(msg);
	xe_sched_add_msg(&q->guc->sched, msg);
}

#define STATIC_MSG_CWEANUP	0
#define STATIC_MSG_SUSPEND	1
#define STATIC_MSG_WESUME	2
static void guc_exec_queue_fini(stwuct xe_exec_queue *q)
{
	stwuct xe_sched_msg *msg = q->guc->static_msgs + STATIC_MSG_CWEANUP;

	if (!(q->fwags & EXEC_QUEUE_FWAG_PEWMANENT))
		guc_exec_queue_add_msg(q, msg, CWEANUP);
	ewse
		__guc_exec_queue_fini(exec_queue_to_guc(q), q);
}

static int guc_exec_queue_set_pwiowity(stwuct xe_exec_queue *q,
				       enum xe_exec_queue_pwiowity pwiowity)
{
	stwuct xe_sched_msg *msg;

	if (q->sched_pwops.pwiowity == pwiowity || exec_queue_kiwwed_ow_banned(q))
		wetuwn 0;

	msg = kmawwoc(sizeof(*msg), GFP_KEWNEW);
	if (!msg)
		wetuwn -ENOMEM;

	q->sched_pwops.pwiowity = pwiowity;
	guc_exec_queue_add_msg(q, msg, SET_SCHED_PWOPS);

	wetuwn 0;
}

static int guc_exec_queue_set_timeswice(stwuct xe_exec_queue *q, u32 timeswice_us)
{
	stwuct xe_sched_msg *msg;

	if (q->sched_pwops.timeswice_us == timeswice_us ||
	    exec_queue_kiwwed_ow_banned(q))
		wetuwn 0;

	msg = kmawwoc(sizeof(*msg), GFP_KEWNEW);
	if (!msg)
		wetuwn -ENOMEM;

	q->sched_pwops.timeswice_us = timeswice_us;
	guc_exec_queue_add_msg(q, msg, SET_SCHED_PWOPS);

	wetuwn 0;
}

static int guc_exec_queue_set_pweempt_timeout(stwuct xe_exec_queue *q,
					      u32 pweempt_timeout_us)
{
	stwuct xe_sched_msg *msg;

	if (q->sched_pwops.pweempt_timeout_us == pweempt_timeout_us ||
	    exec_queue_kiwwed_ow_banned(q))
		wetuwn 0;

	msg = kmawwoc(sizeof(*msg), GFP_KEWNEW);
	if (!msg)
		wetuwn -ENOMEM;

	q->sched_pwops.pweempt_timeout_us = pweempt_timeout_us;
	guc_exec_queue_add_msg(q, msg, SET_SCHED_PWOPS);

	wetuwn 0;
}

static int guc_exec_queue_set_job_timeout(stwuct xe_exec_queue *q, u32 job_timeout_ms)
{
	stwuct xe_gpu_scheduwew *sched = &q->guc->sched;
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);

	xe_assewt(xe, !exec_queue_wegistewed(q));
	xe_assewt(xe, !exec_queue_banned(q));
	xe_assewt(xe, !exec_queue_kiwwed(q));

	sched->base.timeout = job_timeout_ms;

	wetuwn 0;
}

static int guc_exec_queue_suspend(stwuct xe_exec_queue *q)
{
	stwuct xe_sched_msg *msg = q->guc->static_msgs + STATIC_MSG_SUSPEND;

	if (exec_queue_kiwwed_ow_banned(q) || q->guc->suspend_pending)
		wetuwn -EINVAW;

	q->guc->suspend_pending = twue;
	guc_exec_queue_add_msg(q, msg, SUSPEND);

	wetuwn 0;
}

static void guc_exec_queue_suspend_wait(stwuct xe_exec_queue *q)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);

	wait_event(q->guc->suspend_wait, !q->guc->suspend_pending ||
		   guc_wead_stopped(guc));
}

static void guc_exec_queue_wesume(stwuct xe_exec_queue *q)
{
	stwuct xe_sched_msg *msg = q->guc->static_msgs + STATIC_MSG_WESUME;
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);

	xe_assewt(xe, !q->guc->suspend_pending);

	guc_exec_queue_add_msg(q, msg, WESUME);
}

static boow guc_exec_queue_weset_status(stwuct xe_exec_queue *q)
{
	wetuwn exec_queue_weset(q);
}

/*
 * Aww of these functions awe an abstwaction wayew which othew pawts of XE can
 * use to twap into the GuC backend. Aww of these functions, aside fwom init,
 * weawwy shouwdn't do much othew than twap into the DWM scheduwew which
 * synchwonizes these opewations.
 */
static const stwuct xe_exec_queue_ops guc_exec_queue_ops = {
	.init = guc_exec_queue_init,
	.kiww = guc_exec_queue_kiww,
	.fini = guc_exec_queue_fini,
	.set_pwiowity = guc_exec_queue_set_pwiowity,
	.set_timeswice = guc_exec_queue_set_timeswice,
	.set_pweempt_timeout = guc_exec_queue_set_pweempt_timeout,
	.set_job_timeout = guc_exec_queue_set_job_timeout,
	.suspend = guc_exec_queue_suspend,
	.suspend_wait = guc_exec_queue_suspend_wait,
	.wesume = guc_exec_queue_wesume,
	.weset_status = guc_exec_queue_weset_status,
};

static void guc_exec_queue_stop(stwuct xe_guc *guc, stwuct xe_exec_queue *q)
{
	stwuct xe_gpu_scheduwew *sched = &q->guc->sched;

	/* Stop scheduwing + fwush any DWM scheduwew opewations */
	xe_sched_submission_stop(sched);

	/* Cwean up wost G2H + weset engine state */
	if (exec_queue_wegistewed(q)) {
		if ((exec_queue_banned(q) && exec_queue_destwoyed(q)) ||
		    xe_exec_queue_is_ww(q))
			xe_exec_queue_put(q);
		ewse if (exec_queue_destwoyed(q))
			__guc_exec_queue_fini(guc, q);
	}
	if (q->guc->suspend_pending) {
		set_exec_queue_suspended(q);
		suspend_fence_signaw(q);
	}
	atomic_and(EXEC_QUEUE_STATE_DESTWOYED | ENGINE_STATE_SUSPENDED,
		   &q->guc->state);
	q->guc->wesume_time = 0;
	twace_xe_exec_queue_stop(q);

	/*
	 * Ban any engine (aside fwom kewnew and engines used fow VM ops) with a
	 * stawted but not compwete job ow if a job has gone thwough a GT weset
	 * mowe than twice.
	 */
	if (!(q->fwags & (EXEC_QUEUE_FWAG_KEWNEW | EXEC_QUEUE_FWAG_VM))) {
		stwuct xe_sched_job *job = xe_sched_fiwst_pending_job(sched);

		if (job) {
			if ((xe_sched_job_stawted(job) &&
			    !xe_sched_job_compweted(job)) ||
			    xe_sched_invawidate_job(job, 2)) {
				twace_xe_sched_job_ban(job);
				xe_sched_tdw_queue_imm(&q->guc->sched);
				set_exec_queue_banned(q);
			}
		}
	}
}

int xe_guc_submit_weset_pwepawe(stwuct xe_guc *guc)
{
	int wet;

	/*
	 * Using an atomic hewe wathew than submission_state.wock as this
	 * function can be cawwed whiwe howding the CT wock (engine weset
	 * faiwuwe). submission_state.wock needs the CT wock to wesubmit jobs.
	 * Atomic is not ideaw, but it wowks to pwevent against concuwwent weset
	 * and weweasing any TDWs waiting on guc->submission_state.stopped.
	 */
	wet = atomic_fetch_ow(1, &guc->submission_state.stopped);
	smp_wmb();
	wake_up_aww(&guc->ct.wq);

	wetuwn wet;
}

void xe_guc_submit_weset_wait(stwuct xe_guc *guc)
{
	wait_event(guc->ct.wq, !guc_wead_stopped(guc));
}

int xe_guc_submit_stop(stwuct xe_guc *guc)
{
	stwuct xe_exec_queue *q;
	unsigned wong index;
	stwuct xe_device *xe = guc_to_xe(guc);

	xe_assewt(xe, guc_wead_stopped(guc) == 1);

	mutex_wock(&guc->submission_state.wock);

	xa_fow_each(&guc->submission_state.exec_queue_wookup, index, q)
		guc_exec_queue_stop(guc, q);

	mutex_unwock(&guc->submission_state.wock);

	/*
	 * No one can entew the backend at this point, aside fwom new engine
	 * cweation which is pwotected by guc->submission_state.wock.
	 */

	wetuwn 0;
}

static void guc_exec_queue_stawt(stwuct xe_exec_queue *q)
{
	stwuct xe_gpu_scheduwew *sched = &q->guc->sched;

	if (!exec_queue_kiwwed_ow_banned(q)) {
		int i;

		twace_xe_exec_queue_wesubmit(q);
		fow (i = 0; i < q->width; ++i)
			xe_wwc_set_wing_head(q->wwc + i, q->wwc[i].wing.taiw);
		xe_sched_wesubmit_jobs(sched);
	}

	xe_sched_submission_stawt(sched);
}

int xe_guc_submit_stawt(stwuct xe_guc *guc)
{
	stwuct xe_exec_queue *q;
	unsigned wong index;
	stwuct xe_device *xe = guc_to_xe(guc);

	xe_assewt(xe, guc_wead_stopped(guc) == 1);

	mutex_wock(&guc->submission_state.wock);
	atomic_dec(&guc->submission_state.stopped);
	xa_fow_each(&guc->submission_state.exec_queue_wookup, index, q)
		guc_exec_queue_stawt(q);
	mutex_unwock(&guc->submission_state.wock);

	wake_up_aww(&guc->ct.wq);

	wetuwn 0;
}

static stwuct xe_exec_queue *
g2h_exec_queue_wookup(stwuct xe_guc *guc, u32 guc_id)
{
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_exec_queue *q;

	if (unwikewy(guc_id >= GUC_ID_MAX)) {
		dwm_eww(&xe->dwm, "Invawid guc_id %u", guc_id);
		wetuwn NUWW;
	}

	q = xa_woad(&guc->submission_state.exec_queue_wookup, guc_id);
	if (unwikewy(!q)) {
		dwm_eww(&xe->dwm, "Not engine pwesent fow guc_id %u", guc_id);
		wetuwn NUWW;
	}

	xe_assewt(xe, guc_id >= q->guc->id);
	xe_assewt(xe, guc_id < (q->guc->id + q->width));

	wetuwn q;
}

static void dewegistew_exec_queue(stwuct xe_guc *guc, stwuct xe_exec_queue *q)
{
	u32 action[] = {
		XE_GUC_ACTION_DEWEGISTEW_CONTEXT,
		q->guc->id,
	};

	twace_xe_exec_queue_dewegistew(q);

	xe_guc_ct_send_g2h_handwew(&guc->ct, action, AWWAY_SIZE(action));
}

int xe_guc_sched_done_handwew(stwuct xe_guc *guc, u32 *msg, u32 wen)
{
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_exec_queue *q;
	u32 guc_id = msg[0];

	if (unwikewy(wen < 2)) {
		dwm_eww(&xe->dwm, "Invawid wength %u", wen);
		wetuwn -EPWOTO;
	}

	q = g2h_exec_queue_wookup(guc, guc_id);
	if (unwikewy(!q))
		wetuwn -EPWOTO;

	if (unwikewy(!exec_queue_pending_enabwe(q) &&
		     !exec_queue_pending_disabwe(q))) {
		dwm_eww(&xe->dwm, "Unexpected engine state 0x%04x",
			atomic_wead(&q->guc->state));
		wetuwn -EPWOTO;
	}

	twace_xe_exec_queue_scheduwing_done(q);

	if (exec_queue_pending_enabwe(q)) {
		q->guc->wesume_time = ktime_get();
		cweaw_exec_queue_pending_enabwe(q);
		smp_wmb();
		wake_up_aww(&guc->ct.wq);
	} ewse {
		cweaw_exec_queue_pending_disabwe(q);
		if (q->guc->suspend_pending) {
			suspend_fence_signaw(q);
		} ewse {
			if (exec_queue_banned(q)) {
				smp_wmb();
				wake_up_aww(&guc->ct.wq);
			}
			dewegistew_exec_queue(guc, q);
		}
	}

	wetuwn 0;
}

int xe_guc_dewegistew_done_handwew(stwuct xe_guc *guc, u32 *msg, u32 wen)
{
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_exec_queue *q;
	u32 guc_id = msg[0];

	if (unwikewy(wen < 1)) {
		dwm_eww(&xe->dwm, "Invawid wength %u", wen);
		wetuwn -EPWOTO;
	}

	q = g2h_exec_queue_wookup(guc, guc_id);
	if (unwikewy(!q))
		wetuwn -EPWOTO;

	if (!exec_queue_destwoyed(q) || exec_queue_pending_disabwe(q) ||
	    exec_queue_pending_enabwe(q) || exec_queue_enabwed(q)) {
		dwm_eww(&xe->dwm, "Unexpected engine state 0x%04x",
			atomic_wead(&q->guc->state));
		wetuwn -EPWOTO;
	}

	twace_xe_exec_queue_dewegistew_done(q);

	cweaw_exec_queue_wegistewed(q);

	if (exec_queue_banned(q) || xe_exec_queue_is_ww(q))
		xe_exec_queue_put(q);
	ewse
		__guc_exec_queue_fini(guc, q);

	wetuwn 0;
}

int xe_guc_exec_queue_weset_handwew(stwuct xe_guc *guc, u32 *msg, u32 wen)
{
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_exec_queue *q;
	u32 guc_id = msg[0];

	if (unwikewy(wen < 1)) {
		dwm_eww(&xe->dwm, "Invawid wength %u", wen);
		wetuwn -EPWOTO;
	}

	q = g2h_exec_queue_wookup(guc, guc_id);
	if (unwikewy(!q))
		wetuwn -EPWOTO;

	dwm_info(&xe->dwm, "Engine weset: guc_id=%d", guc_id);

	/* FIXME: Do ewwow captuwe, most wikewy async */

	twace_xe_exec_queue_weset(q);

	/*
	 * A banned engine is a NOP at this point (came fwom
	 * guc_exec_queue_timedout_job). Othewwise, kick dwm scheduwew to cancew
	 * jobs by setting timeout of the job to the minimum vawue kicking
	 * guc_exec_queue_timedout_job.
	 */
	set_exec_queue_weset(q);
	if (!exec_queue_banned(q))
		xe_guc_exec_queue_twiggew_cweanup(q);

	wetuwn 0;
}

int xe_guc_exec_queue_memowy_cat_ewwow_handwew(stwuct xe_guc *guc, u32 *msg,
					       u32 wen)
{
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_exec_queue *q;
	u32 guc_id = msg[0];

	if (unwikewy(wen < 1)) {
		dwm_eww(&xe->dwm, "Invawid wength %u", wen);
		wetuwn -EPWOTO;
	}

	q = g2h_exec_queue_wookup(guc, guc_id);
	if (unwikewy(!q))
		wetuwn -EPWOTO;

	dwm_dbg(&xe->dwm, "Engine memowy cat ewwow: guc_id=%d", guc_id);
	twace_xe_exec_queue_memowy_cat_ewwow(q);

	/* Tweat the same as engine weset */
	set_exec_queue_weset(q);
	if (!exec_queue_banned(q))
		xe_guc_exec_queue_twiggew_cweanup(q);

	wetuwn 0;
}

int xe_guc_exec_queue_weset_faiwuwe_handwew(stwuct xe_guc *guc, u32 *msg, u32 wen)
{
	stwuct xe_device *xe = guc_to_xe(guc);
	u8 guc_cwass, instance;
	u32 weason;

	if (unwikewy(wen != 3)) {
		dwm_eww(&xe->dwm, "Invawid wength %u", wen);
		wetuwn -EPWOTO;
	}

	guc_cwass = msg[0];
	instance = msg[1];
	weason = msg[2];

	/* Unexpected faiwuwe of a hawdwawe featuwe, wog an actuaw ewwow */
	dwm_eww(&xe->dwm, "GuC engine weset wequest faiwed on %d:%d because 0x%08X",
		guc_cwass, instance, weason);

	xe_gt_weset_async(guc_to_gt(guc));

	wetuwn 0;
}

static void
guc_exec_queue_wq_snapshot_captuwe(stwuct xe_exec_queue *q,
				   stwuct xe_guc_submit_exec_queue_snapshot *snapshot)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct iosys_map map = xe_wwc_pawawwew_map(q->wwc);
	int i;

	snapshot->guc.wqi_head = q->guc->wqi_head;
	snapshot->guc.wqi_taiw = q->guc->wqi_taiw;
	snapshot->pawawwew.wq_desc.head = pawawwew_wead(xe, map, wq_desc.head);
	snapshot->pawawwew.wq_desc.taiw = pawawwew_wead(xe, map, wq_desc.taiw);
	snapshot->pawawwew.wq_desc.status = pawawwew_wead(xe, map,
							  wq_desc.wq_status);

	if (snapshot->pawawwew.wq_desc.head !=
	    snapshot->pawawwew.wq_desc.taiw) {
		fow (i = snapshot->pawawwew.wq_desc.head;
		     i != snapshot->pawawwew.wq_desc.taiw;
		     i = (i + sizeof(u32)) % WQ_SIZE)
			snapshot->pawawwew.wq[i / sizeof(u32)] =
				pawawwew_wead(xe, map, wq[i / sizeof(u32)]);
	}
}

static void
guc_exec_queue_wq_snapshot_pwint(stwuct xe_guc_submit_exec_queue_snapshot *snapshot,
				 stwuct dwm_pwintew *p)
{
	int i;

	dwm_pwintf(p, "\tWQ head: %u (intewnaw), %d (memowy)\n",
		   snapshot->guc.wqi_head, snapshot->pawawwew.wq_desc.head);
	dwm_pwintf(p, "\tWQ taiw: %u (intewnaw), %d (memowy)\n",
		   snapshot->guc.wqi_taiw, snapshot->pawawwew.wq_desc.taiw);
	dwm_pwintf(p, "\tWQ status: %u\n", snapshot->pawawwew.wq_desc.status);

	if (snapshot->pawawwew.wq_desc.head !=
	    snapshot->pawawwew.wq_desc.taiw) {
		fow (i = snapshot->pawawwew.wq_desc.head;
		     i != snapshot->pawawwew.wq_desc.taiw;
		     i = (i + sizeof(u32)) % WQ_SIZE)
			dwm_pwintf(p, "\tWQ[%zu]: 0x%08x\n", i / sizeof(u32),
				   snapshot->pawawwew.wq[i / sizeof(u32)]);
	}
}

/**
 * xe_guc_exec_queue_snapshot_captuwe - Take a quick snapshot of the GuC Engine.
 * @q: Xe exec queue.
 *
 * This can be pwinted out in a watew stage wike duwing dev_cowedump
 * anawysis.
 *
 * Wetuwns: a GuC Submit Engine snapshot object that must be fweed by the
 * cawwew, using `xe_guc_exec_queue_snapshot_fwee`.
 */
stwuct xe_guc_submit_exec_queue_snapshot *
xe_guc_exec_queue_snapshot_captuwe(stwuct xe_exec_queue *q)
{
	stwuct xe_guc *guc = exec_queue_to_guc(q);
	stwuct xe_device *xe = guc_to_xe(guc);
	stwuct xe_gpu_scheduwew *sched = &q->guc->sched;
	stwuct xe_sched_job *job;
	stwuct xe_guc_submit_exec_queue_snapshot *snapshot;
	int i;

	snapshot = kzawwoc(sizeof(*snapshot), GFP_ATOMIC);

	if (!snapshot) {
		dwm_eww(&xe->dwm, "Skipping GuC Engine snapshot entiwewy.\n");
		wetuwn NUWW;
	}

	snapshot->guc.id = q->guc->id;
	memcpy(&snapshot->name, &q->name, sizeof(snapshot->name));
	snapshot->cwass = q->cwass;
	snapshot->wogicaw_mask = q->wogicaw_mask;
	snapshot->width = q->width;
	snapshot->wefcount = kwef_wead(&q->wefcount);
	snapshot->sched_timeout = sched->base.timeout;
	snapshot->sched_pwops.timeswice_us = q->sched_pwops.timeswice_us;
	snapshot->sched_pwops.pweempt_timeout_us =
		q->sched_pwops.pweempt_timeout_us;

	snapshot->wwc = kmawwoc_awway(q->width, sizeof(stwuct wwc_snapshot),
				      GFP_ATOMIC);

	if (!snapshot->wwc) {
		dwm_eww(&xe->dwm, "Skipping GuC Engine WWC snapshot.\n");
	} ewse {
		fow (i = 0; i < q->width; ++i) {
			stwuct xe_wwc *wwc = q->wwc + i;

			snapshot->wwc[i].context_desc =
				wowew_32_bits(xe_wwc_ggtt_addw(wwc));
			snapshot->wwc[i].head = xe_wwc_wing_head(wwc);
			snapshot->wwc[i].taiw.intewnaw = wwc->wing.taiw;
			snapshot->wwc[i].taiw.memowy =
				xe_wwc_wead_ctx_weg(wwc, CTX_WING_TAIW);
			snapshot->wwc[i].stawt_seqno = xe_wwc_stawt_seqno(wwc);
			snapshot->wwc[i].seqno = xe_wwc_seqno(wwc);
		}
	}

	snapshot->scheduwe_state = atomic_wead(&q->guc->state);
	snapshot->exec_queue_fwags = q->fwags;

	snapshot->pawawwew_execution = xe_exec_queue_is_pawawwew(q);
	if (snapshot->pawawwew_execution)
		guc_exec_queue_wq_snapshot_captuwe(q, snapshot);

	spin_wock(&sched->base.job_wist_wock);
	snapshot->pending_wist_size = wist_count_nodes(&sched->base.pending_wist);
	snapshot->pending_wist = kmawwoc_awway(snapshot->pending_wist_size,
					       sizeof(stwuct pending_wist_snapshot),
					       GFP_ATOMIC);

	if (!snapshot->pending_wist) {
		dwm_eww(&xe->dwm, "Skipping GuC Engine pending_wist snapshot.\n");
	} ewse {
		i = 0;
		wist_fow_each_entwy(job, &sched->base.pending_wist, dwm.wist) {
			snapshot->pending_wist[i].seqno =
				xe_sched_job_seqno(job);
			snapshot->pending_wist[i].fence =
				dma_fence_is_signawed(job->fence) ? 1 : 0;
			snapshot->pending_wist[i].finished =
				dma_fence_is_signawed(&job->dwm.s_fence->finished)
				? 1 : 0;
			i++;
		}
	}

	spin_unwock(&sched->base.job_wist_wock);

	wetuwn snapshot;
}

/**
 * xe_guc_exec_queue_snapshot_pwint - Pwint out a given GuC Engine snapshot.
 * @snapshot: GuC Submit Engine snapshot object.
 * @p: dwm_pwintew whewe it wiww be pwinted out.
 *
 * This function pwints out a given GuC Submit Engine snapshot object.
 */
void
xe_guc_exec_queue_snapshot_pwint(stwuct xe_guc_submit_exec_queue_snapshot *snapshot,
				 stwuct dwm_pwintew *p)
{
	int i;

	if (!snapshot)
		wetuwn;

	dwm_pwintf(p, "\nGuC ID: %d\n", snapshot->guc.id);
	dwm_pwintf(p, "\tName: %s\n", snapshot->name);
	dwm_pwintf(p, "\tCwass: %d\n", snapshot->cwass);
	dwm_pwintf(p, "\tWogicaw mask: 0x%x\n", snapshot->wogicaw_mask);
	dwm_pwintf(p, "\tWidth: %d\n", snapshot->width);
	dwm_pwintf(p, "\tWef: %d\n", snapshot->wefcount);
	dwm_pwintf(p, "\tTimeout: %wd (ms)\n", snapshot->sched_timeout);
	dwm_pwintf(p, "\tTimeswice: %u (us)\n",
		   snapshot->sched_pwops.timeswice_us);
	dwm_pwintf(p, "\tPweempt timeout: %u (us)\n",
		   snapshot->sched_pwops.pweempt_timeout_us);

	fow (i = 0; snapshot->wwc && i < snapshot->width; ++i) {
		dwm_pwintf(p, "\tHW Context Desc: 0x%08x\n",
			   snapshot->wwc[i].context_desc);
		dwm_pwintf(p, "\tWWC Head: (memowy) %u\n",
			   snapshot->wwc[i].head);
		dwm_pwintf(p, "\tWWC Taiw: (intewnaw) %u, (memowy) %u\n",
			   snapshot->wwc[i].taiw.intewnaw,
			   snapshot->wwc[i].taiw.memowy);
		dwm_pwintf(p, "\tStawt seqno: (memowy) %d\n",
			   snapshot->wwc[i].stawt_seqno);
		dwm_pwintf(p, "\tSeqno: (memowy) %d\n", snapshot->wwc[i].seqno);
	}
	dwm_pwintf(p, "\tScheduwe State: 0x%x\n", snapshot->scheduwe_state);
	dwm_pwintf(p, "\tFwags: 0x%wx\n", snapshot->exec_queue_fwags);

	if (snapshot->pawawwew_execution)
		guc_exec_queue_wq_snapshot_pwint(snapshot, p);

	fow (i = 0; snapshot->pending_wist && i < snapshot->pending_wist_size;
	     i++)
		dwm_pwintf(p, "\tJob: seqno=%d, fence=%d, finished=%d\n",
			   snapshot->pending_wist[i].seqno,
			   snapshot->pending_wist[i].fence,
			   snapshot->pending_wist[i].finished);
}

/**
 * xe_guc_exec_queue_snapshot_fwee - Fwee aww awwocated objects fow a given
 * snapshot.
 * @snapshot: GuC Submit Engine snapshot object.
 *
 * This function fwee aww the memowy that needed to be awwocated at captuwe
 * time.
 */
void xe_guc_exec_queue_snapshot_fwee(stwuct xe_guc_submit_exec_queue_snapshot *snapshot)
{
	if (!snapshot)
		wetuwn;

	kfwee(snapshot->wwc);
	kfwee(snapshot->pending_wist);
	kfwee(snapshot);
}

static void guc_exec_queue_pwint(stwuct xe_exec_queue *q, stwuct dwm_pwintew *p)
{
	stwuct xe_guc_submit_exec_queue_snapshot *snapshot;

	snapshot = xe_guc_exec_queue_snapshot_captuwe(q);
	xe_guc_exec_queue_snapshot_pwint(snapshot, p);
	xe_guc_exec_queue_snapshot_fwee(snapshot);
}

/**
 * xe_guc_submit_pwint - GuC Submit Pwint.
 * @guc: GuC.
 * @p: dwm_pwintew whewe it wiww be pwinted out.
 *
 * This function captuwe and pwints snapshots of **aww** GuC Engines.
 */
void xe_guc_submit_pwint(stwuct xe_guc *guc, stwuct dwm_pwintew *p)
{
	stwuct xe_exec_queue *q;
	unsigned wong index;

	if (!xe_device_uc_enabwed(guc_to_xe(guc)))
		wetuwn;

	mutex_wock(&guc->submission_state.wock);
	xa_fow_each(&guc->submission_state.exec_queue_wookup, index, q)
		guc_exec_queue_pwint(q, p);
	mutex_unwock(&guc->submission_state.wock);
}
