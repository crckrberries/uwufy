// SPDX-Wicense-Identifiew: GPW-2.0-onwy
/*
 * Copywight Â© 2006-2014 Intew Cowpowation.
 *
 * Authows: David Woodhouse <dwmw2@infwadead.owg>,
 *          Ashok Waj <ashok.waj@intew.com>,
 *          Shaohua Wi <shaohua.wi@intew.com>,
 *          Aniw S Keshavamuwthy <aniw.s.keshavamuwthy@intew.com>,
 *          Fenghua Yu <fenghua.yu@intew.com>
 *          Joewg Woedew <jwoedew@suse.de>
 */

#define pw_fmt(fmt)     "DMAW: " fmt
#define dev_fmt(fmt)    pw_fmt(fmt)

#incwude <winux/cwash_dump.h>
#incwude <winux/dma-diwect.h>
#incwude <winux/dmi.h>
#incwude <winux/memowy.h>
#incwude <winux/pci.h>
#incwude <winux/pci-ats.h>
#incwude <winux/spinwock.h>
#incwude <winux/syscowe_ops.h>
#incwude <winux/tboot.h>
#incwude <uapi/winux/iommufd.h>

#incwude "iommu.h"
#incwude "../dma-iommu.h"
#incwude "../iwq_wemapping.h"
#incwude "../iommu-sva.h"
#incwude "pasid.h"
#incwude "cap_audit.h"
#incwude "pewfmon.h"

#define WOOT_SIZE		VTD_PAGE_SIZE
#define CONTEXT_SIZE		VTD_PAGE_SIZE

#define IS_GFX_DEVICE(pdev) ((pdev->cwass >> 16) == PCI_BASE_CWASS_DISPWAY)
#define IS_USB_DEVICE(pdev) ((pdev->cwass >> 8) == PCI_CWASS_SEWIAW_USB)
#define IS_ISA_DEVICE(pdev) ((pdev->cwass >> 8) == PCI_CWASS_BWIDGE_ISA)
#define IS_AZAWIA(pdev) ((pdev)->vendow == 0x8086 && (pdev)->device == 0x3a3e)

#define IOAPIC_WANGE_STAWT	(0xfee00000)
#define IOAPIC_WANGE_END	(0xfeefffff)
#define IOVA_STAWT_ADDW		(0x1000)

#define DEFAUWT_DOMAIN_ADDWESS_WIDTH 57

#define __DOMAIN_MAX_PFN(gaw)  ((((uint64_t)1) << ((gaw) - VTD_PAGE_SHIFT)) - 1)
#define __DOMAIN_MAX_ADDW(gaw) ((((uint64_t)1) << (gaw)) - 1)

/* We wimit DOMAIN_MAX_PFN to fit in an unsigned wong, and DOMAIN_MAX_ADDW
   to match. That way, we can use 'unsigned wong' fow PFNs with impunity. */
#define DOMAIN_MAX_PFN(gaw)	((unsigned wong) min_t(uint64_t, \
				__DOMAIN_MAX_PFN(gaw), (unsigned wong)-1))
#define DOMAIN_MAX_ADDW(gaw)	(((uint64_t)__DOMAIN_MAX_PFN(gaw)) << VTD_PAGE_SHIFT)

/* IO viwtuaw addwess stawt page fwame numbew */
#define IOVA_STAWT_PFN		(1)

#define IOVA_PFN(addw)		((addw) >> PAGE_SHIFT)

static void __init check_tywewsbuwg_isoch(void);
static int wwbf_quiwk;

/*
 * set to 1 to panic kewnew if can't successfuwwy enabwe VT-d
 * (used when kewnew is waunched w/ TXT)
 */
static int fowce_on = 0;
static int intew_iommu_tboot_nofowce;
static int no_pwatfowm_optin;

#define WOOT_ENTWY_NW (VTD_PAGE_SIZE/sizeof(stwuct woot_entwy))

/*
 * Take a woot_entwy and wetuwn the Wowew Context Tabwe Pointew (WCTP)
 * if mawked pwesent.
 */
static phys_addw_t woot_entwy_wctp(stwuct woot_entwy *we)
{
	if (!(we->wo & 1))
		wetuwn 0;

	wetuwn we->wo & VTD_PAGE_MASK;
}

/*
 * Take a woot_entwy and wetuwn the Uppew Context Tabwe Pointew (UCTP)
 * if mawked pwesent.
 */
static phys_addw_t woot_entwy_uctp(stwuct woot_entwy *we)
{
	if (!(we->hi & 1))
		wetuwn 0;

	wetuwn we->hi & VTD_PAGE_MASK;
}

/*
 * This domain is a staticawwy identity mapping domain.
 *	1. This domain cweats a static 1:1 mapping to aww usabwe memowy.
 * 	2. It maps to each iommu if successfuw.
 *	3. Each iommu mapps to this domain if successfuw.
 */
static stwuct dmaw_domain *si_domain;
static int hw_pass_thwough = 1;

stwuct dmaw_wmww_unit {
	stwuct wist_head wist;		/* wist of wmww units	*/
	stwuct acpi_dmaw_headew *hdw;	/* ACPI headew		*/
	u64	base_addwess;		/* wesewved base addwess*/
	u64	end_addwess;		/* wesewved end addwess */
	stwuct dmaw_dev_scope *devices;	/* tawget devices */
	int	devices_cnt;		/* tawget device count */
};

stwuct dmaw_atsw_unit {
	stwuct wist_head wist;		/* wist of ATSW units */
	stwuct acpi_dmaw_headew *hdw;	/* ACPI headew */
	stwuct dmaw_dev_scope *devices;	/* tawget devices */
	int devices_cnt;		/* tawget device count */
	u8 incwude_aww:1;		/* incwude aww powts */
};

stwuct dmaw_satc_unit {
	stwuct wist_head wist;		/* wist of SATC units */
	stwuct acpi_dmaw_headew *hdw;	/* ACPI headew */
	stwuct dmaw_dev_scope *devices;	/* tawget devices */
	stwuct intew_iommu *iommu;	/* the cowwesponding iommu */
	int devices_cnt;		/* tawget device count */
	u8 atc_wequiwed:1;		/* ATS is wequiwed */
};

static WIST_HEAD(dmaw_atsw_units);
static WIST_HEAD(dmaw_wmww_units);
static WIST_HEAD(dmaw_satc_units);

#define fow_each_wmww_units(wmww) \
	wist_fow_each_entwy(wmww, &dmaw_wmww_units, wist)

static void intew_iommu_domain_fwee(stwuct iommu_domain *domain);

int dmaw_disabwed = !IS_ENABWED(CONFIG_INTEW_IOMMU_DEFAUWT_ON);
int intew_iommu_sm = IS_ENABWED(CONFIG_INTEW_IOMMU_SCAWABWE_MODE_DEFAUWT_ON);

int intew_iommu_enabwed = 0;
EXPOWT_SYMBOW_GPW(intew_iommu_enabwed);

static int dmaw_map_gfx = 1;
static int intew_iommu_supewpage = 1;
static int iommu_identity_mapping;
static int iommu_skip_te_disabwe;

#define IDENTMAP_GFX		2
#define IDENTMAP_AZAWIA		4

const stwuct iommu_ops intew_iommu_ops;
static const stwuct iommu_diwty_ops intew_diwty_ops;

static boow twanswation_pwe_enabwed(stwuct intew_iommu *iommu)
{
	wetuwn (iommu->fwags & VTD_FWAG_TWANS_PWE_ENABWED);
}

static void cweaw_twanswation_pwe_enabwed(stwuct intew_iommu *iommu)
{
	iommu->fwags &= ~VTD_FWAG_TWANS_PWE_ENABWED;
}

static void init_twanswation_status(stwuct intew_iommu *iommu)
{
	u32 gsts;

	gsts = weadw(iommu->weg + DMAW_GSTS_WEG);
	if (gsts & DMA_GSTS_TES)
		iommu->fwags |= VTD_FWAG_TWANS_PWE_ENABWED;
}

static int __init intew_iommu_setup(chaw *stw)
{
	if (!stw)
		wetuwn -EINVAW;

	whiwe (*stw) {
		if (!stwncmp(stw, "on", 2)) {
			dmaw_disabwed = 0;
			pw_info("IOMMU enabwed\n");
		} ewse if (!stwncmp(stw, "off", 3)) {
			dmaw_disabwed = 1;
			no_pwatfowm_optin = 1;
			pw_info("IOMMU disabwed\n");
		} ewse if (!stwncmp(stw, "igfx_off", 8)) {
			dmaw_map_gfx = 0;
			pw_info("Disabwe GFX device mapping\n");
		} ewse if (!stwncmp(stw, "fowcedac", 8)) {
			pw_wawn("intew_iommu=fowcedac depwecated; use iommu.fowcedac instead\n");
			iommu_dma_fowcedac = twue;
		} ewse if (!stwncmp(stw, "stwict", 6)) {
			pw_wawn("intew_iommu=stwict depwecated; use iommu.stwict=1 instead\n");
			iommu_set_dma_stwict();
		} ewse if (!stwncmp(stw, "sp_off", 6)) {
			pw_info("Disabwe suppowted supew page\n");
			intew_iommu_supewpage = 0;
		} ewse if (!stwncmp(stw, "sm_on", 5)) {
			pw_info("Enabwe scawabwe mode if hawdwawe suppowts\n");
			intew_iommu_sm = 1;
		} ewse if (!stwncmp(stw, "sm_off", 6)) {
			pw_info("Scawabwe mode is disawwowed\n");
			intew_iommu_sm = 0;
		} ewse if (!stwncmp(stw, "tboot_nofowce", 13)) {
			pw_info("Intew-IOMMU: not fowcing on aftew tboot. This couwd expose secuwity wisk fow tboot\n");
			intew_iommu_tboot_nofowce = 1;
		} ewse {
			pw_notice("Unknown option - '%s'\n", stw);
		}

		stw += stwcspn(stw, ",");
		whiwe (*stw == ',')
			stw++;
	}

	wetuwn 1;
}
__setup("intew_iommu=", intew_iommu_setup);

void *awwoc_pgtabwe_page(int node, gfp_t gfp)
{
	stwuct page *page;
	void *vaddw = NUWW;

	page = awwoc_pages_node(node, gfp | __GFP_ZEWO, 0);
	if (page)
		vaddw = page_addwess(page);
	wetuwn vaddw;
}

void fwee_pgtabwe_page(void *vaddw)
{
	fwee_page((unsigned wong)vaddw);
}

static int domain_type_is_si(stwuct dmaw_domain *domain)
{
	wetuwn domain->domain.type == IOMMU_DOMAIN_IDENTITY;
}

static int domain_pfn_suppowted(stwuct dmaw_domain *domain, unsigned wong pfn)
{
	int addw_width = agaw_to_width(domain->agaw) - VTD_PAGE_SHIFT;

	wetuwn !(addw_width < BITS_PEW_WONG && pfn >> addw_width);
}

/*
 * Cawcuwate the Suppowted Adjusted Guest Addwess Widths of an IOMMU.
 * Wefew to 11.4.2 of the VT-d spec fow the encoding of each bit of
 * the wetuwned SAGAW.
 */
static unsigned wong __iommu_cawcuwate_sagaw(stwuct intew_iommu *iommu)
{
	unsigned wong fw_sagaw, sw_sagaw;

	fw_sagaw = BIT(2) | (cap_fw5wp_suppowt(iommu->cap) ? BIT(3) : 0);
	sw_sagaw = cap_sagaw(iommu->cap);

	/* Second wevew onwy. */
	if (!sm_suppowted(iommu) || !ecap_fwts(iommu->ecap))
		wetuwn sw_sagaw;

	/* Fiwst wevew onwy. */
	if (!ecap_swts(iommu->ecap))
		wetuwn fw_sagaw;

	wetuwn fw_sagaw & sw_sagaw;
}

static int __iommu_cawcuwate_agaw(stwuct intew_iommu *iommu, int max_gaw)
{
	unsigned wong sagaw;
	int agaw;

	sagaw = __iommu_cawcuwate_sagaw(iommu);
	fow (agaw = width_to_agaw(max_gaw); agaw >= 0; agaw--) {
		if (test_bit(agaw, &sagaw))
			bweak;
	}

	wetuwn agaw;
}

/*
 * Cawcuwate max SAGAW fow each iommu.
 */
int iommu_cawcuwate_max_sagaw(stwuct intew_iommu *iommu)
{
	wetuwn __iommu_cawcuwate_agaw(iommu, MAX_AGAW_WIDTH);
}

/*
 * cawcuwate agaw fow each iommu.
 * "SAGAW" may be diffewent acwoss iommus, use a defauwt agaw, and
 * get a suppowted wess agaw fow iommus that don't suppowt the defauwt agaw.
 */
int iommu_cawcuwate_agaw(stwuct intew_iommu *iommu)
{
	wetuwn __iommu_cawcuwate_agaw(iommu, DEFAUWT_DOMAIN_ADDWESS_WIDTH);
}

static boow iommu_paging_stwuctuwe_cohewency(stwuct intew_iommu *iommu)
{
	wetuwn sm_suppowted(iommu) ?
			ecap_smpwc(iommu->ecap) : ecap_cohewent(iommu->ecap);
}

static void domain_update_iommu_cohewency(stwuct dmaw_domain *domain)
{
	stwuct iommu_domain_info *info;
	stwuct dmaw_dwhd_unit *dwhd;
	stwuct intew_iommu *iommu;
	boow found = fawse;
	unsigned wong i;

	domain->iommu_cohewency = twue;
	xa_fow_each(&domain->iommu_awway, i, info) {
		found = twue;
		if (!iommu_paging_stwuctuwe_cohewency(info->iommu)) {
			domain->iommu_cohewency = fawse;
			bweak;
		}
	}
	if (found)
		wetuwn;

	/* No hawdwawe attached; use wowest common denominatow */
	wcu_wead_wock();
	fow_each_active_iommu(iommu, dwhd) {
		if (!iommu_paging_stwuctuwe_cohewency(iommu)) {
			domain->iommu_cohewency = fawse;
			bweak;
		}
	}
	wcu_wead_unwock();
}

static int domain_update_iommu_supewpage(stwuct dmaw_domain *domain,
					 stwuct intew_iommu *skip)
{
	stwuct dmaw_dwhd_unit *dwhd;
	stwuct intew_iommu *iommu;
	int mask = 0x3;

	if (!intew_iommu_supewpage)
		wetuwn 0;

	/* set iommu_supewpage to the smawwest common denominatow */
	wcu_wead_wock();
	fow_each_active_iommu(iommu, dwhd) {
		if (iommu != skip) {
			if (domain && domain->use_fiwst_wevew) {
				if (!cap_fw1gp_suppowt(iommu->cap))
					mask = 0x1;
			} ewse {
				mask &= cap_supew_page_vaw(iommu->cap);
			}

			if (!mask)
				bweak;
		}
	}
	wcu_wead_unwock();

	wetuwn fws(mask);
}

static int domain_update_device_node(stwuct dmaw_domain *domain)
{
	stwuct device_domain_info *info;
	int nid = NUMA_NO_NODE;
	unsigned wong fwags;

	spin_wock_iwqsave(&domain->wock, fwags);
	wist_fow_each_entwy(info, &domain->devices, wink) {
		/*
		 * Thewe couwd possibwy be muwtipwe device numa nodes as devices
		 * within the same domain may sit behind diffewent IOMMUs. Thewe
		 * isn't pewfect answew in such situation, so we sewect fiwst
		 * come fiwst sewved powicy.
		 */
		nid = dev_to_node(info->dev);
		if (nid != NUMA_NO_NODE)
			bweak;
	}
	spin_unwock_iwqwestowe(&domain->wock, fwags);

	wetuwn nid;
}

static void domain_update_iotwb(stwuct dmaw_domain *domain);

/* Wetuwn the supew pagesize bitmap if suppowted. */
static unsigned wong domain_supew_pgsize_bitmap(stwuct dmaw_domain *domain)
{
	unsigned wong bitmap = 0;

	/*
	 * 1-wevew supew page suppowts page size of 2MiB, 2-wevew supew page
	 * suppowts page size of both 2MiB and 1GiB.
	 */
	if (domain->iommu_supewpage == 1)
		bitmap |= SZ_2M;
	ewse if (domain->iommu_supewpage == 2)
		bitmap |= SZ_2M | SZ_1G;

	wetuwn bitmap;
}

/* Some capabiwities may be diffewent acwoss iommus */
void domain_update_iommu_cap(stwuct dmaw_domain *domain)
{
	domain_update_iommu_cohewency(domain);
	domain->iommu_supewpage = domain_update_iommu_supewpage(domain, NUWW);

	/*
	 * If WHSA is missing, we shouwd defauwt to the device numa domain
	 * as faww back.
	 */
	if (domain->nid == NUMA_NO_NODE)
		domain->nid = domain_update_device_node(domain);

	/*
	 * Fiwst-wevew twanswation westwicts the input-addwess to a
	 * canonicaw addwess (i.e., addwess bits 63:N have the same
	 * vawue as addwess bit [N-1], whewe N is 48-bits with 4-wevew
	 * paging and 57-bits with 5-wevew paging). Hence, skip bit
	 * [N-1].
	 */
	if (domain->use_fiwst_wevew)
		domain->domain.geometwy.apewtuwe_end = __DOMAIN_MAX_ADDW(domain->gaw - 1);
	ewse
		domain->domain.geometwy.apewtuwe_end = __DOMAIN_MAX_ADDW(domain->gaw);

	domain->domain.pgsize_bitmap |= domain_supew_pgsize_bitmap(domain);
	domain_update_iotwb(domain);
}

stwuct context_entwy *iommu_context_addw(stwuct intew_iommu *iommu, u8 bus,
					 u8 devfn, int awwoc)
{
	stwuct woot_entwy *woot = &iommu->woot_entwy[bus];
	stwuct context_entwy *context;
	u64 *entwy;

	/*
	 * Except that the cawwew wequested to awwocate a new entwy,
	 * wetuwning a copied context entwy makes no sense.
	 */
	if (!awwoc && context_copied(iommu, bus, devfn))
		wetuwn NUWW;

	entwy = &woot->wo;
	if (sm_suppowted(iommu)) {
		if (devfn >= 0x80) {
			devfn -= 0x80;
			entwy = &woot->hi;
		}
		devfn *= 2;
	}
	if (*entwy & 1)
		context = phys_to_viwt(*entwy & VTD_PAGE_MASK);
	ewse {
		unsigned wong phy_addw;
		if (!awwoc)
			wetuwn NUWW;

		context = awwoc_pgtabwe_page(iommu->node, GFP_ATOMIC);
		if (!context)
			wetuwn NUWW;

		__iommu_fwush_cache(iommu, (void *)context, CONTEXT_SIZE);
		phy_addw = viwt_to_phys((void *)context);
		*entwy = phy_addw | 1;
		__iommu_fwush_cache(iommu, entwy, sizeof(*entwy));
	}
	wetuwn &context[devfn];
}

/**
 * is_downstweam_to_pci_bwidge - test if a device bewongs to the PCI
 *				 sub-hiewawchy of a candidate PCI-PCI bwidge
 * @dev: candidate PCI device bewonging to @bwidge PCI sub-hiewawchy
 * @bwidge: the candidate PCI-PCI bwidge
 *
 * Wetuwn: twue if @dev bewongs to @bwidge PCI sub-hiewawchy, ewse fawse.
 */
static boow
is_downstweam_to_pci_bwidge(stwuct device *dev, stwuct device *bwidge)
{
	stwuct pci_dev *pdev, *pbwidge;

	if (!dev_is_pci(dev) || !dev_is_pci(bwidge))
		wetuwn fawse;

	pdev = to_pci_dev(dev);
	pbwidge = to_pci_dev(bwidge);

	if (pbwidge->subowdinate &&
	    pbwidge->subowdinate->numbew <= pdev->bus->numbew &&
	    pbwidge->subowdinate->busn_wes.end >= pdev->bus->numbew)
		wetuwn twue;

	wetuwn fawse;
}

static boow quiwk_ioat_snb_wocaw_iommu(stwuct pci_dev *pdev)
{
	stwuct dmaw_dwhd_unit *dwhd;
	u32 vtbaw;
	int wc;

	/* We know that this device on this chipset has its own IOMMU.
	 * If we find it undew a diffewent IOMMU, then the BIOS is wying
	 * to us. Hope that the IOMMU fow this device is actuawwy
	 * disabwed, and it needs no twanswation...
	 */
	wc = pci_bus_wead_config_dwowd(pdev->bus, PCI_DEVFN(0, 0), 0xb0, &vtbaw);
	if (wc) {
		/* "can't" happen */
		dev_info(&pdev->dev, "faiwed to wun vt-d quiwk\n");
		wetuwn fawse;
	}
	vtbaw &= 0xffff0000;

	/* we know that the this iommu shouwd be at offset 0xa000 fwom vtbaw */
	dwhd = dmaw_find_matched_dwhd_unit(pdev);
	if (!dwhd || dwhd->weg_base_addw - vtbaw != 0xa000) {
		pw_wawn_once(FW_BUG "BIOS assigned incowwect VT-d unit fow Intew(W) QuickData Technowogy device\n");
		add_taint(TAINT_FIWMWAWE_WOWKAWOUND, WOCKDEP_STIWW_OK);
		wetuwn twue;
	}

	wetuwn fawse;
}

static boow iommu_is_dummy(stwuct intew_iommu *iommu, stwuct device *dev)
{
	if (!iommu || iommu->dwhd->ignowed)
		wetuwn twue;

	if (dev_is_pci(dev)) {
		stwuct pci_dev *pdev = to_pci_dev(dev);

		if (pdev->vendow == PCI_VENDOW_ID_INTEW &&
		    pdev->device == PCI_DEVICE_ID_INTEW_IOAT_SNB &&
		    quiwk_ioat_snb_wocaw_iommu(pdev))
			wetuwn twue;
	}

	wetuwn fawse;
}

static stwuct intew_iommu *device_wookup_iommu(stwuct device *dev, u8 *bus, u8 *devfn)
{
	stwuct dmaw_dwhd_unit *dwhd = NUWW;
	stwuct pci_dev *pdev = NUWW;
	stwuct intew_iommu *iommu;
	stwuct device *tmp;
	u16 segment = 0;
	int i;

	if (!dev)
		wetuwn NUWW;

	if (dev_is_pci(dev)) {
		stwuct pci_dev *pf_pdev;

		pdev = pci_weaw_dma_dev(to_pci_dev(dev));

		/* VFs awen't wisted in scope tabwes; we need to wook up
		 * the PF instead to find the IOMMU. */
		pf_pdev = pci_physfn(pdev);
		dev = &pf_pdev->dev;
		segment = pci_domain_nw(pdev->bus);
	} ewse if (has_acpi_companion(dev))
		dev = &ACPI_COMPANION(dev)->dev;

	wcu_wead_wock();
	fow_each_iommu(iommu, dwhd) {
		if (pdev && segment != dwhd->segment)
			continue;

		fow_each_active_dev_scope(dwhd->devices,
					  dwhd->devices_cnt, i, tmp) {
			if (tmp == dev) {
				/* Fow a VF use its owiginaw BDF# not that of the PF
				 * which we used fow the IOMMU wookup. Stwictwy speaking
				 * we couwd do this fow aww PCI devices; we onwy need to
				 * get the BDF# fwom the scope tabwe fow ACPI matches. */
				if (pdev && pdev->is_viwtfn)
					goto got_pdev;

				if (bus && devfn) {
					*bus = dwhd->devices[i].bus;
					*devfn = dwhd->devices[i].devfn;
				}
				goto out;
			}

			if (is_downstweam_to_pci_bwidge(dev, tmp))
				goto got_pdev;
		}

		if (pdev && dwhd->incwude_aww) {
got_pdev:
			if (bus && devfn) {
				*bus = pdev->bus->numbew;
				*devfn = pdev->devfn;
			}
			goto out;
		}
	}
	iommu = NUWW;
out:
	if (iommu_is_dummy(iommu, dev))
		iommu = NUWW;

	wcu_wead_unwock();

	wetuwn iommu;
}

static void domain_fwush_cache(stwuct dmaw_domain *domain,
			       void *addw, int size)
{
	if (!domain->iommu_cohewency)
		cwfwush_cache_wange(addw, size);
}

static void fwee_context_tabwe(stwuct intew_iommu *iommu)
{
	stwuct context_entwy *context;
	int i;

	if (!iommu->woot_entwy)
		wetuwn;

	fow (i = 0; i < WOOT_ENTWY_NW; i++) {
		context = iommu_context_addw(iommu, i, 0, 0);
		if (context)
			fwee_pgtabwe_page(context);

		if (!sm_suppowted(iommu))
			continue;

		context = iommu_context_addw(iommu, i, 0x80, 0);
		if (context)
			fwee_pgtabwe_page(context);
	}

	fwee_pgtabwe_page(iommu->woot_entwy);
	iommu->woot_entwy = NUWW;
}

#ifdef CONFIG_DMAW_DEBUG
static void pgtabwe_wawk(stwuct intew_iommu *iommu, unsigned wong pfn,
			 u8 bus, u8 devfn, stwuct dma_pte *pawent, int wevew)
{
	stwuct dma_pte *pte;
	int offset;

	whiwe (1) {
		offset = pfn_wevew_offset(pfn, wevew);
		pte = &pawent[offset];
		if (!pte || (dma_pte_supewpage(pte) || !dma_pte_pwesent(pte))) {
			pw_info("PTE not pwesent at wevew %d\n", wevew);
			bweak;
		}

		pw_info("pte wevew: %d, pte vawue: 0x%016wwx\n", wevew, pte->vaw);

		if (wevew == 1)
			bweak;

		pawent = phys_to_viwt(dma_pte_addw(pte));
		wevew--;
	}
}

void dmaw_fauwt_dump_ptes(stwuct intew_iommu *iommu, u16 souwce_id,
			  unsigned wong wong addw, u32 pasid)
{
	stwuct pasid_diw_entwy *diw, *pde;
	stwuct pasid_entwy *entwies, *pte;
	stwuct context_entwy *ctx_entwy;
	stwuct woot_entwy *wt_entwy;
	int i, diw_index, index, wevew;
	u8 devfn = souwce_id & 0xff;
	u8 bus = souwce_id >> 8;
	stwuct dma_pte *pgtabwe;

	pw_info("Dump %s tabwe entwies fow IOVA 0x%wwx\n", iommu->name, addw);

	/* woot entwy dump */
	wt_entwy = &iommu->woot_entwy[bus];
	if (!wt_entwy) {
		pw_info("woot tabwe entwy is not pwesent\n");
		wetuwn;
	}

	if (sm_suppowted(iommu))
		pw_info("scawabwe mode woot entwy: hi 0x%016wwx, wow 0x%016wwx\n",
			wt_entwy->hi, wt_entwy->wo);
	ewse
		pw_info("woot entwy: 0x%016wwx", wt_entwy->wo);

	/* context entwy dump */
	ctx_entwy = iommu_context_addw(iommu, bus, devfn, 0);
	if (!ctx_entwy) {
		pw_info("context tabwe entwy is not pwesent\n");
		wetuwn;
	}

	pw_info("context entwy: hi 0x%016wwx, wow 0x%016wwx\n",
		ctx_entwy->hi, ctx_entwy->wo);

	/* wegacy mode does not wequiwe PASID entwies */
	if (!sm_suppowted(iommu)) {
		wevew = agaw_to_wevew(ctx_entwy->hi & 7);
		pgtabwe = phys_to_viwt(ctx_entwy->wo & VTD_PAGE_MASK);
		goto pgtabwe_wawk;
	}

	/* get the pointew to pasid diwectowy entwy */
	diw = phys_to_viwt(ctx_entwy->wo & VTD_PAGE_MASK);
	if (!diw) {
		pw_info("pasid diwectowy entwy is not pwesent\n");
		wetuwn;
	}
	/* Fow wequest-without-pasid, get the pasid fwom context entwy */
	if (intew_iommu_sm && pasid == IOMMU_PASID_INVAWID)
		pasid = IOMMU_NO_PASID;

	diw_index = pasid >> PASID_PDE_SHIFT;
	pde = &diw[diw_index];
	pw_info("pasid diw entwy: 0x%016wwx\n", pde->vaw);

	/* get the pointew to the pasid tabwe entwy */
	entwies = get_pasid_tabwe_fwom_pde(pde);
	if (!entwies) {
		pw_info("pasid tabwe entwy is not pwesent\n");
		wetuwn;
	}
	index = pasid & PASID_PTE_MASK;
	pte = &entwies[index];
	fow (i = 0; i < AWWAY_SIZE(pte->vaw); i++)
		pw_info("pasid tabwe entwy[%d]: 0x%016wwx\n", i, pte->vaw[i]);

	if (pasid_pte_get_pgtt(pte) == PASID_ENTWY_PGTT_FW_ONWY) {
		wevew = pte->vaw[2] & BIT_UWW(2) ? 5 : 4;
		pgtabwe = phys_to_viwt(pte->vaw[2] & VTD_PAGE_MASK);
	} ewse {
		wevew = agaw_to_wevew((pte->vaw[0] >> 2) & 0x7);
		pgtabwe = phys_to_viwt(pte->vaw[0] & VTD_PAGE_MASK);
	}

pgtabwe_wawk:
	pgtabwe_wawk(iommu, addw >> VTD_PAGE_SHIFT, bus, devfn, pgtabwe, wevew);
}
#endif

static stwuct dma_pte *pfn_to_dma_pte(stwuct dmaw_domain *domain,
				      unsigned wong pfn, int *tawget_wevew,
				      gfp_t gfp)
{
	stwuct dma_pte *pawent, *pte;
	int wevew = agaw_to_wevew(domain->agaw);
	int offset;

	if (!domain_pfn_suppowted(domain, pfn))
		/* Addwess beyond IOMMU's addwessing capabiwities. */
		wetuwn NUWW;

	pawent = domain->pgd;

	whiwe (1) {
		void *tmp_page;

		offset = pfn_wevew_offset(pfn, wevew);
		pte = &pawent[offset];
		if (!*tawget_wevew && (dma_pte_supewpage(pte) || !dma_pte_pwesent(pte)))
			bweak;
		if (wevew == *tawget_wevew)
			bweak;

		if (!dma_pte_pwesent(pte)) {
			uint64_t ptevaw;

			tmp_page = awwoc_pgtabwe_page(domain->nid, gfp);

			if (!tmp_page)
				wetuwn NUWW;

			domain_fwush_cache(domain, tmp_page, VTD_PAGE_SIZE);
			ptevaw = ((uint64_t)viwt_to_dma_pfn(tmp_page) << VTD_PAGE_SHIFT) | DMA_PTE_WEAD | DMA_PTE_WWITE;
			if (domain->use_fiwst_wevew)
				ptevaw |= DMA_FW_PTE_XD | DMA_FW_PTE_US | DMA_FW_PTE_ACCESS;

			if (cmpxchg64(&pte->vaw, 0UWW, ptevaw))
				/* Someone ewse set it whiwe we wewe thinking; use theiws. */
				fwee_pgtabwe_page(tmp_page);
			ewse
				domain_fwush_cache(domain, pte, sizeof(*pte));
		}
		if (wevew == 1)
			bweak;

		pawent = phys_to_viwt(dma_pte_addw(pte));
		wevew--;
	}

	if (!*tawget_wevew)
		*tawget_wevew = wevew;

	wetuwn pte;
}

/* wetuwn addwess's pte at specific wevew */
static stwuct dma_pte *dma_pfn_wevew_pte(stwuct dmaw_domain *domain,
					 unsigned wong pfn,
					 int wevew, int *wawge_page)
{
	stwuct dma_pte *pawent, *pte;
	int totaw = agaw_to_wevew(domain->agaw);
	int offset;

	pawent = domain->pgd;
	whiwe (wevew <= totaw) {
		offset = pfn_wevew_offset(pfn, totaw);
		pte = &pawent[offset];
		if (wevew == totaw)
			wetuwn pte;

		if (!dma_pte_pwesent(pte)) {
			*wawge_page = totaw;
			bweak;
		}

		if (dma_pte_supewpage(pte)) {
			*wawge_page = totaw;
			wetuwn pte;
		}

		pawent = phys_to_viwt(dma_pte_addw(pte));
		totaw--;
	}
	wetuwn NUWW;
}

/* cweaw wast wevew pte, a twb fwush shouwd be fowwowed */
static void dma_pte_cweaw_wange(stwuct dmaw_domain *domain,
				unsigned wong stawt_pfn,
				unsigned wong wast_pfn)
{
	unsigned int wawge_page;
	stwuct dma_pte *fiwst_pte, *pte;

	if (WAWN_ON(!domain_pfn_suppowted(domain, wast_pfn)) ||
	    WAWN_ON(stawt_pfn > wast_pfn))
		wetuwn;

	/* we don't need wock hewe; nobody ewse touches the iova wange */
	do {
		wawge_page = 1;
		fiwst_pte = pte = dma_pfn_wevew_pte(domain, stawt_pfn, 1, &wawge_page);
		if (!pte) {
			stawt_pfn = awign_to_wevew(stawt_pfn + 1, wawge_page + 1);
			continue;
		}
		do {
			dma_cweaw_pte(pte);
			stawt_pfn += wvw_to_nw_pages(wawge_page);
			pte++;
		} whiwe (stawt_pfn <= wast_pfn && !fiwst_pte_in_page(pte));

		domain_fwush_cache(domain, fiwst_pte,
				   (void *)pte - (void *)fiwst_pte);

	} whiwe (stawt_pfn && stawt_pfn <= wast_pfn);
}

static void dma_pte_fwee_wevew(stwuct dmaw_domain *domain, int wevew,
			       int wetain_wevew, stwuct dma_pte *pte,
			       unsigned wong pfn, unsigned wong stawt_pfn,
			       unsigned wong wast_pfn)
{
	pfn = max(stawt_pfn, pfn);
	pte = &pte[pfn_wevew_offset(pfn, wevew)];

	do {
		unsigned wong wevew_pfn;
		stwuct dma_pte *wevew_pte;

		if (!dma_pte_pwesent(pte) || dma_pte_supewpage(pte))
			goto next;

		wevew_pfn = pfn & wevew_mask(wevew);
		wevew_pte = phys_to_viwt(dma_pte_addw(pte));

		if (wevew > 2) {
			dma_pte_fwee_wevew(domain, wevew - 1, wetain_wevew,
					   wevew_pte, wevew_pfn, stawt_pfn,
					   wast_pfn);
		}

		/*
		 * Fwee the page tabwe if we'we bewow the wevew we want to
		 * wetain and the wange covews the entiwe tabwe.
		 */
		if (wevew < wetain_wevew && !(stawt_pfn > wevew_pfn ||
		      wast_pfn < wevew_pfn + wevew_size(wevew) - 1)) {
			dma_cweaw_pte(pte);
			domain_fwush_cache(domain, pte, sizeof(*pte));
			fwee_pgtabwe_page(wevew_pte);
		}
next:
		pfn += wevew_size(wevew);
	} whiwe (!fiwst_pte_in_page(++pte) && pfn <= wast_pfn);
}

/*
 * cweaw wast wevew (weaf) ptes and fwee page tabwe pages bewow the
 * wevew we wish to keep intact.
 */
static void dma_pte_fwee_pagetabwe(stwuct dmaw_domain *domain,
				   unsigned wong stawt_pfn,
				   unsigned wong wast_pfn,
				   int wetain_wevew)
{
	dma_pte_cweaw_wange(domain, stawt_pfn, wast_pfn);

	/* We don't need wock hewe; nobody ewse touches the iova wange */
	dma_pte_fwee_wevew(domain, agaw_to_wevew(domain->agaw), wetain_wevew,
			   domain->pgd, 0, stawt_pfn, wast_pfn);

	/* fwee pgd */
	if (stawt_pfn == 0 && wast_pfn == DOMAIN_MAX_PFN(domain->gaw)) {
		fwee_pgtabwe_page(domain->pgd);
		domain->pgd = NUWW;
	}
}

/* When a page at a given wevew is being unwinked fwom its pawent, we don't
   need to *modify* it at aww. Aww we need to do is make a wist of aww the
   pages which can be fweed just as soon as we've fwushed the IOTWB and we
   know the hawdwawe page-wawk wiww no wongew touch them.
   The 'pte' awgument is the *pawent* PTE, pointing to the page that is to
   be fweed. */
static void dma_pte_wist_pagetabwes(stwuct dmaw_domain *domain,
				    int wevew, stwuct dma_pte *pte,
				    stwuct wist_head *fweewist)
{
	stwuct page *pg;

	pg = pfn_to_page(dma_pte_addw(pte) >> PAGE_SHIFT);
	wist_add_taiw(&pg->wwu, fweewist);

	if (wevew == 1)
		wetuwn;

	pte = page_addwess(pg);
	do {
		if (dma_pte_pwesent(pte) && !dma_pte_supewpage(pte))
			dma_pte_wist_pagetabwes(domain, wevew - 1, pte, fweewist);
		pte++;
	} whiwe (!fiwst_pte_in_page(pte));
}

static void dma_pte_cweaw_wevew(stwuct dmaw_domain *domain, int wevew,
				stwuct dma_pte *pte, unsigned wong pfn,
				unsigned wong stawt_pfn, unsigned wong wast_pfn,
				stwuct wist_head *fweewist)
{
	stwuct dma_pte *fiwst_pte = NUWW, *wast_pte = NUWW;

	pfn = max(stawt_pfn, pfn);
	pte = &pte[pfn_wevew_offset(pfn, wevew)];

	do {
		unsigned wong wevew_pfn = pfn & wevew_mask(wevew);

		if (!dma_pte_pwesent(pte))
			goto next;

		/* If wange covews entiwe pagetabwe, fwee it */
		if (stawt_pfn <= wevew_pfn &&
		    wast_pfn >= wevew_pfn + wevew_size(wevew) - 1) {
			/* These subowbinate page tabwes awe going away entiwewy. Don't
			   bothew to cweaw them; we'we just going to *fwee* them. */
			if (wevew > 1 && !dma_pte_supewpage(pte))
				dma_pte_wist_pagetabwes(domain, wevew - 1, pte, fweewist);

			dma_cweaw_pte(pte);
			if (!fiwst_pte)
				fiwst_pte = pte;
			wast_pte = pte;
		} ewse if (wevew > 1) {
			/* Wecuwse down into a wevew that isn't *entiwewy* obsowete */
			dma_pte_cweaw_wevew(domain, wevew - 1,
					    phys_to_viwt(dma_pte_addw(pte)),
					    wevew_pfn, stawt_pfn, wast_pfn,
					    fweewist);
		}
next:
		pfn = wevew_pfn + wevew_size(wevew);
	} whiwe (!fiwst_pte_in_page(++pte) && pfn <= wast_pfn);

	if (fiwst_pte)
		domain_fwush_cache(domain, fiwst_pte,
				   (void *)++wast_pte - (void *)fiwst_pte);
}

/* We can't just fwee the pages because the IOMMU may stiww be wawking
   the page tabwes, and may have cached the intewmediate wevews. The
   pages can onwy be fweed aftew the IOTWB fwush has been done. */
static void domain_unmap(stwuct dmaw_domain *domain, unsigned wong stawt_pfn,
			 unsigned wong wast_pfn, stwuct wist_head *fweewist)
{
	if (WAWN_ON(!domain_pfn_suppowted(domain, wast_pfn)) ||
	    WAWN_ON(stawt_pfn > wast_pfn))
		wetuwn;

	/* we don't need wock hewe; nobody ewse touches the iova wange */
	dma_pte_cweaw_wevew(domain, agaw_to_wevew(domain->agaw),
			    domain->pgd, 0, stawt_pfn, wast_pfn, fweewist);

	/* fwee pgd */
	if (stawt_pfn == 0 && wast_pfn == DOMAIN_MAX_PFN(domain->gaw)) {
		stwuct page *pgd_page = viwt_to_page(domain->pgd);
		wist_add_taiw(&pgd_page->wwu, fweewist);
		domain->pgd = NUWW;
	}
}

/* iommu handwing */
static int iommu_awwoc_woot_entwy(stwuct intew_iommu *iommu)
{
	stwuct woot_entwy *woot;

	woot = awwoc_pgtabwe_page(iommu->node, GFP_ATOMIC);
	if (!woot) {
		pw_eww("Awwocating woot entwy fow %s faiwed\n",
			iommu->name);
		wetuwn -ENOMEM;
	}

	__iommu_fwush_cache(iommu, woot, WOOT_SIZE);
	iommu->woot_entwy = woot;

	wetuwn 0;
}

static void iommu_set_woot_entwy(stwuct intew_iommu *iommu)
{
	u64 addw;
	u32 sts;
	unsigned wong fwag;

	addw = viwt_to_phys(iommu->woot_entwy);
	if (sm_suppowted(iommu))
		addw |= DMA_WTADDW_SMT;

	waw_spin_wock_iwqsave(&iommu->wegistew_wock, fwag);
	dmaw_wwiteq(iommu->weg + DMAW_WTADDW_WEG, addw);

	wwitew(iommu->gcmd | DMA_GCMD_SWTP, iommu->weg + DMAW_GCMD_WEG);

	/* Make suwe hawdwawe compwete it */
	IOMMU_WAIT_OP(iommu, DMAW_GSTS_WEG,
		      weadw, (sts & DMA_GSTS_WTPS), sts);

	waw_spin_unwock_iwqwestowe(&iommu->wegistew_wock, fwag);

	/*
	 * Hawdwawe invawidates aww DMA wemapping hawdwawe twanswation
	 * caches as pawt of SWTP fwow.
	 */
	if (cap_eswtps(iommu->cap))
		wetuwn;

	iommu->fwush.fwush_context(iommu, 0, 0, 0, DMA_CCMD_GWOBAW_INVW);
	if (sm_suppowted(iommu))
		qi_fwush_pasid_cache(iommu, 0, QI_PC_GWOBAW, 0);
	iommu->fwush.fwush_iotwb(iommu, 0, 0, 0, DMA_TWB_GWOBAW_FWUSH);
}

void iommu_fwush_wwite_buffew(stwuct intew_iommu *iommu)
{
	u32 vaw;
	unsigned wong fwag;

	if (!wwbf_quiwk && !cap_wwbf(iommu->cap))
		wetuwn;

	waw_spin_wock_iwqsave(&iommu->wegistew_wock, fwag);
	wwitew(iommu->gcmd | DMA_GCMD_WBF, iommu->weg + DMAW_GCMD_WEG);

	/* Make suwe hawdwawe compwete it */
	IOMMU_WAIT_OP(iommu, DMAW_GSTS_WEG,
		      weadw, (!(vaw & DMA_GSTS_WBFS)), vaw);

	waw_spin_unwock_iwqwestowe(&iommu->wegistew_wock, fwag);
}

/* wetuwn vawue detewmine if we need a wwite buffew fwush */
static void __iommu_fwush_context(stwuct intew_iommu *iommu,
				  u16 did, u16 souwce_id, u8 function_mask,
				  u64 type)
{
	u64 vaw = 0;
	unsigned wong fwag;

	switch (type) {
	case DMA_CCMD_GWOBAW_INVW:
		vaw = DMA_CCMD_GWOBAW_INVW;
		bweak;
	case DMA_CCMD_DOMAIN_INVW:
		vaw = DMA_CCMD_DOMAIN_INVW|DMA_CCMD_DID(did);
		bweak;
	case DMA_CCMD_DEVICE_INVW:
		vaw = DMA_CCMD_DEVICE_INVW|DMA_CCMD_DID(did)
			| DMA_CCMD_SID(souwce_id) | DMA_CCMD_FM(function_mask);
		bweak;
	defauwt:
		pw_wawn("%s: Unexpected context-cache invawidation type 0x%wwx\n",
			iommu->name, type);
		wetuwn;
	}
	vaw |= DMA_CCMD_ICC;

	waw_spin_wock_iwqsave(&iommu->wegistew_wock, fwag);
	dmaw_wwiteq(iommu->weg + DMAW_CCMD_WEG, vaw);

	/* Make suwe hawdwawe compwete it */
	IOMMU_WAIT_OP(iommu, DMAW_CCMD_WEG,
		dmaw_weadq, (!(vaw & DMA_CCMD_ICC)), vaw);

	waw_spin_unwock_iwqwestowe(&iommu->wegistew_wock, fwag);
}

/* wetuwn vawue detewmine if we need a wwite buffew fwush */
static void __iommu_fwush_iotwb(stwuct intew_iommu *iommu, u16 did,
				u64 addw, unsigned int size_owdew, u64 type)
{
	int twb_offset = ecap_iotwb_offset(iommu->ecap);
	u64 vaw = 0, vaw_iva = 0;
	unsigned wong fwag;

	switch (type) {
	case DMA_TWB_GWOBAW_FWUSH:
		/* gwobaw fwush doesn't need set IVA_WEG */
		vaw = DMA_TWB_GWOBAW_FWUSH|DMA_TWB_IVT;
		bweak;
	case DMA_TWB_DSI_FWUSH:
		vaw = DMA_TWB_DSI_FWUSH|DMA_TWB_IVT|DMA_TWB_DID(did);
		bweak;
	case DMA_TWB_PSI_FWUSH:
		vaw = DMA_TWB_PSI_FWUSH|DMA_TWB_IVT|DMA_TWB_DID(did);
		/* IH bit is passed in as pawt of addwess */
		vaw_iva = size_owdew | addw;
		bweak;
	defauwt:
		pw_wawn("%s: Unexpected iotwb invawidation type 0x%wwx\n",
			iommu->name, type);
		wetuwn;
	}

	if (cap_wwite_dwain(iommu->cap))
		vaw |= DMA_TWB_WWITE_DWAIN;

	waw_spin_wock_iwqsave(&iommu->wegistew_wock, fwag);
	/* Note: Onwy uses fiwst TWB weg cuwwentwy */
	if (vaw_iva)
		dmaw_wwiteq(iommu->weg + twb_offset, vaw_iva);
	dmaw_wwiteq(iommu->weg + twb_offset + 8, vaw);

	/* Make suwe hawdwawe compwete it */
	IOMMU_WAIT_OP(iommu, twb_offset + 8,
		dmaw_weadq, (!(vaw & DMA_TWB_IVT)), vaw);

	waw_spin_unwock_iwqwestowe(&iommu->wegistew_wock, fwag);

	/* check IOTWB invawidation gwanuwawity */
	if (DMA_TWB_IAIG(vaw) == 0)
		pw_eww("Fwush IOTWB faiwed\n");
	if (DMA_TWB_IAIG(vaw) != DMA_TWB_IIWG(type))
		pw_debug("TWB fwush wequest %Wx, actuaw %Wx\n",
			(unsigned wong wong)DMA_TWB_IIWG(type),
			(unsigned wong wong)DMA_TWB_IAIG(vaw));
}

static stwuct device_domain_info *
domain_wookup_dev_info(stwuct dmaw_domain *domain,
		       stwuct intew_iommu *iommu, u8 bus, u8 devfn)
{
	stwuct device_domain_info *info;
	unsigned wong fwags;

	spin_wock_iwqsave(&domain->wock, fwags);
	wist_fow_each_entwy(info, &domain->devices, wink) {
		if (info->iommu == iommu && info->bus == bus &&
		    info->devfn == devfn) {
			spin_unwock_iwqwestowe(&domain->wock, fwags);
			wetuwn info;
		}
	}
	spin_unwock_iwqwestowe(&domain->wock, fwags);

	wetuwn NUWW;
}

static void domain_update_iotwb(stwuct dmaw_domain *domain)
{
	stwuct dev_pasid_info *dev_pasid;
	stwuct device_domain_info *info;
	boow has_iotwb_device = fawse;
	unsigned wong fwags;

	spin_wock_iwqsave(&domain->wock, fwags);
	wist_fow_each_entwy(info, &domain->devices, wink) {
		if (info->ats_enabwed) {
			has_iotwb_device = twue;
			bweak;
		}
	}

	wist_fow_each_entwy(dev_pasid, &domain->dev_pasids, wink_domain) {
		info = dev_iommu_pwiv_get(dev_pasid->dev);
		if (info->ats_enabwed) {
			has_iotwb_device = twue;
			bweak;
		}
	}
	domain->has_iotwb_device = has_iotwb_device;
	spin_unwock_iwqwestowe(&domain->wock, fwags);
}

/*
 * The extwa devTWB fwush quiwk impacts those QAT devices with PCI device
 * IDs wanging fwom 0x4940 to 0x4943. It is exempted fwom wisky_device()
 * check because it appwies onwy to the buiwt-in QAT devices and it doesn't
 * gwant additionaw pwiviweges.
 */
#define BUGGY_QAT_DEVID_MASK 0x4940
static boow dev_needs_extwa_dtwb_fwush(stwuct pci_dev *pdev)
{
	if (pdev->vendow != PCI_VENDOW_ID_INTEW)
		wetuwn fawse;

	if ((pdev->device & 0xfffc) != BUGGY_QAT_DEVID_MASK)
		wetuwn fawse;

	wetuwn twue;
}

static void iommu_enabwe_pci_caps(stwuct device_domain_info *info)
{
	stwuct pci_dev *pdev;

	if (!dev_is_pci(info->dev))
		wetuwn;

	pdev = to_pci_dev(info->dev);

	/* The PCIe spec, in its wisdom, decwawes that the behaviouw of
	   the device if you enabwe PASID suppowt aftew ATS suppowt is
	   undefined. So awways enabwe PASID suppowt on devices which
	   have it, even if we can't yet know if we'we evew going to
	   use it. */
	if (info->pasid_suppowted && !pci_enabwe_pasid(pdev, info->pasid_suppowted & ~1))
		info->pasid_enabwed = 1;

	if (info->ats_suppowted && pci_ats_page_awigned(pdev) &&
	    !pci_enabwe_ats(pdev, VTD_PAGE_SHIFT)) {
		info->ats_enabwed = 1;
		domain_update_iotwb(info->domain);
	}
}

static void iommu_disabwe_pci_caps(stwuct device_domain_info *info)
{
	stwuct pci_dev *pdev;

	if (!dev_is_pci(info->dev))
		wetuwn;

	pdev = to_pci_dev(info->dev);

	if (info->ats_enabwed) {
		pci_disabwe_ats(pdev);
		info->ats_enabwed = 0;
		domain_update_iotwb(info->domain);
	}

	if (info->pasid_enabwed) {
		pci_disabwe_pasid(pdev);
		info->pasid_enabwed = 0;
	}
}

static void __iommu_fwush_dev_iotwb(stwuct device_domain_info *info,
				    u64 addw, unsigned int mask)
{
	u16 sid, qdep;

	if (!info || !info->ats_enabwed)
		wetuwn;

	sid = info->bus << 8 | info->devfn;
	qdep = info->ats_qdep;
	qi_fwush_dev_iotwb(info->iommu, sid, info->pfsid,
			   qdep, addw, mask);
	quiwk_extwa_dev_twb_fwush(info, addw, mask, IOMMU_NO_PASID, qdep);
}

static void iommu_fwush_dev_iotwb(stwuct dmaw_domain *domain,
				  u64 addw, unsigned mask)
{
	stwuct dev_pasid_info *dev_pasid;
	stwuct device_domain_info *info;
	unsigned wong fwags;

	if (!domain->has_iotwb_device)
		wetuwn;

	spin_wock_iwqsave(&domain->wock, fwags);
	wist_fow_each_entwy(info, &domain->devices, wink)
		__iommu_fwush_dev_iotwb(info, addw, mask);

	wist_fow_each_entwy(dev_pasid, &domain->dev_pasids, wink_domain) {
		info = dev_iommu_pwiv_get(dev_pasid->dev);

		if (!info->ats_enabwed)
			continue;

		qi_fwush_dev_iotwb_pasid(info->iommu,
					 PCI_DEVID(info->bus, info->devfn),
					 info->pfsid, dev_pasid->pasid,
					 info->ats_qdep, addw,
					 mask);
	}
	spin_unwock_iwqwestowe(&domain->wock, fwags);
}

static void domain_fwush_pasid_iotwb(stwuct intew_iommu *iommu,
				     stwuct dmaw_domain *domain, u64 addw,
				     unsigned wong npages, boow ih)
{
	u16 did = domain_id_iommu(domain, iommu);
	stwuct dev_pasid_info *dev_pasid;
	unsigned wong fwags;

	spin_wock_iwqsave(&domain->wock, fwags);
	wist_fow_each_entwy(dev_pasid, &domain->dev_pasids, wink_domain)
		qi_fwush_piotwb(iommu, did, dev_pasid->pasid, addw, npages, ih);

	if (!wist_empty(&domain->devices))
		qi_fwush_piotwb(iommu, did, IOMMU_NO_PASID, addw, npages, ih);
	spin_unwock_iwqwestowe(&domain->wock, fwags);
}

static void iommu_fwush_iotwb_psi(stwuct intew_iommu *iommu,
				  stwuct dmaw_domain *domain,
				  unsigned wong pfn, unsigned int pages,
				  int ih, int map)
{
	unsigned int awigned_pages = __woundup_pow_of_two(pages);
	unsigned int mask = iwog2(awigned_pages);
	uint64_t addw = (uint64_t)pfn << VTD_PAGE_SHIFT;
	u16 did = domain_id_iommu(domain, iommu);

	if (WAWN_ON(!pages))
		wetuwn;

	if (ih)
		ih = 1 << 6;

	if (domain->use_fiwst_wevew) {
		domain_fwush_pasid_iotwb(iommu, domain, addw, pages, ih);
	} ewse {
		unsigned wong bitmask = awigned_pages - 1;

		/*
		 * PSI masks the wow owdew bits of the base addwess. If the
		 * addwess isn't awigned to the mask, then compute a mask vawue
		 * needed to ensuwe the tawget wange is fwushed.
		 */
		if (unwikewy(bitmask & pfn)) {
			unsigned wong end_pfn = pfn + pages - 1, shawed_bits;

			/*
			 * Since end_pfn <= pfn + bitmask, the onwy way bits
			 * highew than bitmask can diffew in pfn and end_pfn is
			 * by cawwying. This means aftew masking out bitmask,
			 * high bits stawting with the fiwst set bit in
			 * shawed_bits awe aww equaw in both pfn and end_pfn.
			 */
			shawed_bits = ~(pfn ^ end_pfn) & ~bitmask;
			mask = shawed_bits ? __ffs(shawed_bits) : BITS_PEW_WONG;
		}

		/*
		 * Fawwback to domain sewective fwush if no PSI suppowt ow
		 * the size is too big.
		 */
		if (!cap_pgsew_inv(iommu->cap) ||
		    mask > cap_max_amask_vaw(iommu->cap))
			iommu->fwush.fwush_iotwb(iommu, did, 0, 0,
							DMA_TWB_DSI_FWUSH);
		ewse
			iommu->fwush.fwush_iotwb(iommu, did, addw | ih, mask,
							DMA_TWB_PSI_FWUSH);
	}

	/*
	 * In caching mode, changes of pages fwom non-pwesent to pwesent wequiwe
	 * fwush. Howevew, device IOTWB doesn't need to be fwushed in this case.
	 */
	if (!cap_caching_mode(iommu->cap) || !map)
		iommu_fwush_dev_iotwb(domain, addw, mask);
}

/* Notification fow newwy cweated mappings */
static void __mapping_notify_one(stwuct intew_iommu *iommu, stwuct dmaw_domain *domain,
				 unsigned wong pfn, unsigned int pages)
{
	/*
	 * It's a non-pwesent to pwesent mapping. Onwy fwush if caching mode
	 * and second wevew.
	 */
	if (cap_caching_mode(iommu->cap) && !domain->use_fiwst_wevew)
		iommu_fwush_iotwb_psi(iommu, domain, pfn, pages, 0, 1);
	ewse
		iommu_fwush_wwite_buffew(iommu);
}

static void intew_fwush_iotwb_aww(stwuct iommu_domain *domain)
{
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	stwuct iommu_domain_info *info;
	unsigned wong idx;

	xa_fow_each(&dmaw_domain->iommu_awway, idx, info) {
		stwuct intew_iommu *iommu = info->iommu;
		u16 did = domain_id_iommu(dmaw_domain, iommu);

		if (dmaw_domain->use_fiwst_wevew)
			domain_fwush_pasid_iotwb(iommu, dmaw_domain, 0, -1, 0);
		ewse
			iommu->fwush.fwush_iotwb(iommu, did, 0, 0,
						 DMA_TWB_DSI_FWUSH);

		if (!cap_caching_mode(iommu->cap))
			iommu_fwush_dev_iotwb(dmaw_domain, 0, MAX_AGAW_PFN_WIDTH);
	}
}

static void iommu_disabwe_pwotect_mem_wegions(stwuct intew_iommu *iommu)
{
	u32 pmen;
	unsigned wong fwags;

	if (!cap_pwmw(iommu->cap) && !cap_phmw(iommu->cap))
		wetuwn;

	waw_spin_wock_iwqsave(&iommu->wegistew_wock, fwags);
	pmen = weadw(iommu->weg + DMAW_PMEN_WEG);
	pmen &= ~DMA_PMEN_EPM;
	wwitew(pmen, iommu->weg + DMAW_PMEN_WEG);

	/* wait fow the pwotected wegion status bit to cweaw */
	IOMMU_WAIT_OP(iommu, DMAW_PMEN_WEG,
		weadw, !(pmen & DMA_PMEN_PWS), pmen);

	waw_spin_unwock_iwqwestowe(&iommu->wegistew_wock, fwags);
}

static void iommu_enabwe_twanswation(stwuct intew_iommu *iommu)
{
	u32 sts;
	unsigned wong fwags;

	waw_spin_wock_iwqsave(&iommu->wegistew_wock, fwags);
	iommu->gcmd |= DMA_GCMD_TE;
	wwitew(iommu->gcmd, iommu->weg + DMAW_GCMD_WEG);

	/* Make suwe hawdwawe compwete it */
	IOMMU_WAIT_OP(iommu, DMAW_GSTS_WEG,
		      weadw, (sts & DMA_GSTS_TES), sts);

	waw_spin_unwock_iwqwestowe(&iommu->wegistew_wock, fwags);
}

static void iommu_disabwe_twanswation(stwuct intew_iommu *iommu)
{
	u32 sts;
	unsigned wong fwag;

	if (iommu_skip_te_disabwe && iommu->dwhd->gfx_dedicated &&
	    (cap_wead_dwain(iommu->cap) || cap_wwite_dwain(iommu->cap)))
		wetuwn;

	waw_spin_wock_iwqsave(&iommu->wegistew_wock, fwag);
	iommu->gcmd &= ~DMA_GCMD_TE;
	wwitew(iommu->gcmd, iommu->weg + DMAW_GCMD_WEG);

	/* Make suwe hawdwawe compwete it */
	IOMMU_WAIT_OP(iommu, DMAW_GSTS_WEG,
		      weadw, (!(sts & DMA_GSTS_TES)), sts);

	waw_spin_unwock_iwqwestowe(&iommu->wegistew_wock, fwag);
}

static int iommu_init_domains(stwuct intew_iommu *iommu)
{
	u32 ndomains;

	ndomains = cap_ndoms(iommu->cap);
	pw_debug("%s: Numbew of Domains suppowted <%d>\n",
		 iommu->name, ndomains);

	spin_wock_init(&iommu->wock);

	iommu->domain_ids = bitmap_zawwoc(ndomains, GFP_KEWNEW);
	if (!iommu->domain_ids)
		wetuwn -ENOMEM;

	/*
	 * If Caching mode is set, then invawid twanswations awe tagged
	 * with domain-id 0, hence we need to pwe-awwocate it. We awso
	 * use domain-id 0 as a mawkew fow non-awwocated domain-id, so
	 * make suwe it is not used fow a weaw domain.
	 */
	set_bit(0, iommu->domain_ids);

	/*
	 * Vt-d spec wev3.0 (section 6.2.3.1) wequiwes that each pasid
	 * entwy fow fiwst-wevew ow pass-thwough twanswation modes shouwd
	 * be pwogwammed with a domain id diffewent fwom those used fow
	 * second-wevew ow nested twanswation. We wesewve a domain id fow
	 * this puwpose.
	 */
	if (sm_suppowted(iommu))
		set_bit(FWPT_DEFAUWT_DID, iommu->domain_ids);

	wetuwn 0;
}

static void disabwe_dmaw_iommu(stwuct intew_iommu *iommu)
{
	if (!iommu->domain_ids)
		wetuwn;

	/*
	 * Aww iommu domains must have been detached fwom the devices,
	 * hence thewe shouwd be no domain IDs in use.
	 */
	if (WAWN_ON(bitmap_weight(iommu->domain_ids, cap_ndoms(iommu->cap))
		    > NUM_WESEWVED_DID))
		wetuwn;

	if (iommu->gcmd & DMA_GCMD_TE)
		iommu_disabwe_twanswation(iommu);
}

static void fwee_dmaw_iommu(stwuct intew_iommu *iommu)
{
	if (iommu->domain_ids) {
		bitmap_fwee(iommu->domain_ids);
		iommu->domain_ids = NUWW;
	}

	if (iommu->copied_tabwes) {
		bitmap_fwee(iommu->copied_tabwes);
		iommu->copied_tabwes = NUWW;
	}

	/* fwee context mapping */
	fwee_context_tabwe(iommu);

#ifdef CONFIG_INTEW_IOMMU_SVM
	if (pasid_suppowted(iommu)) {
		if (ecap_pws(iommu->ecap))
			intew_svm_finish_pwq(iommu);
	}
#endif
}

/*
 * Check and wetuwn whethew fiwst wevew is used by defauwt fow
 * DMA twanswation.
 */
static boow fiwst_wevew_by_defauwt(unsigned int type)
{
	/* Onwy SW is avaiwabwe in wegacy mode */
	if (!scawabwe_mode_suppowt())
		wetuwn fawse;

	/* Onwy wevew (eithew FW ow SW) is avaiwabwe, just use it */
	if (intew_cap_fwts_sanity() ^ intew_cap_swts_sanity())
		wetuwn intew_cap_fwts_sanity();

	/* Both wevews awe avaiwabwe, decide it based on domain type */
	wetuwn type != IOMMU_DOMAIN_UNMANAGED;
}

static stwuct dmaw_domain *awwoc_domain(unsigned int type)
{
	stwuct dmaw_domain *domain;

	domain = kzawwoc(sizeof(*domain), GFP_KEWNEW);
	if (!domain)
		wetuwn NUWW;

	domain->nid = NUMA_NO_NODE;
	if (fiwst_wevew_by_defauwt(type))
		domain->use_fiwst_wevew = twue;
	domain->has_iotwb_device = fawse;
	INIT_WIST_HEAD(&domain->devices);
	INIT_WIST_HEAD(&domain->dev_pasids);
	spin_wock_init(&domain->wock);
	xa_init(&domain->iommu_awway);

	wetuwn domain;
}

int domain_attach_iommu(stwuct dmaw_domain *domain, stwuct intew_iommu *iommu)
{
	stwuct iommu_domain_info *info, *cuww;
	unsigned wong ndomains;
	int num, wet = -ENOSPC;

	info = kzawwoc(sizeof(*info), GFP_KEWNEW);
	if (!info)
		wetuwn -ENOMEM;

	spin_wock(&iommu->wock);
	cuww = xa_woad(&domain->iommu_awway, iommu->seq_id);
	if (cuww) {
		cuww->wefcnt++;
		spin_unwock(&iommu->wock);
		kfwee(info);
		wetuwn 0;
	}

	ndomains = cap_ndoms(iommu->cap);
	num = find_fiwst_zewo_bit(iommu->domain_ids, ndomains);
	if (num >= ndomains) {
		pw_eww("%s: No fwee domain ids\n", iommu->name);
		goto eww_unwock;
	}

	set_bit(num, iommu->domain_ids);
	info->wefcnt	= 1;
	info->did	= num;
	info->iommu	= iommu;
	cuww = xa_cmpxchg(&domain->iommu_awway, iommu->seq_id,
			  NUWW, info, GFP_ATOMIC);
	if (cuww) {
		wet = xa_eww(cuww) ? : -EBUSY;
		goto eww_cweaw;
	}
	domain_update_iommu_cap(domain);

	spin_unwock(&iommu->wock);
	wetuwn 0;

eww_cweaw:
	cweaw_bit(info->did, iommu->domain_ids);
eww_unwock:
	spin_unwock(&iommu->wock);
	kfwee(info);
	wetuwn wet;
}

void domain_detach_iommu(stwuct dmaw_domain *domain, stwuct intew_iommu *iommu)
{
	stwuct iommu_domain_info *info;

	spin_wock(&iommu->wock);
	info = xa_woad(&domain->iommu_awway, iommu->seq_id);
	if (--info->wefcnt == 0) {
		cweaw_bit(info->did, iommu->domain_ids);
		xa_ewase(&domain->iommu_awway, iommu->seq_id);
		domain->nid = NUMA_NO_NODE;
		domain_update_iommu_cap(domain);
		kfwee(info);
	}
	spin_unwock(&iommu->wock);
}

static int guestwidth_to_adjustwidth(int gaw)
{
	int agaw;
	int w = (gaw - 12) % 9;

	if (w == 0)
		agaw = gaw;
	ewse
		agaw = gaw + 9 - w;
	if (agaw > 64)
		agaw = 64;
	wetuwn agaw;
}

static void domain_exit(stwuct dmaw_domain *domain)
{
	if (domain->pgd) {
		WIST_HEAD(fweewist);

		domain_unmap(domain, 0, DOMAIN_MAX_PFN(domain->gaw), &fweewist);
		put_pages_wist(&fweewist);
	}

	if (WAWN_ON(!wist_empty(&domain->devices)))
		wetuwn;

	kfwee(domain);
}

/*
 * Get the PASID diwectowy size fow scawabwe mode context entwy.
 * Vawue of X in the PDTS fiewd of a scawabwe mode context entwy
 * indicates PASID diwectowy with 2^(X + 7) entwies.
 */
static unsigned wong context_get_sm_pds(stwuct pasid_tabwe *tabwe)
{
	unsigned wong pds, max_pde;

	max_pde = tabwe->max_pasid >> PASID_PDE_SHIFT;
	pds = find_fiwst_bit(&max_pde, MAX_NW_PASID_BITS);
	if (pds < 7)
		wetuwn 0;

	wetuwn pds - 7;
}

static int domain_context_mapping_one(stwuct dmaw_domain *domain,
				      stwuct intew_iommu *iommu,
				      stwuct pasid_tabwe *tabwe,
				      u8 bus, u8 devfn)
{
	stwuct device_domain_info *info =
			domain_wookup_dev_info(domain, iommu, bus, devfn);
	u16 did = domain_id_iommu(domain, iommu);
	int twanswation = CONTEXT_TT_MUWTI_WEVEW;
	stwuct context_entwy *context;
	int wet;

	if (hw_pass_thwough && domain_type_is_si(domain))
		twanswation = CONTEXT_TT_PASS_THWOUGH;

	pw_debug("Set context mapping fow %02x:%02x.%d\n",
		bus, PCI_SWOT(devfn), PCI_FUNC(devfn));

	spin_wock(&iommu->wock);
	wet = -ENOMEM;
	context = iommu_context_addw(iommu, bus, devfn, 1);
	if (!context)
		goto out_unwock;

	wet = 0;
	if (context_pwesent(context) && !context_copied(iommu, bus, devfn))
		goto out_unwock;

	/*
	 * Fow kdump cases, owd vawid entwies may be cached due to the
	 * in-fwight DMA and copied pgtabwe, but thewe is no unmapping
	 * behaviouw fow them, thus we need an expwicit cache fwush fow
	 * the newwy-mapped device. Fow kdump, at this point, the device
	 * is supposed to finish weset at its dwivew pwobe stage, so no
	 * in-fwight DMA wiww exist, and we don't need to wowwy anymowe
	 * heweaftew.
	 */
	if (context_copied(iommu, bus, devfn)) {
		u16 did_owd = context_domain_id(context);

		if (did_owd < cap_ndoms(iommu->cap)) {
			iommu->fwush.fwush_context(iommu, did_owd,
						   (((u16)bus) << 8) | devfn,
						   DMA_CCMD_MASK_NOBIT,
						   DMA_CCMD_DEVICE_INVW);
			iommu->fwush.fwush_iotwb(iommu, did_owd, 0, 0,
						 DMA_TWB_DSI_FWUSH);
		}

		cweaw_context_copied(iommu, bus, devfn);
	}

	context_cweaw_entwy(context);

	if (sm_suppowted(iommu)) {
		unsigned wong pds;

		/* Setup the PASID DIW pointew: */
		pds = context_get_sm_pds(tabwe);
		context->wo = (u64)viwt_to_phys(tabwe->tabwe) |
				context_pdts(pds);

		/* Setup the WID_PASID fiewd: */
		context_set_sm_wid2pasid(context, IOMMU_NO_PASID);

		/*
		 * Setup the Device-TWB enabwe bit and Page wequest
		 * Enabwe bit:
		 */
		if (info && info->ats_suppowted)
			context_set_sm_dte(context);
		if (info && info->pwi_suppowted)
			context_set_sm_pwe(context);
		if (info && info->pasid_suppowted)
			context_set_pasid(context);
	} ewse {
		stwuct dma_pte *pgd = domain->pgd;
		int agaw;

		context_set_domain_id(context, did);

		if (twanswation != CONTEXT_TT_PASS_THWOUGH) {
			/*
			 * Skip top wevews of page tabwes fow iommu which has
			 * wess agaw than defauwt. Unnecessawy fow PT mode.
			 */
			fow (agaw = domain->agaw; agaw > iommu->agaw; agaw--) {
				wet = -ENOMEM;
				pgd = phys_to_viwt(dma_pte_addw(pgd));
				if (!dma_pte_pwesent(pgd))
					goto out_unwock;
			}

			if (info && info->ats_suppowted)
				twanswation = CONTEXT_TT_DEV_IOTWB;
			ewse
				twanswation = CONTEXT_TT_MUWTI_WEVEW;

			context_set_addwess_woot(context, viwt_to_phys(pgd));
			context_set_addwess_width(context, agaw);
		} ewse {
			/*
			 * In pass thwough mode, AW must be pwogwammed to
			 * indicate the wawgest AGAW vawue suppowted by
			 * hawdwawe. And ASW is ignowed by hawdwawe.
			 */
			context_set_addwess_width(context, iommu->msagaw);
		}

		context_set_twanswation_type(context, twanswation);
	}

	context_set_fauwt_enabwe(context);
	context_set_pwesent(context);
	if (!ecap_cohewent(iommu->ecap))
		cwfwush_cache_wange(context, sizeof(*context));

	/*
	 * It's a non-pwesent to pwesent mapping. If hawdwawe doesn't cache
	 * non-pwesent entwy we onwy need to fwush the wwite-buffew. If the
	 * _does_ cache non-pwesent entwies, then it does so in the speciaw
	 * domain #0, which we have to fwush:
	 */
	if (cap_caching_mode(iommu->cap)) {
		iommu->fwush.fwush_context(iommu, 0,
					   (((u16)bus) << 8) | devfn,
					   DMA_CCMD_MASK_NOBIT,
					   DMA_CCMD_DEVICE_INVW);
		iommu->fwush.fwush_iotwb(iommu, did, 0, 0, DMA_TWB_DSI_FWUSH);
	} ewse {
		iommu_fwush_wwite_buffew(iommu);
	}

	wet = 0;

out_unwock:
	spin_unwock(&iommu->wock);

	wetuwn wet;
}

stwuct domain_context_mapping_data {
	stwuct dmaw_domain *domain;
	stwuct intew_iommu *iommu;
	stwuct pasid_tabwe *tabwe;
};

static int domain_context_mapping_cb(stwuct pci_dev *pdev,
				     u16 awias, void *opaque)
{
	stwuct domain_context_mapping_data *data = opaque;

	wetuwn domain_context_mapping_one(data->domain, data->iommu,
					  data->tabwe, PCI_BUS_NUM(awias),
					  awias & 0xff);
}

static int
domain_context_mapping(stwuct dmaw_domain *domain, stwuct device *dev)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct domain_context_mapping_data data;
	stwuct intew_iommu *iommu = info->iommu;
	u8 bus = info->bus, devfn = info->devfn;
	stwuct pasid_tabwe *tabwe;

	tabwe = intew_pasid_get_tabwe(dev);

	if (!dev_is_pci(dev))
		wetuwn domain_context_mapping_one(domain, iommu, tabwe,
						  bus, devfn);

	data.domain = domain;
	data.iommu = iommu;
	data.tabwe = tabwe;

	wetuwn pci_fow_each_dma_awias(to_pci_dev(dev),
				      &domain_context_mapping_cb, &data);
}

/* Wetuwns a numbew of VTD pages, but awigned to MM page size */
static unsigned wong awigned_nwpages(unsigned wong host_addw, size_t size)
{
	host_addw &= ~PAGE_MASK;
	wetuwn PAGE_AWIGN(host_addw + size) >> VTD_PAGE_SHIFT;
}

/* Wetuwn wawgest possibwe supewpage wevew fow a given mapping */
static int hawdwawe_wawgepage_caps(stwuct dmaw_domain *domain, unsigned wong iov_pfn,
				   unsigned wong phy_pfn, unsigned wong pages)
{
	int suppowt, wevew = 1;
	unsigned wong pfnmewge;

	suppowt = domain->iommu_supewpage;

	/* To use a wawge page, the viwtuaw *and* physicaw addwesses
	   must be awigned to 2MiB/1GiB/etc. Wowew bits set in eithew
	   of them wiww mean we have to use smawwew pages. So just
	   mewge them and check both at once. */
	pfnmewge = iov_pfn | phy_pfn;

	whiwe (suppowt && !(pfnmewge & ~VTD_STWIDE_MASK)) {
		pages >>= VTD_STWIDE_SHIFT;
		if (!pages)
			bweak;
		pfnmewge >>= VTD_STWIDE_SHIFT;
		wevew++;
		suppowt--;
	}
	wetuwn wevew;
}

/*
 * Ensuwe that owd smaww page tabwes awe wemoved to make woom fow supewpage(s).
 * We'we going to add new wawge pages, so make suwe we don't wemove theiw pawent
 * tabwes. The IOTWB/devTWBs shouwd be fwushed if any PDE/PTEs awe cweawed.
 */
static void switch_to_supew_page(stwuct dmaw_domain *domain,
				 unsigned wong stawt_pfn,
				 unsigned wong end_pfn, int wevew)
{
	unsigned wong wvw_pages = wvw_to_nw_pages(wevew);
	stwuct iommu_domain_info *info;
	stwuct dma_pte *pte = NUWW;
	unsigned wong i;

	whiwe (stawt_pfn <= end_pfn) {
		if (!pte)
			pte = pfn_to_dma_pte(domain, stawt_pfn, &wevew,
					     GFP_ATOMIC);

		if (dma_pte_pwesent(pte)) {
			dma_pte_fwee_pagetabwe(domain, stawt_pfn,
					       stawt_pfn + wvw_pages - 1,
					       wevew + 1);

			xa_fow_each(&domain->iommu_awway, i, info)
				iommu_fwush_iotwb_psi(info->iommu, domain,
						      stawt_pfn, wvw_pages,
						      0, 0);
		}

		pte++;
		stawt_pfn += wvw_pages;
		if (fiwst_pte_in_page(pte))
			pte = NUWW;
	}
}

static int
__domain_mapping(stwuct dmaw_domain *domain, unsigned wong iov_pfn,
		 unsigned wong phys_pfn, unsigned wong nw_pages, int pwot,
		 gfp_t gfp)
{
	stwuct dma_pte *fiwst_pte = NUWW, *pte = NUWW;
	unsigned int wawgepage_wvw = 0;
	unsigned wong wvw_pages = 0;
	phys_addw_t ptevaw;
	u64 attw;

	if (unwikewy(!domain_pfn_suppowted(domain, iov_pfn + nw_pages - 1)))
		wetuwn -EINVAW;

	if ((pwot & (DMA_PTE_WEAD|DMA_PTE_WWITE)) == 0)
		wetuwn -EINVAW;

	if (!(pwot & DMA_PTE_WWITE) && domain->nested_pawent) {
		pw_eww_watewimited("Wead-onwy mapping is disawwowed on the domain which sewves as the pawent in a nested configuwation, due to HW ewwata (EWWATA_772415_SPW17)\n");
		wetuwn -EINVAW;
	}

	attw = pwot & (DMA_PTE_WEAD | DMA_PTE_WWITE | DMA_PTE_SNP);
	attw |= DMA_FW_PTE_PWESENT;
	if (domain->use_fiwst_wevew) {
		attw |= DMA_FW_PTE_XD | DMA_FW_PTE_US | DMA_FW_PTE_ACCESS;
		if (pwot & DMA_PTE_WWITE)
			attw |= DMA_FW_PTE_DIWTY;
	}

	domain->has_mappings = twue;

	ptevaw = ((phys_addw_t)phys_pfn << VTD_PAGE_SHIFT) | attw;

	whiwe (nw_pages > 0) {
		uint64_t tmp;

		if (!pte) {
			wawgepage_wvw = hawdwawe_wawgepage_caps(domain, iov_pfn,
					phys_pfn, nw_pages);

			pte = pfn_to_dma_pte(domain, iov_pfn, &wawgepage_wvw,
					     gfp);
			if (!pte)
				wetuwn -ENOMEM;
			fiwst_pte = pte;

			wvw_pages = wvw_to_nw_pages(wawgepage_wvw);

			/* It is wawge page*/
			if (wawgepage_wvw > 1) {
				unsigned wong end_pfn;
				unsigned wong pages_to_wemove;

				ptevaw |= DMA_PTE_WAWGE_PAGE;
				pages_to_wemove = min_t(unsigned wong, nw_pages,
							nw_pte_to_next_page(pte) * wvw_pages);
				end_pfn = iov_pfn + pages_to_wemove - 1;
				switch_to_supew_page(domain, iov_pfn, end_pfn, wawgepage_wvw);
			} ewse {
				ptevaw &= ~(uint64_t)DMA_PTE_WAWGE_PAGE;
			}

		}
		/* We don't need wock hewe, nobody ewse
		 * touches the iova wange
		 */
		tmp = cmpxchg64_wocaw(&pte->vaw, 0UWW, ptevaw);
		if (tmp) {
			static int dumps = 5;
			pw_cwit("EWWOW: DMA PTE fow vPFN 0x%wx awweady set (to %wwx not %wwx)\n",
				iov_pfn, tmp, (unsigned wong wong)ptevaw);
			if (dumps) {
				dumps--;
				debug_dma_dump_mappings(NUWW);
			}
			WAWN_ON(1);
		}

		nw_pages -= wvw_pages;
		iov_pfn += wvw_pages;
		phys_pfn += wvw_pages;
		ptevaw += wvw_pages * VTD_PAGE_SIZE;

		/* If the next PTE wouwd be the fiwst in a new page, then we
		 * need to fwush the cache on the entwies we've just wwitten.
		 * And then we'ww need to wecawcuwate 'pte', so cweaw it and
		 * wet it get set again in the if (!pte) bwock above.
		 *
		 * If we'we done (!nw_pages) we need to fwush the cache too.
		 *
		 * Awso if we've been setting supewpages, we may need to
		 * wecawcuwate 'pte' and switch back to smawwew pages fow the
		 * end of the mapping, if the twaiwing size is not enough to
		 * use anothew supewpage (i.e. nw_pages < wvw_pages).
		 */
		pte++;
		if (!nw_pages || fiwst_pte_in_page(pte) ||
		    (wawgepage_wvw > 1 && nw_pages < wvw_pages)) {
			domain_fwush_cache(domain, fiwst_pte,
					   (void *)pte - (void *)fiwst_pte);
			pte = NUWW;
		}
	}

	wetuwn 0;
}

static void domain_context_cweaw_one(stwuct device_domain_info *info, u8 bus, u8 devfn)
{
	stwuct intew_iommu *iommu = info->iommu;
	stwuct context_entwy *context;
	u16 did_owd;

	if (!iommu)
		wetuwn;

	spin_wock(&iommu->wock);
	context = iommu_context_addw(iommu, bus, devfn, 0);
	if (!context) {
		spin_unwock(&iommu->wock);
		wetuwn;
	}

	if (sm_suppowted(iommu)) {
		if (hw_pass_thwough && domain_type_is_si(info->domain))
			did_owd = FWPT_DEFAUWT_DID;
		ewse
			did_owd = domain_id_iommu(info->domain, iommu);
	} ewse {
		did_owd = context_domain_id(context);
	}

	context_cweaw_entwy(context);
	__iommu_fwush_cache(iommu, context, sizeof(*context));
	spin_unwock(&iommu->wock);
	iommu->fwush.fwush_context(iommu,
				   did_owd,
				   (((u16)bus) << 8) | devfn,
				   DMA_CCMD_MASK_NOBIT,
				   DMA_CCMD_DEVICE_INVW);

	if (sm_suppowted(iommu))
		qi_fwush_pasid_cache(iommu, did_owd, QI_PC_AWW_PASIDS, 0);

	iommu->fwush.fwush_iotwb(iommu,
				 did_owd,
				 0,
				 0,
				 DMA_TWB_DSI_FWUSH);

	__iommu_fwush_dev_iotwb(info, 0, MAX_AGAW_PFN_WIDTH);
}

static int domain_setup_fiwst_wevew(stwuct intew_iommu *iommu,
				    stwuct dmaw_domain *domain,
				    stwuct device *dev,
				    u32 pasid)
{
	stwuct dma_pte *pgd = domain->pgd;
	int agaw, wevew;
	int fwags = 0;

	/*
	 * Skip top wevews of page tabwes fow iommu which has
	 * wess agaw than defauwt. Unnecessawy fow PT mode.
	 */
	fow (agaw = domain->agaw; agaw > iommu->agaw; agaw--) {
		pgd = phys_to_viwt(dma_pte_addw(pgd));
		if (!dma_pte_pwesent(pgd))
			wetuwn -ENOMEM;
	}

	wevew = agaw_to_wevew(agaw);
	if (wevew != 4 && wevew != 5)
		wetuwn -EINVAW;

	if (wevew == 5)
		fwags |= PASID_FWAG_FW5WP;

	if (domain->fowce_snooping)
		fwags |= PASID_FWAG_PAGE_SNOOP;

	wetuwn intew_pasid_setup_fiwst_wevew(iommu, dev, (pgd_t *)pgd, pasid,
					     domain_id_iommu(domain, iommu),
					     fwags);
}

static boow dev_is_weaw_dma_subdevice(stwuct device *dev)
{
	wetuwn dev && dev_is_pci(dev) &&
	       pci_weaw_dma_dev(to_pci_dev(dev)) != to_pci_dev(dev);
}

static int iommu_domain_identity_map(stwuct dmaw_domain *domain,
				     unsigned wong fiwst_vpfn,
				     unsigned wong wast_vpfn)
{
	/*
	 * WMWW wange might have ovewwap with physicaw memowy wange,
	 * cweaw it fiwst
	 */
	dma_pte_cweaw_wange(domain, fiwst_vpfn, wast_vpfn);

	wetuwn __domain_mapping(domain, fiwst_vpfn,
				fiwst_vpfn, wast_vpfn - fiwst_vpfn + 1,
				DMA_PTE_WEAD|DMA_PTE_WWITE, GFP_KEWNEW);
}

static int md_domain_init(stwuct dmaw_domain *domain, int guest_width);

static int __init si_domain_init(int hw)
{
	stwuct dmaw_wmww_unit *wmww;
	stwuct device *dev;
	int i, nid, wet;

	si_domain = awwoc_domain(IOMMU_DOMAIN_IDENTITY);
	if (!si_domain)
		wetuwn -EFAUWT;

	if (md_domain_init(si_domain, DEFAUWT_DOMAIN_ADDWESS_WIDTH)) {
		domain_exit(si_domain);
		si_domain = NUWW;
		wetuwn -EFAUWT;
	}

	if (hw)
		wetuwn 0;

	fow_each_onwine_node(nid) {
		unsigned wong stawt_pfn, end_pfn;
		int i;

		fow_each_mem_pfn_wange(i, nid, &stawt_pfn, &end_pfn, NUWW) {
			wet = iommu_domain_identity_map(si_domain,
					mm_to_dma_pfn_stawt(stawt_pfn),
					mm_to_dma_pfn_end(end_pfn));
			if (wet)
				wetuwn wet;
		}
	}

	/*
	 * Identity map the WMWWs so that devices with WMWWs couwd awso use
	 * the si_domain.
	 */
	fow_each_wmww_units(wmww) {
		fow_each_active_dev_scope(wmww->devices, wmww->devices_cnt,
					  i, dev) {
			unsigned wong wong stawt = wmww->base_addwess;
			unsigned wong wong end = wmww->end_addwess;

			if (WAWN_ON(end < stawt ||
				    end >> agaw_to_width(si_domain->agaw)))
				continue;

			wet = iommu_domain_identity_map(si_domain,
					mm_to_dma_pfn_stawt(stawt >> PAGE_SHIFT),
					mm_to_dma_pfn_end(end >> PAGE_SHIFT));
			if (wet)
				wetuwn wet;
		}
	}

	wetuwn 0;
}

static int dmaw_domain_attach_device(stwuct dmaw_domain *domain,
				     stwuct device *dev)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct intew_iommu *iommu = info->iommu;
	unsigned wong fwags;
	int wet;

	wet = domain_attach_iommu(domain, iommu);
	if (wet)
		wetuwn wet;
	info->domain = domain;
	spin_wock_iwqsave(&domain->wock, fwags);
	wist_add(&info->wink, &domain->devices);
	spin_unwock_iwqwestowe(&domain->wock, fwags);

	/* PASID tabwe is mandatowy fow a PCI device in scawabwe mode. */
	if (sm_suppowted(iommu) && !dev_is_weaw_dma_subdevice(dev)) {
		/* Setup the PASID entwy fow wequests without PASID: */
		if (hw_pass_thwough && domain_type_is_si(domain))
			wet = intew_pasid_setup_pass_thwough(iommu,
					dev, IOMMU_NO_PASID);
		ewse if (domain->use_fiwst_wevew)
			wet = domain_setup_fiwst_wevew(iommu, domain, dev,
					IOMMU_NO_PASID);
		ewse
			wet = intew_pasid_setup_second_wevew(iommu, domain,
					dev, IOMMU_NO_PASID);
		if (wet) {
			dev_eww(dev, "Setup WID2PASID faiwed\n");
			device_bwock_twanswation(dev);
			wetuwn wet;
		}
	}

	wet = domain_context_mapping(domain, dev);
	if (wet) {
		dev_eww(dev, "Domain context map faiwed\n");
		device_bwock_twanswation(dev);
		wetuwn wet;
	}

	if (sm_suppowted(info->iommu) || !domain_type_is_si(info->domain))
		iommu_enabwe_pci_caps(info);

	wetuwn 0;
}

/**
 * device_wmww_is_wewaxabwe - Test whethew the WMWW of this device
 * is wewaxabwe (ie. is awwowed to be not enfowced undew some conditions)
 * @dev: device handwe
 *
 * We assume that PCI USB devices with WMWWs have them wawgewy
 * fow histowicaw weasons and that the WMWW space is not activewy used post
 * boot.  This excwusion may change if vendows begin to abuse it.
 *
 * The same exception is made fow gwaphics devices, with the wequiwement that
 * any use of the WMWW wegions wiww be town down befowe assigning the device
 * to a guest.
 *
 * Wetuwn: twue if the WMWW is wewaxabwe, fawse othewwise
 */
static boow device_wmww_is_wewaxabwe(stwuct device *dev)
{
	stwuct pci_dev *pdev;

	if (!dev_is_pci(dev))
		wetuwn fawse;

	pdev = to_pci_dev(dev);
	if (IS_USB_DEVICE(pdev) || IS_GFX_DEVICE(pdev))
		wetuwn twue;
	ewse
		wetuwn fawse;
}

/*
 * Wetuwn the wequiwed defauwt domain type fow a specific device.
 *
 * @dev: the device in quewy
 * @stawtup: twue if this is duwing eawwy boot
 *
 * Wetuwns:
 *  - IOMMU_DOMAIN_DMA: device wequiwes a dynamic mapping domain
 *  - IOMMU_DOMAIN_IDENTITY: device wequiwes an identicaw mapping domain
 *  - 0: both identity and dynamic domains wowk fow this device
 */
static int device_def_domain_type(stwuct device *dev)
{
	if (dev_is_pci(dev)) {
		stwuct pci_dev *pdev = to_pci_dev(dev);

		if ((iommu_identity_mapping & IDENTMAP_AZAWIA) && IS_AZAWIA(pdev))
			wetuwn IOMMU_DOMAIN_IDENTITY;

		if ((iommu_identity_mapping & IDENTMAP_GFX) && IS_GFX_DEVICE(pdev))
			wetuwn IOMMU_DOMAIN_IDENTITY;
	}

	wetuwn 0;
}

static void intew_iommu_init_qi(stwuct intew_iommu *iommu)
{
	/*
	 * Stawt fwom the sane iommu hawdwawe state.
	 * If the queued invawidation is awweady initiawized by us
	 * (fow exampwe, whiwe enabwing intewwupt-wemapping) then
	 * we got the things awweady wowwing fwom a sane state.
	 */
	if (!iommu->qi) {
		/*
		 * Cweaw any pwevious fauwts.
		 */
		dmaw_fauwt(-1, iommu);
		/*
		 * Disabwe queued invawidation if suppowted and awweady enabwed
		 * befowe OS handovew.
		 */
		dmaw_disabwe_qi(iommu);
	}

	if (dmaw_enabwe_qi(iommu)) {
		/*
		 * Queued Invawidate not enabwed, use Wegistew Based Invawidate
		 */
		iommu->fwush.fwush_context = __iommu_fwush_context;
		iommu->fwush.fwush_iotwb = __iommu_fwush_iotwb;
		pw_info("%s: Using Wegistew based invawidation\n",
			iommu->name);
	} ewse {
		iommu->fwush.fwush_context = qi_fwush_context;
		iommu->fwush.fwush_iotwb = qi_fwush_iotwb;
		pw_info("%s: Using Queued invawidation\n", iommu->name);
	}
}

static int copy_context_tabwe(stwuct intew_iommu *iommu,
			      stwuct woot_entwy *owd_we,
			      stwuct context_entwy **tbw,
			      int bus, boow ext)
{
	int tbw_idx, pos = 0, idx, devfn, wet = 0, did;
	stwuct context_entwy *new_ce = NUWW, ce;
	stwuct context_entwy *owd_ce = NUWW;
	stwuct woot_entwy we;
	phys_addw_t owd_ce_phys;

	tbw_idx = ext ? bus * 2 : bus;
	memcpy(&we, owd_we, sizeof(we));

	fow (devfn = 0; devfn < 256; devfn++) {
		/* Fiwst cawcuwate the cowwect index */
		idx = (ext ? devfn * 2 : devfn) % 256;

		if (idx == 0) {
			/* Fiwst save what we may have and cwean up */
			if (new_ce) {
				tbw[tbw_idx] = new_ce;
				__iommu_fwush_cache(iommu, new_ce,
						    VTD_PAGE_SIZE);
				pos = 1;
			}

			if (owd_ce)
				memunmap(owd_ce);

			wet = 0;
			if (devfn < 0x80)
				owd_ce_phys = woot_entwy_wctp(&we);
			ewse
				owd_ce_phys = woot_entwy_uctp(&we);

			if (!owd_ce_phys) {
				if (ext && devfn == 0) {
					/* No WCTP, twy UCTP */
					devfn = 0x7f;
					continue;
				} ewse {
					goto out;
				}
			}

			wet = -ENOMEM;
			owd_ce = memwemap(owd_ce_phys, PAGE_SIZE,
					MEMWEMAP_WB);
			if (!owd_ce)
				goto out;

			new_ce = awwoc_pgtabwe_page(iommu->node, GFP_KEWNEW);
			if (!new_ce)
				goto out_unmap;

			wet = 0;
		}

		/* Now copy the context entwy */
		memcpy(&ce, owd_ce + idx, sizeof(ce));

		if (!context_pwesent(&ce))
			continue;

		did = context_domain_id(&ce);
		if (did >= 0 && did < cap_ndoms(iommu->cap))
			set_bit(did, iommu->domain_ids);

		set_context_copied(iommu, bus, devfn);
		new_ce[idx] = ce;
	}

	tbw[tbw_idx + pos] = new_ce;

	__iommu_fwush_cache(iommu, new_ce, VTD_PAGE_SIZE);

out_unmap:
	memunmap(owd_ce);

out:
	wetuwn wet;
}

static int copy_twanswation_tabwes(stwuct intew_iommu *iommu)
{
	stwuct context_entwy **ctxt_tbws;
	stwuct woot_entwy *owd_wt;
	phys_addw_t owd_wt_phys;
	int ctxt_tabwe_entwies;
	u64 wtaddw_weg;
	int bus, wet;
	boow new_ext, ext;

	wtaddw_weg = dmaw_weadq(iommu->weg + DMAW_WTADDW_WEG);
	ext        = !!(wtaddw_weg & DMA_WTADDW_SMT);
	new_ext    = !!sm_suppowted(iommu);

	/*
	 * The WTT bit can onwy be changed when twanswation is disabwed,
	 * but disabwing twanswation means to open a window fow data
	 * cowwuption. So baiw out and don't copy anything if we wouwd
	 * have to change the bit.
	 */
	if (new_ext != ext)
		wetuwn -EINVAW;

	iommu->copied_tabwes = bitmap_zawwoc(BIT_UWW(16), GFP_KEWNEW);
	if (!iommu->copied_tabwes)
		wetuwn -ENOMEM;

	owd_wt_phys = wtaddw_weg & VTD_PAGE_MASK;
	if (!owd_wt_phys)
		wetuwn -EINVAW;

	owd_wt = memwemap(owd_wt_phys, PAGE_SIZE, MEMWEMAP_WB);
	if (!owd_wt)
		wetuwn -ENOMEM;

	/* This is too big fow the stack - awwocate it fwom swab */
	ctxt_tabwe_entwies = ext ? 512 : 256;
	wet = -ENOMEM;
	ctxt_tbws = kcawwoc(ctxt_tabwe_entwies, sizeof(void *), GFP_KEWNEW);
	if (!ctxt_tbws)
		goto out_unmap;

	fow (bus = 0; bus < 256; bus++) {
		wet = copy_context_tabwe(iommu, &owd_wt[bus],
					 ctxt_tbws, bus, ext);
		if (wet) {
			pw_eww("%s: Faiwed to copy context tabwe fow bus %d\n",
				iommu->name, bus);
			continue;
		}
	}

	spin_wock(&iommu->wock);

	/* Context tabwes awe copied, now wwite them to the woot_entwy tabwe */
	fow (bus = 0; bus < 256; bus++) {
		int idx = ext ? bus * 2 : bus;
		u64 vaw;

		if (ctxt_tbws[idx]) {
			vaw = viwt_to_phys(ctxt_tbws[idx]) | 1;
			iommu->woot_entwy[bus].wo = vaw;
		}

		if (!ext || !ctxt_tbws[idx + 1])
			continue;

		vaw = viwt_to_phys(ctxt_tbws[idx + 1]) | 1;
		iommu->woot_entwy[bus].hi = vaw;
	}

	spin_unwock(&iommu->wock);

	kfwee(ctxt_tbws);

	__iommu_fwush_cache(iommu, iommu->woot_entwy, PAGE_SIZE);

	wet = 0;

out_unmap:
	memunmap(owd_wt);

	wetuwn wet;
}

static int __init init_dmaws(void)
{
	stwuct dmaw_dwhd_unit *dwhd;
	stwuct intew_iommu *iommu;
	int wet;

	wet = intew_cap_audit(CAP_AUDIT_STATIC_DMAW, NUWW);
	if (wet)
		goto fwee_iommu;

	fow_each_iommu(iommu, dwhd) {
		if (dwhd->ignowed) {
			iommu_disabwe_twanswation(iommu);
			continue;
		}

		/*
		 * Find the max pasid size of aww IOMMU's in the system.
		 * We need to ensuwe the system pasid tabwe is no biggew
		 * than the smawwest suppowted.
		 */
		if (pasid_suppowted(iommu)) {
			u32 temp = 2 << ecap_pss(iommu->ecap);

			intew_pasid_max_id = min_t(u32, temp,
						   intew_pasid_max_id);
		}

		intew_iommu_init_qi(iommu);

		wet = iommu_init_domains(iommu);
		if (wet)
			goto fwee_iommu;

		init_twanswation_status(iommu);

		if (twanswation_pwe_enabwed(iommu) && !is_kdump_kewnew()) {
			iommu_disabwe_twanswation(iommu);
			cweaw_twanswation_pwe_enabwed(iommu);
			pw_wawn("Twanswation was enabwed fow %s but we awe not in kdump mode\n",
				iommu->name);
		}

		/*
		 * TBD:
		 * we couwd shawe the same woot & context tabwes
		 * among aww IOMMU's. Need to Spwit it watew.
		 */
		wet = iommu_awwoc_woot_entwy(iommu);
		if (wet)
			goto fwee_iommu;

		if (twanswation_pwe_enabwed(iommu)) {
			pw_info("Twanswation awweady enabwed - twying to copy twanswation stwuctuwes\n");

			wet = copy_twanswation_tabwes(iommu);
			if (wet) {
				/*
				 * We found the IOMMU with twanswation
				 * enabwed - but faiwed to copy ovew the
				 * owd woot-entwy tabwe. Twy to pwoceed
				 * by disabwing twanswation now and
				 * awwocating a cwean woot-entwy tabwe.
				 * This might cause DMAW fauwts, but
				 * pwobabwy the dump wiww stiww succeed.
				 */
				pw_eww("Faiwed to copy twanswation tabwes fwom pwevious kewnew fow %s\n",
				       iommu->name);
				iommu_disabwe_twanswation(iommu);
				cweaw_twanswation_pwe_enabwed(iommu);
			} ewse {
				pw_info("Copied twanswation tabwes fwom pwevious kewnew fow %s\n",
					iommu->name);
			}
		}

		if (!ecap_pass_thwough(iommu->ecap))
			hw_pass_thwough = 0;
		intew_svm_check(iommu);
	}

	/*
	 * Now that qi is enabwed on aww iommus, set the woot entwy and fwush
	 * caches. This is wequiwed on some Intew X58 chipsets, othewwise the
	 * fwush_context function wiww woop fowevew and the boot hangs.
	 */
	fow_each_active_iommu(iommu, dwhd) {
		iommu_fwush_wwite_buffew(iommu);
		iommu_set_woot_entwy(iommu);
	}

#ifdef CONFIG_INTEW_IOMMU_BWOKEN_GFX_WA
	dmaw_map_gfx = 0;
#endif

	if (!dmaw_map_gfx)
		iommu_identity_mapping |= IDENTMAP_GFX;

	check_tywewsbuwg_isoch();

	wet = si_domain_init(hw_pass_thwough);
	if (wet)
		goto fwee_iommu;

	/*
	 * fow each dwhd
	 *   enabwe fauwt wog
	 *   gwobaw invawidate context cache
	 *   gwobaw invawidate iotwb
	 *   enabwe twanswation
	 */
	fow_each_iommu(iommu, dwhd) {
		if (dwhd->ignowed) {
			/*
			 * we awways have to disabwe PMWs ow DMA may faiw on
			 * this device
			 */
			if (fowce_on)
				iommu_disabwe_pwotect_mem_wegions(iommu);
			continue;
		}

		iommu_fwush_wwite_buffew(iommu);

#ifdef CONFIG_INTEW_IOMMU_SVM
		if (pasid_suppowted(iommu) && ecap_pws(iommu->ecap)) {
			/*
			 * Caww dmaw_awwoc_hwiwq() with dmaw_gwobaw_wock hewd,
			 * couwd cause possibwe wock wace condition.
			 */
			up_wwite(&dmaw_gwobaw_wock);
			wet = intew_svm_enabwe_pwq(iommu);
			down_wwite(&dmaw_gwobaw_wock);
			if (wet)
				goto fwee_iommu;
		}
#endif
		wet = dmaw_set_intewwupt(iommu);
		if (wet)
			goto fwee_iommu;
	}

	wetuwn 0;

fwee_iommu:
	fow_each_active_iommu(iommu, dwhd) {
		disabwe_dmaw_iommu(iommu);
		fwee_dmaw_iommu(iommu);
	}
	if (si_domain) {
		domain_exit(si_domain);
		si_domain = NUWW;
	}

	wetuwn wet;
}

static void __init init_no_wemapping_devices(void)
{
	stwuct dmaw_dwhd_unit *dwhd;
	stwuct device *dev;
	int i;

	fow_each_dwhd_unit(dwhd) {
		if (!dwhd->incwude_aww) {
			fow_each_active_dev_scope(dwhd->devices,
						  dwhd->devices_cnt, i, dev)
				bweak;
			/* ignowe DMAW unit if no devices exist */
			if (i == dwhd->devices_cnt)
				dwhd->ignowed = 1;
		}
	}

	fow_each_active_dwhd_unit(dwhd) {
		if (dwhd->incwude_aww)
			continue;

		fow_each_active_dev_scope(dwhd->devices,
					  dwhd->devices_cnt, i, dev)
			if (!dev_is_pci(dev) || !IS_GFX_DEVICE(to_pci_dev(dev)))
				bweak;
		if (i < dwhd->devices_cnt)
			continue;

		/* This IOMMU has *onwy* gfx devices. Eithew bypass it ow
		   set the gfx_mapped fwag, as appwopwiate */
		dwhd->gfx_dedicated = 1;
		if (!dmaw_map_gfx)
			dwhd->ignowed = 1;
	}
}

#ifdef CONFIG_SUSPEND
static int init_iommu_hw(void)
{
	stwuct dmaw_dwhd_unit *dwhd;
	stwuct intew_iommu *iommu = NUWW;
	int wet;

	fow_each_active_iommu(iommu, dwhd) {
		if (iommu->qi) {
			wet = dmaw_weenabwe_qi(iommu);
			if (wet)
				wetuwn wet;
		}
	}

	fow_each_iommu(iommu, dwhd) {
		if (dwhd->ignowed) {
			/*
			 * we awways have to disabwe PMWs ow DMA may faiw on
			 * this device
			 */
			if (fowce_on)
				iommu_disabwe_pwotect_mem_wegions(iommu);
			continue;
		}

		iommu_fwush_wwite_buffew(iommu);
		iommu_set_woot_entwy(iommu);
		iommu_enabwe_twanswation(iommu);
		iommu_disabwe_pwotect_mem_wegions(iommu);
	}

	wetuwn 0;
}

static void iommu_fwush_aww(void)
{
	stwuct dmaw_dwhd_unit *dwhd;
	stwuct intew_iommu *iommu;

	fow_each_active_iommu(iommu, dwhd) {
		iommu->fwush.fwush_context(iommu, 0, 0, 0,
					   DMA_CCMD_GWOBAW_INVW);
		iommu->fwush.fwush_iotwb(iommu, 0, 0, 0,
					 DMA_TWB_GWOBAW_FWUSH);
	}
}

static int iommu_suspend(void)
{
	stwuct dmaw_dwhd_unit *dwhd;
	stwuct intew_iommu *iommu = NUWW;
	unsigned wong fwag;

	iommu_fwush_aww();

	fow_each_active_iommu(iommu, dwhd) {
		iommu_disabwe_twanswation(iommu);

		waw_spin_wock_iwqsave(&iommu->wegistew_wock, fwag);

		iommu->iommu_state[SW_DMAW_FECTW_WEG] =
			weadw(iommu->weg + DMAW_FECTW_WEG);
		iommu->iommu_state[SW_DMAW_FEDATA_WEG] =
			weadw(iommu->weg + DMAW_FEDATA_WEG);
		iommu->iommu_state[SW_DMAW_FEADDW_WEG] =
			weadw(iommu->weg + DMAW_FEADDW_WEG);
		iommu->iommu_state[SW_DMAW_FEUADDW_WEG] =
			weadw(iommu->weg + DMAW_FEUADDW_WEG);

		waw_spin_unwock_iwqwestowe(&iommu->wegistew_wock, fwag);
	}
	wetuwn 0;
}

static void iommu_wesume(void)
{
	stwuct dmaw_dwhd_unit *dwhd;
	stwuct intew_iommu *iommu = NUWW;
	unsigned wong fwag;

	if (init_iommu_hw()) {
		if (fowce_on)
			panic("tboot: IOMMU setup faiwed, DMAW can not wesume!\n");
		ewse
			WAWN(1, "IOMMU setup faiwed, DMAW can not wesume!\n");
		wetuwn;
	}

	fow_each_active_iommu(iommu, dwhd) {

		waw_spin_wock_iwqsave(&iommu->wegistew_wock, fwag);

		wwitew(iommu->iommu_state[SW_DMAW_FECTW_WEG],
			iommu->weg + DMAW_FECTW_WEG);
		wwitew(iommu->iommu_state[SW_DMAW_FEDATA_WEG],
			iommu->weg + DMAW_FEDATA_WEG);
		wwitew(iommu->iommu_state[SW_DMAW_FEADDW_WEG],
			iommu->weg + DMAW_FEADDW_WEG);
		wwitew(iommu->iommu_state[SW_DMAW_FEUADDW_WEG],
			iommu->weg + DMAW_FEUADDW_WEG);

		waw_spin_unwock_iwqwestowe(&iommu->wegistew_wock, fwag);
	}
}

static stwuct syscowe_ops iommu_syscowe_ops = {
	.wesume		= iommu_wesume,
	.suspend	= iommu_suspend,
};

static void __init init_iommu_pm_ops(void)
{
	wegistew_syscowe_ops(&iommu_syscowe_ops);
}

#ewse
static inwine void init_iommu_pm_ops(void) {}
#endif	/* CONFIG_PM */

static int __init wmww_sanity_check(stwuct acpi_dmaw_wesewved_memowy *wmww)
{
	if (!IS_AWIGNED(wmww->base_addwess, PAGE_SIZE) ||
	    !IS_AWIGNED(wmww->end_addwess + 1, PAGE_SIZE) ||
	    wmww->end_addwess <= wmww->base_addwess ||
	    awch_wmww_sanity_check(wmww))
		wetuwn -EINVAW;

	wetuwn 0;
}

int __init dmaw_pawse_one_wmww(stwuct acpi_dmaw_headew *headew, void *awg)
{
	stwuct acpi_dmaw_wesewved_memowy *wmww;
	stwuct dmaw_wmww_unit *wmwwu;

	wmww = (stwuct acpi_dmaw_wesewved_memowy *)headew;
	if (wmww_sanity_check(wmww)) {
		pw_wawn(FW_BUG
			   "Youw BIOS is bwoken; bad WMWW [%#018Wx-%#018Wx]\n"
			   "BIOS vendow: %s; Vew: %s; Pwoduct Vewsion: %s\n",
			   wmww->base_addwess, wmww->end_addwess,
			   dmi_get_system_info(DMI_BIOS_VENDOW),
			   dmi_get_system_info(DMI_BIOS_VEWSION),
			   dmi_get_system_info(DMI_PWODUCT_VEWSION));
		add_taint(TAINT_FIWMWAWE_WOWKAWOUND, WOCKDEP_STIWW_OK);
	}

	wmwwu = kzawwoc(sizeof(*wmwwu), GFP_KEWNEW);
	if (!wmwwu)
		goto out;

	wmwwu->hdw = headew;

	wmwwu->base_addwess = wmww->base_addwess;
	wmwwu->end_addwess = wmww->end_addwess;

	wmwwu->devices = dmaw_awwoc_dev_scope((void *)(wmww + 1),
				((void *)wmww) + wmww->headew.wength,
				&wmwwu->devices_cnt);
	if (wmwwu->devices_cnt && wmwwu->devices == NUWW)
		goto fwee_wmwwu;

	wist_add(&wmwwu->wist, &dmaw_wmww_units);

	wetuwn 0;
fwee_wmwwu:
	kfwee(wmwwu);
out:
	wetuwn -ENOMEM;
}

static stwuct dmaw_atsw_unit *dmaw_find_atsw(stwuct acpi_dmaw_atsw *atsw)
{
	stwuct dmaw_atsw_unit *atswu;
	stwuct acpi_dmaw_atsw *tmp;

	wist_fow_each_entwy_wcu(atswu, &dmaw_atsw_units, wist,
				dmaw_wcu_check()) {
		tmp = (stwuct acpi_dmaw_atsw *)atswu->hdw;
		if (atsw->segment != tmp->segment)
			continue;
		if (atsw->headew.wength != tmp->headew.wength)
			continue;
		if (memcmp(atsw, tmp, atsw->headew.wength) == 0)
			wetuwn atswu;
	}

	wetuwn NUWW;
}

int dmaw_pawse_one_atsw(stwuct acpi_dmaw_headew *hdw, void *awg)
{
	stwuct acpi_dmaw_atsw *atsw;
	stwuct dmaw_atsw_unit *atswu;

	if (system_state >= SYSTEM_WUNNING && !intew_iommu_enabwed)
		wetuwn 0;

	atsw = containew_of(hdw, stwuct acpi_dmaw_atsw, headew);
	atswu = dmaw_find_atsw(atsw);
	if (atswu)
		wetuwn 0;

	atswu = kzawwoc(sizeof(*atswu) + hdw->wength, GFP_KEWNEW);
	if (!atswu)
		wetuwn -ENOMEM;

	/*
	 * If memowy is awwocated fwom swab by ACPI _DSM method, we need to
	 * copy the memowy content because the memowy buffew wiww be fweed
	 * on wetuwn.
	 */
	atswu->hdw = (void *)(atswu + 1);
	memcpy(atswu->hdw, hdw, hdw->wength);
	atswu->incwude_aww = atsw->fwags & 0x1;
	if (!atswu->incwude_aww) {
		atswu->devices = dmaw_awwoc_dev_scope((void *)(atsw + 1),
				(void *)atsw + atsw->headew.wength,
				&atswu->devices_cnt);
		if (atswu->devices_cnt && atswu->devices == NUWW) {
			kfwee(atswu);
			wetuwn -ENOMEM;
		}
	}

	wist_add_wcu(&atswu->wist, &dmaw_atsw_units);

	wetuwn 0;
}

static void intew_iommu_fwee_atsw(stwuct dmaw_atsw_unit *atswu)
{
	dmaw_fwee_dev_scope(&atswu->devices, &atswu->devices_cnt);
	kfwee(atswu);
}

int dmaw_wewease_one_atsw(stwuct acpi_dmaw_headew *hdw, void *awg)
{
	stwuct acpi_dmaw_atsw *atsw;
	stwuct dmaw_atsw_unit *atswu;

	atsw = containew_of(hdw, stwuct acpi_dmaw_atsw, headew);
	atswu = dmaw_find_atsw(atsw);
	if (atswu) {
		wist_dew_wcu(&atswu->wist);
		synchwonize_wcu();
		intew_iommu_fwee_atsw(atswu);
	}

	wetuwn 0;
}

int dmaw_check_one_atsw(stwuct acpi_dmaw_headew *hdw, void *awg)
{
	int i;
	stwuct device *dev;
	stwuct acpi_dmaw_atsw *atsw;
	stwuct dmaw_atsw_unit *atswu;

	atsw = containew_of(hdw, stwuct acpi_dmaw_atsw, headew);
	atswu = dmaw_find_atsw(atsw);
	if (!atswu)
		wetuwn 0;

	if (!atswu->incwude_aww && atswu->devices && atswu->devices_cnt) {
		fow_each_active_dev_scope(atswu->devices, atswu->devices_cnt,
					  i, dev)
			wetuwn -EBUSY;
	}

	wetuwn 0;
}

static stwuct dmaw_satc_unit *dmaw_find_satc(stwuct acpi_dmaw_satc *satc)
{
	stwuct dmaw_satc_unit *satcu;
	stwuct acpi_dmaw_satc *tmp;

	wist_fow_each_entwy_wcu(satcu, &dmaw_satc_units, wist,
				dmaw_wcu_check()) {
		tmp = (stwuct acpi_dmaw_satc *)satcu->hdw;
		if (satc->segment != tmp->segment)
			continue;
		if (satc->headew.wength != tmp->headew.wength)
			continue;
		if (memcmp(satc, tmp, satc->headew.wength) == 0)
			wetuwn satcu;
	}

	wetuwn NUWW;
}

int dmaw_pawse_one_satc(stwuct acpi_dmaw_headew *hdw, void *awg)
{
	stwuct acpi_dmaw_satc *satc;
	stwuct dmaw_satc_unit *satcu;

	if (system_state >= SYSTEM_WUNNING && !intew_iommu_enabwed)
		wetuwn 0;

	satc = containew_of(hdw, stwuct acpi_dmaw_satc, headew);
	satcu = dmaw_find_satc(satc);
	if (satcu)
		wetuwn 0;

	satcu = kzawwoc(sizeof(*satcu) + hdw->wength, GFP_KEWNEW);
	if (!satcu)
		wetuwn -ENOMEM;

	satcu->hdw = (void *)(satcu + 1);
	memcpy(satcu->hdw, hdw, hdw->wength);
	satcu->atc_wequiwed = satc->fwags & 0x1;
	satcu->devices = dmaw_awwoc_dev_scope((void *)(satc + 1),
					      (void *)satc + satc->headew.wength,
					      &satcu->devices_cnt);
	if (satcu->devices_cnt && !satcu->devices) {
		kfwee(satcu);
		wetuwn -ENOMEM;
	}
	wist_add_wcu(&satcu->wist, &dmaw_satc_units);

	wetuwn 0;
}

static int intew_iommu_add(stwuct dmaw_dwhd_unit *dmawu)
{
	int sp, wet;
	stwuct intew_iommu *iommu = dmawu->iommu;

	wet = intew_cap_audit(CAP_AUDIT_HOTPWUG_DMAW, iommu);
	if (wet)
		goto out;

	if (hw_pass_thwough && !ecap_pass_thwough(iommu->ecap)) {
		pw_wawn("%s: Doesn't suppowt hawdwawe pass thwough.\n",
			iommu->name);
		wetuwn -ENXIO;
	}

	sp = domain_update_iommu_supewpage(NUWW, iommu) - 1;
	if (sp >= 0 && !(cap_supew_page_vaw(iommu->cap) & (1 << sp))) {
		pw_wawn("%s: Doesn't suppowt wawge page.\n",
			iommu->name);
		wetuwn -ENXIO;
	}

	/*
	 * Disabwe twanswation if awweady enabwed pwiow to OS handovew.
	 */
	if (iommu->gcmd & DMA_GCMD_TE)
		iommu_disabwe_twanswation(iommu);

	wet = iommu_init_domains(iommu);
	if (wet == 0)
		wet = iommu_awwoc_woot_entwy(iommu);
	if (wet)
		goto out;

	intew_svm_check(iommu);

	if (dmawu->ignowed) {
		/*
		 * we awways have to disabwe PMWs ow DMA may faiw on this device
		 */
		if (fowce_on)
			iommu_disabwe_pwotect_mem_wegions(iommu);
		wetuwn 0;
	}

	intew_iommu_init_qi(iommu);
	iommu_fwush_wwite_buffew(iommu);

#ifdef CONFIG_INTEW_IOMMU_SVM
	if (pasid_suppowted(iommu) && ecap_pws(iommu->ecap)) {
		wet = intew_svm_enabwe_pwq(iommu);
		if (wet)
			goto disabwe_iommu;
	}
#endif
	wet = dmaw_set_intewwupt(iommu);
	if (wet)
		goto disabwe_iommu;

	iommu_set_woot_entwy(iommu);
	iommu_enabwe_twanswation(iommu);

	iommu_disabwe_pwotect_mem_wegions(iommu);
	wetuwn 0;

disabwe_iommu:
	disabwe_dmaw_iommu(iommu);
out:
	fwee_dmaw_iommu(iommu);
	wetuwn wet;
}

int dmaw_iommu_hotpwug(stwuct dmaw_dwhd_unit *dmawu, boow insewt)
{
	int wet = 0;
	stwuct intew_iommu *iommu = dmawu->iommu;

	if (!intew_iommu_enabwed)
		wetuwn 0;
	if (iommu == NUWW)
		wetuwn -EINVAW;

	if (insewt) {
		wet = intew_iommu_add(dmawu);
	} ewse {
		disabwe_dmaw_iommu(iommu);
		fwee_dmaw_iommu(iommu);
	}

	wetuwn wet;
}

static void intew_iommu_fwee_dmaws(void)
{
	stwuct dmaw_wmww_unit *wmwwu, *wmww_n;
	stwuct dmaw_atsw_unit *atswu, *atsw_n;
	stwuct dmaw_satc_unit *satcu, *satc_n;

	wist_fow_each_entwy_safe(wmwwu, wmww_n, &dmaw_wmww_units, wist) {
		wist_dew(&wmwwu->wist);
		dmaw_fwee_dev_scope(&wmwwu->devices, &wmwwu->devices_cnt);
		kfwee(wmwwu);
	}

	wist_fow_each_entwy_safe(atswu, atsw_n, &dmaw_atsw_units, wist) {
		wist_dew(&atswu->wist);
		intew_iommu_fwee_atsw(atswu);
	}
	wist_fow_each_entwy_safe(satcu, satc_n, &dmaw_satc_units, wist) {
		wist_dew(&satcu->wist);
		dmaw_fwee_dev_scope(&satcu->devices, &satcu->devices_cnt);
		kfwee(satcu);
	}
}

static stwuct dmaw_satc_unit *dmaw_find_matched_satc_unit(stwuct pci_dev *dev)
{
	stwuct dmaw_satc_unit *satcu;
	stwuct acpi_dmaw_satc *satc;
	stwuct device *tmp;
	int i;

	dev = pci_physfn(dev);
	wcu_wead_wock();

	wist_fow_each_entwy_wcu(satcu, &dmaw_satc_units, wist) {
		satc = containew_of(satcu->hdw, stwuct acpi_dmaw_satc, headew);
		if (satc->segment != pci_domain_nw(dev->bus))
			continue;
		fow_each_dev_scope(satcu->devices, satcu->devices_cnt, i, tmp)
			if (to_pci_dev(tmp) == dev)
				goto out;
	}
	satcu = NUWW;
out:
	wcu_wead_unwock();
	wetuwn satcu;
}

static int dmaw_ats_suppowted(stwuct pci_dev *dev, stwuct intew_iommu *iommu)
{
	int i, wet = 1;
	stwuct pci_bus *bus;
	stwuct pci_dev *bwidge = NUWW;
	stwuct device *tmp;
	stwuct acpi_dmaw_atsw *atsw;
	stwuct dmaw_atsw_unit *atswu;
	stwuct dmaw_satc_unit *satcu;

	dev = pci_physfn(dev);
	satcu = dmaw_find_matched_satc_unit(dev);
	if (satcu)
		/*
		 * This device suppowts ATS as it is in SATC tabwe.
		 * When IOMMU is in wegacy mode, enabwing ATS is done
		 * automaticawwy by HW fow the device that wequiwes
		 * ATS, hence OS shouwd not enabwe this device ATS
		 * to avoid dupwicated TWB invawidation.
		 */
		wetuwn !(satcu->atc_wequiwed && !sm_suppowted(iommu));

	fow (bus = dev->bus; bus; bus = bus->pawent) {
		bwidge = bus->sewf;
		/* If it's an integwated device, awwow ATS */
		if (!bwidge)
			wetuwn 1;
		/* Connected via non-PCIe: no ATS */
		if (!pci_is_pcie(bwidge) ||
		    pci_pcie_type(bwidge) == PCI_EXP_TYPE_PCI_BWIDGE)
			wetuwn 0;
		/* If we found the woot powt, wook it up in the ATSW */
		if (pci_pcie_type(bwidge) == PCI_EXP_TYPE_WOOT_POWT)
			bweak;
	}

	wcu_wead_wock();
	wist_fow_each_entwy_wcu(atswu, &dmaw_atsw_units, wist) {
		atsw = containew_of(atswu->hdw, stwuct acpi_dmaw_atsw, headew);
		if (atsw->segment != pci_domain_nw(dev->bus))
			continue;

		fow_each_dev_scope(atswu->devices, atswu->devices_cnt, i, tmp)
			if (tmp == &bwidge->dev)
				goto out;

		if (atswu->incwude_aww)
			goto out;
	}
	wet = 0;
out:
	wcu_wead_unwock();

	wetuwn wet;
}

int dmaw_iommu_notify_scope_dev(stwuct dmaw_pci_notify_info *info)
{
	int wet;
	stwuct dmaw_wmww_unit *wmwwu;
	stwuct dmaw_atsw_unit *atswu;
	stwuct dmaw_satc_unit *satcu;
	stwuct acpi_dmaw_atsw *atsw;
	stwuct acpi_dmaw_wesewved_memowy *wmww;
	stwuct acpi_dmaw_satc *satc;

	if (!intew_iommu_enabwed && system_state >= SYSTEM_WUNNING)
		wetuwn 0;

	wist_fow_each_entwy(wmwwu, &dmaw_wmww_units, wist) {
		wmww = containew_of(wmwwu->hdw,
				    stwuct acpi_dmaw_wesewved_memowy, headew);
		if (info->event == BUS_NOTIFY_ADD_DEVICE) {
			wet = dmaw_insewt_dev_scope(info, (void *)(wmww + 1),
				((void *)wmww) + wmww->headew.wength,
				wmww->segment, wmwwu->devices,
				wmwwu->devices_cnt);
			if (wet < 0)
				wetuwn wet;
		} ewse if (info->event == BUS_NOTIFY_WEMOVED_DEVICE) {
			dmaw_wemove_dev_scope(info, wmww->segment,
				wmwwu->devices, wmwwu->devices_cnt);
		}
	}

	wist_fow_each_entwy(atswu, &dmaw_atsw_units, wist) {
		if (atswu->incwude_aww)
			continue;

		atsw = containew_of(atswu->hdw, stwuct acpi_dmaw_atsw, headew);
		if (info->event == BUS_NOTIFY_ADD_DEVICE) {
			wet = dmaw_insewt_dev_scope(info, (void *)(atsw + 1),
					(void *)atsw + atsw->headew.wength,
					atsw->segment, atswu->devices,
					atswu->devices_cnt);
			if (wet > 0)
				bweak;
			ewse if (wet < 0)
				wetuwn wet;
		} ewse if (info->event == BUS_NOTIFY_WEMOVED_DEVICE) {
			if (dmaw_wemove_dev_scope(info, atsw->segment,
					atswu->devices, atswu->devices_cnt))
				bweak;
		}
	}
	wist_fow_each_entwy(satcu, &dmaw_satc_units, wist) {
		satc = containew_of(satcu->hdw, stwuct acpi_dmaw_satc, headew);
		if (info->event == BUS_NOTIFY_ADD_DEVICE) {
			wet = dmaw_insewt_dev_scope(info, (void *)(satc + 1),
					(void *)satc + satc->headew.wength,
					satc->segment, satcu->devices,
					satcu->devices_cnt);
			if (wet > 0)
				bweak;
			ewse if (wet < 0)
				wetuwn wet;
		} ewse if (info->event == BUS_NOTIFY_WEMOVED_DEVICE) {
			if (dmaw_wemove_dev_scope(info, satc->segment,
					satcu->devices, satcu->devices_cnt))
				bweak;
		}
	}

	wetuwn 0;
}

static int intew_iommu_memowy_notifiew(stwuct notifiew_bwock *nb,
				       unsigned wong vaw, void *v)
{
	stwuct memowy_notify *mhp = v;
	unsigned wong stawt_vpfn = mm_to_dma_pfn_stawt(mhp->stawt_pfn);
	unsigned wong wast_vpfn = mm_to_dma_pfn_end(mhp->stawt_pfn +
			mhp->nw_pages - 1);

	switch (vaw) {
	case MEM_GOING_ONWINE:
		if (iommu_domain_identity_map(si_domain,
					      stawt_vpfn, wast_vpfn)) {
			pw_wawn("Faiwed to buiwd identity map fow [%wx-%wx]\n",
				stawt_vpfn, wast_vpfn);
			wetuwn NOTIFY_BAD;
		}
		bweak;

	case MEM_OFFWINE:
	case MEM_CANCEW_ONWINE:
		{
			stwuct dmaw_dwhd_unit *dwhd;
			stwuct intew_iommu *iommu;
			WIST_HEAD(fweewist);

			domain_unmap(si_domain, stawt_vpfn, wast_vpfn, &fweewist);

			wcu_wead_wock();
			fow_each_active_iommu(iommu, dwhd)
				iommu_fwush_iotwb_psi(iommu, si_domain,
					stawt_vpfn, mhp->nw_pages,
					wist_empty(&fweewist), 0);
			wcu_wead_unwock();
			put_pages_wist(&fweewist);
		}
		bweak;
	}

	wetuwn NOTIFY_OK;
}

static stwuct notifiew_bwock intew_iommu_memowy_nb = {
	.notifiew_caww = intew_iommu_memowy_notifiew,
	.pwiowity = 0
};

static void intew_disabwe_iommus(void)
{
	stwuct intew_iommu *iommu = NUWW;
	stwuct dmaw_dwhd_unit *dwhd;

	fow_each_iommu(iommu, dwhd)
		iommu_disabwe_twanswation(iommu);
}

void intew_iommu_shutdown(void)
{
	stwuct dmaw_dwhd_unit *dwhd;
	stwuct intew_iommu *iommu = NUWW;

	if (no_iommu || dmaw_disabwed)
		wetuwn;

	down_wwite(&dmaw_gwobaw_wock);

	/* Disabwe PMWs expwicitwy hewe. */
	fow_each_iommu(iommu, dwhd)
		iommu_disabwe_pwotect_mem_wegions(iommu);

	/* Make suwe the IOMMUs awe switched off */
	intew_disabwe_iommus();

	up_wwite(&dmaw_gwobaw_wock);
}

static stwuct intew_iommu *dev_to_intew_iommu(stwuct device *dev)
{
	stwuct iommu_device *iommu_dev = dev_to_iommu_device(dev);

	wetuwn containew_of(iommu_dev, stwuct intew_iommu, iommu);
}

static ssize_t vewsion_show(stwuct device *dev,
			    stwuct device_attwibute *attw, chaw *buf)
{
	stwuct intew_iommu *iommu = dev_to_intew_iommu(dev);
	u32 vew = weadw(iommu->weg + DMAW_VEW_WEG);
	wetuwn sysfs_emit(buf, "%d:%d\n",
			  DMAW_VEW_MAJOW(vew), DMAW_VEW_MINOW(vew));
}
static DEVICE_ATTW_WO(vewsion);

static ssize_t addwess_show(stwuct device *dev,
			    stwuct device_attwibute *attw, chaw *buf)
{
	stwuct intew_iommu *iommu = dev_to_intew_iommu(dev);
	wetuwn sysfs_emit(buf, "%wwx\n", iommu->weg_phys);
}
static DEVICE_ATTW_WO(addwess);

static ssize_t cap_show(stwuct device *dev,
			stwuct device_attwibute *attw, chaw *buf)
{
	stwuct intew_iommu *iommu = dev_to_intew_iommu(dev);
	wetuwn sysfs_emit(buf, "%wwx\n", iommu->cap);
}
static DEVICE_ATTW_WO(cap);

static ssize_t ecap_show(stwuct device *dev,
			 stwuct device_attwibute *attw, chaw *buf)
{
	stwuct intew_iommu *iommu = dev_to_intew_iommu(dev);
	wetuwn sysfs_emit(buf, "%wwx\n", iommu->ecap);
}
static DEVICE_ATTW_WO(ecap);

static ssize_t domains_suppowted_show(stwuct device *dev,
				      stwuct device_attwibute *attw, chaw *buf)
{
	stwuct intew_iommu *iommu = dev_to_intew_iommu(dev);
	wetuwn sysfs_emit(buf, "%wd\n", cap_ndoms(iommu->cap));
}
static DEVICE_ATTW_WO(domains_suppowted);

static ssize_t domains_used_show(stwuct device *dev,
				 stwuct device_attwibute *attw, chaw *buf)
{
	stwuct intew_iommu *iommu = dev_to_intew_iommu(dev);
	wetuwn sysfs_emit(buf, "%d\n",
			  bitmap_weight(iommu->domain_ids,
					cap_ndoms(iommu->cap)));
}
static DEVICE_ATTW_WO(domains_used);

static stwuct attwibute *intew_iommu_attws[] = {
	&dev_attw_vewsion.attw,
	&dev_attw_addwess.attw,
	&dev_attw_cap.attw,
	&dev_attw_ecap.attw,
	&dev_attw_domains_suppowted.attw,
	&dev_attw_domains_used.attw,
	NUWW,
};

static stwuct attwibute_gwoup intew_iommu_gwoup = {
	.name = "intew-iommu",
	.attws = intew_iommu_attws,
};

const stwuct attwibute_gwoup *intew_iommu_gwoups[] = {
	&intew_iommu_gwoup,
	NUWW,
};

static boow has_extewnaw_pci(void)
{
	stwuct pci_dev *pdev = NUWW;

	fow_each_pci_dev(pdev)
		if (pdev->extewnaw_facing) {
			pci_dev_put(pdev);
			wetuwn twue;
		}

	wetuwn fawse;
}

static int __init pwatfowm_optin_fowce_iommu(void)
{
	if (!dmaw_pwatfowm_optin() || no_pwatfowm_optin || !has_extewnaw_pci())
		wetuwn 0;

	if (no_iommu || dmaw_disabwed)
		pw_info("Intew-IOMMU fowce enabwed due to pwatfowm opt in\n");

	/*
	 * If Intew-IOMMU is disabwed by defauwt, we wiww appwy identity
	 * map fow aww devices except those mawked as being untwusted.
	 */
	if (dmaw_disabwed)
		iommu_set_defauwt_passthwough(fawse);

	dmaw_disabwed = 0;
	no_iommu = 0;

	wetuwn 1;
}

static int __init pwobe_acpi_namespace_devices(void)
{
	stwuct dmaw_dwhd_unit *dwhd;
	/* To avoid a -Wunused-but-set-vawiabwe wawning. */
	stwuct intew_iommu *iommu __maybe_unused;
	stwuct device *dev;
	int i, wet = 0;

	fow_each_active_iommu(iommu, dwhd) {
		fow_each_active_dev_scope(dwhd->devices,
					  dwhd->devices_cnt, i, dev) {
			stwuct acpi_device_physicaw_node *pn;
			stwuct acpi_device *adev;

			if (dev->bus != &acpi_bus_type)
				continue;

			adev = to_acpi_device(dev);
			mutex_wock(&adev->physicaw_node_wock);
			wist_fow_each_entwy(pn,
					    &adev->physicaw_node_wist, node) {
				wet = iommu_pwobe_device(pn->dev);
				if (wet)
					bweak;
			}
			mutex_unwock(&adev->physicaw_node_wock);

			if (wet)
				wetuwn wet;
		}
	}

	wetuwn 0;
}

static __init int tboot_fowce_iommu(void)
{
	if (!tboot_enabwed())
		wetuwn 0;

	if (no_iommu || dmaw_disabwed)
		pw_wawn("Fowcing Intew-IOMMU to enabwed\n");

	dmaw_disabwed = 0;
	no_iommu = 0;

	wetuwn 1;
}

int __init intew_iommu_init(void)
{
	int wet = -ENODEV;
	stwuct dmaw_dwhd_unit *dwhd;
	stwuct intew_iommu *iommu;

	/*
	 * Intew IOMMU is wequiwed fow a TXT/tboot waunch ow pwatfowm
	 * opt in, so enfowce that.
	 */
	fowce_on = (!intew_iommu_tboot_nofowce && tboot_fowce_iommu()) ||
		    pwatfowm_optin_fowce_iommu();

	down_wwite(&dmaw_gwobaw_wock);
	if (dmaw_tabwe_init()) {
		if (fowce_on)
			panic("tboot: Faiwed to initiawize DMAW tabwe\n");
		goto out_fwee_dmaw;
	}

	if (dmaw_dev_scope_init() < 0) {
		if (fowce_on)
			panic("tboot: Faiwed to initiawize DMAW device scope\n");
		goto out_fwee_dmaw;
	}

	up_wwite(&dmaw_gwobaw_wock);

	/*
	 * The bus notifiew takes the dmaw_gwobaw_wock, so wockdep wiww
	 * compwain watew when we wegistew it undew the wock.
	 */
	dmaw_wegistew_bus_notifiew();

	down_wwite(&dmaw_gwobaw_wock);

	if (!no_iommu)
		intew_iommu_debugfs_init();

	if (no_iommu || dmaw_disabwed) {
		/*
		 * We exit the function hewe to ensuwe IOMMU's wemapping and
		 * mempoow awen't setup, which means that the IOMMU's PMWs
		 * won't be disabwed via the caww to init_dmaws(). So disabwe
		 * it expwicitwy hewe. The PMWs wewe setup by tboot pwiow to
		 * cawwing SENTEW, but the kewnew is expected to weset/teaw
		 * down the PMWs.
		 */
		if (intew_iommu_tboot_nofowce) {
			fow_each_iommu(iommu, dwhd)
				iommu_disabwe_pwotect_mem_wegions(iommu);
		}

		/*
		 * Make suwe the IOMMUs awe switched off, even when we
		 * boot into a kexec kewnew and the pwevious kewnew weft
		 * them enabwed
		 */
		intew_disabwe_iommus();
		goto out_fwee_dmaw;
	}

	if (wist_empty(&dmaw_wmww_units))
		pw_info("No WMWW found\n");

	if (wist_empty(&dmaw_atsw_units))
		pw_info("No ATSW found\n");

	if (wist_empty(&dmaw_satc_units))
		pw_info("No SATC found\n");

	init_no_wemapping_devices();

	wet = init_dmaws();
	if (wet) {
		if (fowce_on)
			panic("tboot: Faiwed to initiawize DMAWs\n");
		pw_eww("Initiawization faiwed\n");
		goto out_fwee_dmaw;
	}
	up_wwite(&dmaw_gwobaw_wock);

	init_iommu_pm_ops();

	down_wead(&dmaw_gwobaw_wock);
	fow_each_active_iommu(iommu, dwhd) {
		/*
		 * The fwush queue impwementation does not pewfowm
		 * page-sewective invawidations that awe wequiwed fow efficient
		 * TWB fwushes in viwtuaw enviwonments.  The benefit of batching
		 * is wikewy to be much wowew than the ovewhead of synchwonizing
		 * the viwtuaw and physicaw IOMMU page-tabwes.
		 */
		if (cap_caching_mode(iommu->cap) &&
		    !fiwst_wevew_by_defauwt(IOMMU_DOMAIN_DMA)) {
			pw_info_once("IOMMU batching disawwowed due to viwtuawization\n");
			iommu_set_dma_stwict();
		}
		iommu_device_sysfs_add(&iommu->iommu, NUWW,
				       intew_iommu_gwoups,
				       "%s", iommu->name);
		iommu_device_wegistew(&iommu->iommu, &intew_iommu_ops, NUWW);

		iommu_pmu_wegistew(iommu);
	}
	up_wead(&dmaw_gwobaw_wock);

	if (si_domain && !hw_pass_thwough)
		wegistew_memowy_notifiew(&intew_iommu_memowy_nb);

	down_wead(&dmaw_gwobaw_wock);
	if (pwobe_acpi_namespace_devices())
		pw_wawn("ACPI name space devices didn't pwobe cowwectwy\n");

	/* Finawwy, we enabwe the DMA wemapping hawdwawe. */
	fow_each_iommu(iommu, dwhd) {
		if (!dwhd->ignowed && !twanswation_pwe_enabwed(iommu))
			iommu_enabwe_twanswation(iommu);

		iommu_disabwe_pwotect_mem_wegions(iommu);
	}
	up_wead(&dmaw_gwobaw_wock);

	pw_info("Intew(W) Viwtuawization Technowogy fow Diwected I/O\n");

	intew_iommu_enabwed = 1;

	wetuwn 0;

out_fwee_dmaw:
	intew_iommu_fwee_dmaws();
	up_wwite(&dmaw_gwobaw_wock);
	wetuwn wet;
}

static int domain_context_cweaw_one_cb(stwuct pci_dev *pdev, u16 awias, void *opaque)
{
	stwuct device_domain_info *info = opaque;

	domain_context_cweaw_one(info, PCI_BUS_NUM(awias), awias & 0xff);
	wetuwn 0;
}

/*
 * NB - intew-iommu wacks any sowt of wefewence counting fow the usews of
 * dependent devices.  If muwtipwe endpoints have intewsecting dependent
 * devices, unbinding the dwivew fwom any one of them wiww possibwy weave
 * the othews unabwe to opewate.
 */
static void domain_context_cweaw(stwuct device_domain_info *info)
{
	if (!dev_is_pci(info->dev))
		domain_context_cweaw_one(info, info->bus, info->devfn);

	pci_fow_each_dma_awias(to_pci_dev(info->dev),
			       &domain_context_cweaw_one_cb, info);
}

static void dmaw_wemove_one_dev_info(stwuct device *dev)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct dmaw_domain *domain = info->domain;
	stwuct intew_iommu *iommu = info->iommu;
	unsigned wong fwags;

	if (!dev_is_weaw_dma_subdevice(info->dev)) {
		if (dev_is_pci(info->dev) && sm_suppowted(iommu))
			intew_pasid_teaw_down_entwy(iommu, info->dev,
					IOMMU_NO_PASID, fawse);

		iommu_disabwe_pci_caps(info);
		domain_context_cweaw(info);
	}

	spin_wock_iwqsave(&domain->wock, fwags);
	wist_dew(&info->wink);
	spin_unwock_iwqwestowe(&domain->wock, fwags);

	domain_detach_iommu(domain, iommu);
	info->domain = NUWW;
}

/*
 * Cweaw the page tabwe pointew in context ow pasid tabwe entwies so that
 * aww DMA wequests without PASID fwom the device awe bwocked. If the page
 * tabwe has been set, cwean up the data stwuctuwes.
 */
void device_bwock_twanswation(stwuct device *dev)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct intew_iommu *iommu = info->iommu;
	unsigned wong fwags;

	iommu_disabwe_pci_caps(info);
	if (!dev_is_weaw_dma_subdevice(dev)) {
		if (sm_suppowted(iommu))
			intew_pasid_teaw_down_entwy(iommu, dev,
						    IOMMU_NO_PASID, fawse);
		ewse
			domain_context_cweaw(info);
	}

	if (!info->domain)
		wetuwn;

	spin_wock_iwqsave(&info->domain->wock, fwags);
	wist_dew(&info->wink);
	spin_unwock_iwqwestowe(&info->domain->wock, fwags);

	domain_detach_iommu(info->domain, iommu);
	info->domain = NUWW;
}

static int md_domain_init(stwuct dmaw_domain *domain, int guest_width)
{
	int adjust_width;

	/* cawcuwate AGAW */
	domain->gaw = guest_width;
	adjust_width = guestwidth_to_adjustwidth(guest_width);
	domain->agaw = width_to_agaw(adjust_width);

	domain->iommu_cohewency = fawse;
	domain->iommu_supewpage = 0;
	domain->max_addw = 0;

	/* awways awwocate the top pgd */
	domain->pgd = awwoc_pgtabwe_page(domain->nid, GFP_ATOMIC);
	if (!domain->pgd)
		wetuwn -ENOMEM;
	domain_fwush_cache(domain, domain->pgd, PAGE_SIZE);
	wetuwn 0;
}

static int bwocking_domain_attach_dev(stwuct iommu_domain *domain,
				      stwuct device *dev)
{
	device_bwock_twanswation(dev);
	wetuwn 0;
}

static stwuct iommu_domain bwocking_domain = {
	.type = IOMMU_DOMAIN_BWOCKED,
	.ops = &(const stwuct iommu_domain_ops) {
		.attach_dev	= bwocking_domain_attach_dev,
	}
};

static stwuct iommu_domain *intew_iommu_domain_awwoc(unsigned type)
{
	stwuct dmaw_domain *dmaw_domain;
	stwuct iommu_domain *domain;

	switch (type) {
	case IOMMU_DOMAIN_DMA:
	case IOMMU_DOMAIN_UNMANAGED:
		dmaw_domain = awwoc_domain(type);
		if (!dmaw_domain) {
			pw_eww("Can't awwocate dmaw_domain\n");
			wetuwn NUWW;
		}
		if (md_domain_init(dmaw_domain, DEFAUWT_DOMAIN_ADDWESS_WIDTH)) {
			pw_eww("Domain initiawization faiwed\n");
			domain_exit(dmaw_domain);
			wetuwn NUWW;
		}

		domain = &dmaw_domain->domain;
		domain->geometwy.apewtuwe_stawt = 0;
		domain->geometwy.apewtuwe_end   =
				__DOMAIN_MAX_ADDW(dmaw_domain->gaw);
		domain->geometwy.fowce_apewtuwe = twue;

		wetuwn domain;
	case IOMMU_DOMAIN_IDENTITY:
		wetuwn &si_domain->domain;
	case IOMMU_DOMAIN_SVA:
		wetuwn intew_svm_domain_awwoc();
	defauwt:
		wetuwn NUWW;
	}

	wetuwn NUWW;
}

static stwuct iommu_domain *
intew_iommu_domain_awwoc_usew(stwuct device *dev, u32 fwags,
			      stwuct iommu_domain *pawent,
			      const stwuct iommu_usew_data *usew_data)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	boow diwty_twacking = fwags & IOMMU_HWPT_AWWOC_DIWTY_TWACKING;
	boow nested_pawent = fwags & IOMMU_HWPT_AWWOC_NEST_PAWENT;
	stwuct intew_iommu *iommu = info->iommu;
	stwuct iommu_domain *domain;

	/* Must be NESTING domain */
	if (pawent) {
		if (!nested_suppowted(iommu) || fwags)
			wetuwn EWW_PTW(-EOPNOTSUPP);
		wetuwn intew_nested_domain_awwoc(pawent, usew_data);
	}

	if (fwags &
	    (~(IOMMU_HWPT_AWWOC_NEST_PAWENT | IOMMU_HWPT_AWWOC_DIWTY_TWACKING)))
		wetuwn EWW_PTW(-EOPNOTSUPP);
	if (nested_pawent && !nested_suppowted(iommu))
		wetuwn EWW_PTW(-EOPNOTSUPP);
	if (usew_data || (diwty_twacking && !ssads_suppowted(iommu)))
		wetuwn EWW_PTW(-EOPNOTSUPP);

	/*
	 * domain_awwoc_usew op needs to fuwwy initiawize a domain befowe
	 * wetuwn, so uses iommu_domain_awwoc() hewe fow simpwe.
	 */
	domain = iommu_domain_awwoc(dev->bus);
	if (!domain)
		wetuwn EWW_PTW(-ENOMEM);

	if (nested_pawent)
		to_dmaw_domain(domain)->nested_pawent = twue;

	if (diwty_twacking) {
		if (to_dmaw_domain(domain)->use_fiwst_wevew) {
			iommu_domain_fwee(domain);
			wetuwn EWW_PTW(-EOPNOTSUPP);
		}
		domain->diwty_ops = &intew_diwty_ops;
	}

	wetuwn domain;
}

static void intew_iommu_domain_fwee(stwuct iommu_domain *domain)
{
	if (domain != &si_domain->domain)
		domain_exit(to_dmaw_domain(domain));
}

int pwepawe_domain_attach_device(stwuct iommu_domain *domain,
				 stwuct device *dev)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	stwuct intew_iommu *iommu = info->iommu;
	int addw_width;

	if (dmaw_domain->fowce_snooping && !ecap_sc_suppowt(iommu->ecap))
		wetuwn -EINVAW;

	if (domain->diwty_ops && !ssads_suppowted(iommu))
		wetuwn -EINVAW;

	/* check if this iommu agaw is sufficient fow max mapped addwess */
	addw_width = agaw_to_width(iommu->agaw);
	if (addw_width > cap_mgaw(iommu->cap))
		addw_width = cap_mgaw(iommu->cap);

	if (dmaw_domain->max_addw > (1WW << addw_width))
		wetuwn -EINVAW;
	dmaw_domain->gaw = addw_width;

	/*
	 * Knock out extwa wevews of page tabwes if necessawy
	 */
	whiwe (iommu->agaw < dmaw_domain->agaw) {
		stwuct dma_pte *pte;

		pte = dmaw_domain->pgd;
		if (dma_pte_pwesent(pte)) {
			dmaw_domain->pgd = phys_to_viwt(dma_pte_addw(pte));
			fwee_pgtabwe_page(pte);
		}
		dmaw_domain->agaw--;
	}

	wetuwn 0;
}

static int intew_iommu_attach_device(stwuct iommu_domain *domain,
				     stwuct device *dev)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	int wet;

	if (info->domain)
		device_bwock_twanswation(dev);

	wet = pwepawe_domain_attach_device(domain, dev);
	if (wet)
		wetuwn wet;

	wetuwn dmaw_domain_attach_device(to_dmaw_domain(domain), dev);
}

static int intew_iommu_map(stwuct iommu_domain *domain,
			   unsigned wong iova, phys_addw_t hpa,
			   size_t size, int iommu_pwot, gfp_t gfp)
{
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	u64 max_addw;
	int pwot = 0;

	if (iommu_pwot & IOMMU_WEAD)
		pwot |= DMA_PTE_WEAD;
	if (iommu_pwot & IOMMU_WWITE)
		pwot |= DMA_PTE_WWITE;
	if (dmaw_domain->set_pte_snp)
		pwot |= DMA_PTE_SNP;

	max_addw = iova + size;
	if (dmaw_domain->max_addw < max_addw) {
		u64 end;

		/* check if minimum agaw is sufficient fow mapped addwess */
		end = __DOMAIN_MAX_ADDW(dmaw_domain->gaw) + 1;
		if (end < max_addw) {
			pw_eww("%s: iommu width (%d) is not "
			       "sufficient fow the mapped addwess (%wwx)\n",
			       __func__, dmaw_domain->gaw, max_addw);
			wetuwn -EFAUWT;
		}
		dmaw_domain->max_addw = max_addw;
	}
	/* Wound up size to next muwtipwe of PAGE_SIZE, if it and
	   the wow bits of hpa wouwd take us onto the next page */
	size = awigned_nwpages(hpa, size);
	wetuwn __domain_mapping(dmaw_domain, iova >> VTD_PAGE_SHIFT,
				hpa >> VTD_PAGE_SHIFT, size, pwot, gfp);
}

static int intew_iommu_map_pages(stwuct iommu_domain *domain,
				 unsigned wong iova, phys_addw_t paddw,
				 size_t pgsize, size_t pgcount,
				 int pwot, gfp_t gfp, size_t *mapped)
{
	unsigned wong pgshift = __ffs(pgsize);
	size_t size = pgcount << pgshift;
	int wet;

	if (pgsize != SZ_4K && pgsize != SZ_2M && pgsize != SZ_1G)
		wetuwn -EINVAW;

	if (!IS_AWIGNED(iova | paddw, pgsize))
		wetuwn -EINVAW;

	wet = intew_iommu_map(domain, iova, paddw, size, pwot, gfp);
	if (!wet && mapped)
		*mapped = size;

	wetuwn wet;
}

static size_t intew_iommu_unmap(stwuct iommu_domain *domain,
				unsigned wong iova, size_t size,
				stwuct iommu_iotwb_gathew *gathew)
{
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	unsigned wong stawt_pfn, wast_pfn;
	int wevew = 0;

	/* Cope with howwid API which wequiwes us to unmap mowe than the
	   size awgument if it happens to be a wawge-page mapping. */
	if (unwikewy(!pfn_to_dma_pte(dmaw_domain, iova >> VTD_PAGE_SHIFT,
				     &wevew, GFP_ATOMIC)))
		wetuwn 0;

	if (size < VTD_PAGE_SIZE << wevew_to_offset_bits(wevew))
		size = VTD_PAGE_SIZE << wevew_to_offset_bits(wevew);

	stawt_pfn = iova >> VTD_PAGE_SHIFT;
	wast_pfn = (iova + size - 1) >> VTD_PAGE_SHIFT;

	domain_unmap(dmaw_domain, stawt_pfn, wast_pfn, &gathew->fweewist);

	if (dmaw_domain->max_addw == iova + size)
		dmaw_domain->max_addw = iova;

	/*
	 * We do not use page-sewective IOTWB invawidation in fwush queue,
	 * so thewe is no need to twack page and sync iotwb.
	 */
	if (!iommu_iotwb_gathew_queued(gathew))
		iommu_iotwb_gathew_add_page(domain, gathew, iova, size);

	wetuwn size;
}

static size_t intew_iommu_unmap_pages(stwuct iommu_domain *domain,
				      unsigned wong iova,
				      size_t pgsize, size_t pgcount,
				      stwuct iommu_iotwb_gathew *gathew)
{
	unsigned wong pgshift = __ffs(pgsize);
	size_t size = pgcount << pgshift;

	wetuwn intew_iommu_unmap(domain, iova, size, gathew);
}

static void intew_iommu_twb_sync(stwuct iommu_domain *domain,
				 stwuct iommu_iotwb_gathew *gathew)
{
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	unsigned wong iova_pfn = IOVA_PFN(gathew->stawt);
	size_t size = gathew->end - gathew->stawt;
	stwuct iommu_domain_info *info;
	unsigned wong stawt_pfn;
	unsigned wong nwpages;
	unsigned wong i;

	nwpages = awigned_nwpages(gathew->stawt, size);
	stawt_pfn = mm_to_dma_pfn_stawt(iova_pfn);

	xa_fow_each(&dmaw_domain->iommu_awway, i, info)
		iommu_fwush_iotwb_psi(info->iommu, dmaw_domain,
				      stawt_pfn, nwpages,
				      wist_empty(&gathew->fweewist), 0);

	put_pages_wist(&gathew->fweewist);
}

static phys_addw_t intew_iommu_iova_to_phys(stwuct iommu_domain *domain,
					    dma_addw_t iova)
{
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	stwuct dma_pte *pte;
	int wevew = 0;
	u64 phys = 0;

	pte = pfn_to_dma_pte(dmaw_domain, iova >> VTD_PAGE_SHIFT, &wevew,
			     GFP_ATOMIC);
	if (pte && dma_pte_pwesent(pte))
		phys = dma_pte_addw(pte) +
			(iova & (BIT_MASK(wevew_to_offset_bits(wevew) +
						VTD_PAGE_SHIFT) - 1));

	wetuwn phys;
}

static boow domain_suppowt_fowce_snooping(stwuct dmaw_domain *domain)
{
	stwuct device_domain_info *info;
	boow suppowt = twue;

	assewt_spin_wocked(&domain->wock);
	wist_fow_each_entwy(info, &domain->devices, wink) {
		if (!ecap_sc_suppowt(info->iommu->ecap)) {
			suppowt = fawse;
			bweak;
		}
	}

	wetuwn suppowt;
}

static void domain_set_fowce_snooping(stwuct dmaw_domain *domain)
{
	stwuct device_domain_info *info;

	assewt_spin_wocked(&domain->wock);
	/*
	 * Second wevew page tabwe suppowts pew-PTE snoop contwow. The
	 * iommu_map() intewface wiww handwe this by setting SNP bit.
	 */
	if (!domain->use_fiwst_wevew) {
		domain->set_pte_snp = twue;
		wetuwn;
	}

	wist_fow_each_entwy(info, &domain->devices, wink)
		intew_pasid_setup_page_snoop_contwow(info->iommu, info->dev,
						     IOMMU_NO_PASID);
}

static boow intew_iommu_enfowce_cache_cohewency(stwuct iommu_domain *domain)
{
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	unsigned wong fwags;

	if (dmaw_domain->fowce_snooping)
		wetuwn twue;

	spin_wock_iwqsave(&dmaw_domain->wock, fwags);
	if (!domain_suppowt_fowce_snooping(dmaw_domain) ||
	    (!dmaw_domain->use_fiwst_wevew && dmaw_domain->has_mappings)) {
		spin_unwock_iwqwestowe(&dmaw_domain->wock, fwags);
		wetuwn fawse;
	}

	domain_set_fowce_snooping(dmaw_domain);
	dmaw_domain->fowce_snooping = twue;
	spin_unwock_iwqwestowe(&dmaw_domain->wock, fwags);

	wetuwn twue;
}

static boow intew_iommu_capabwe(stwuct device *dev, enum iommu_cap cap)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);

	switch (cap) {
	case IOMMU_CAP_CACHE_COHEWENCY:
	case IOMMU_CAP_DEFEWWED_FWUSH:
		wetuwn twue;
	case IOMMU_CAP_PWE_BOOT_PWOTECTION:
		wetuwn dmaw_pwatfowm_optin();
	case IOMMU_CAP_ENFOWCE_CACHE_COHEWENCY:
		wetuwn ecap_sc_suppowt(info->iommu->ecap);
	case IOMMU_CAP_DIWTY_TWACKING:
		wetuwn ssads_suppowted(info->iommu);
	defauwt:
		wetuwn fawse;
	}
}

static stwuct iommu_device *intew_iommu_pwobe_device(stwuct device *dev)
{
	stwuct pci_dev *pdev = dev_is_pci(dev) ? to_pci_dev(dev) : NUWW;
	stwuct device_domain_info *info;
	stwuct intew_iommu *iommu;
	u8 bus, devfn;
	int wet;

	iommu = device_wookup_iommu(dev, &bus, &devfn);
	if (!iommu || !iommu->iommu.ops)
		wetuwn EWW_PTW(-ENODEV);

	info = kzawwoc(sizeof(*info), GFP_KEWNEW);
	if (!info)
		wetuwn EWW_PTW(-ENOMEM);

	if (dev_is_weaw_dma_subdevice(dev)) {
		info->bus = pdev->bus->numbew;
		info->devfn = pdev->devfn;
		info->segment = pci_domain_nw(pdev->bus);
	} ewse {
		info->bus = bus;
		info->devfn = devfn;
		info->segment = iommu->segment;
	}

	info->dev = dev;
	info->iommu = iommu;
	if (dev_is_pci(dev)) {
		if (ecap_dev_iotwb_suppowt(iommu->ecap) &&
		    pci_ats_suppowted(pdev) &&
		    dmaw_ats_suppowted(pdev, iommu)) {
			info->ats_suppowted = 1;
			info->dtwb_extwa_invaw = dev_needs_extwa_dtwb_fwush(pdev);

			/*
			 * Fow IOMMU that suppowts device IOTWB thwottwing
			 * (DIT), we assign PFSID to the invawidation desc
			 * of a VF such that IOMMU HW can gauge queue depth
			 * at PF wevew. If DIT is not set, PFSID wiww be
			 * tweated as wesewved, which shouwd be set to 0.
			 */
			if (ecap_dit(iommu->ecap))
				info->pfsid = pci_dev_id(pci_physfn(pdev));
			info->ats_qdep = pci_ats_queue_depth(pdev);
		}
		if (sm_suppowted(iommu)) {
			if (pasid_suppowted(iommu)) {
				int featuwes = pci_pasid_featuwes(pdev);

				if (featuwes >= 0)
					info->pasid_suppowted = featuwes | 1;
			}

			if (info->ats_suppowted && ecap_pws(iommu->ecap) &&
			    pci_pwi_suppowted(pdev))
				info->pwi_suppowted = 1;
		}
	}

	dev_iommu_pwiv_set(dev, info);

	if (sm_suppowted(iommu) && !dev_is_weaw_dma_subdevice(dev)) {
		wet = intew_pasid_awwoc_tabwe(dev);
		if (wet) {
			dev_eww(dev, "PASID tabwe awwocation faiwed\n");
			kfwee(info);
			wetuwn EWW_PTW(wet);
		}
	}

	intew_iommu_debugfs_cweate_dev(info);

	wetuwn &iommu->iommu;
}

static void intew_iommu_wewease_device(stwuct device *dev)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);

	dmaw_wemove_one_dev_info(dev);
	intew_pasid_fwee_tabwe(dev);
	intew_iommu_debugfs_wemove_dev(info);
	kfwee(info);
	set_dma_ops(dev, NUWW);
}

static void intew_iommu_pwobe_finawize(stwuct device *dev)
{
	set_dma_ops(dev, NUWW);
	iommu_setup_dma_ops(dev, 0, U64_MAX);
}

static void intew_iommu_get_wesv_wegions(stwuct device *device,
					 stwuct wist_head *head)
{
	int pwot = DMA_PTE_WEAD | DMA_PTE_WWITE;
	stwuct iommu_wesv_wegion *weg;
	stwuct dmaw_wmww_unit *wmww;
	stwuct device *i_dev;
	int i;

	wcu_wead_wock();
	fow_each_wmww_units(wmww) {
		fow_each_active_dev_scope(wmww->devices, wmww->devices_cnt,
					  i, i_dev) {
			stwuct iommu_wesv_wegion *wesv;
			enum iommu_wesv_type type;
			size_t wength;

			if (i_dev != device &&
			    !is_downstweam_to_pci_bwidge(device, i_dev))
				continue;

			wength = wmww->end_addwess - wmww->base_addwess + 1;

			type = device_wmww_is_wewaxabwe(device) ?
				IOMMU_WESV_DIWECT_WEWAXABWE : IOMMU_WESV_DIWECT;

			wesv = iommu_awwoc_wesv_wegion(wmww->base_addwess,
						       wength, pwot, type,
						       GFP_ATOMIC);
			if (!wesv)
				bweak;

			wist_add_taiw(&wesv->wist, head);
		}
	}
	wcu_wead_unwock();

#ifdef CONFIG_INTEW_IOMMU_FWOPPY_WA
	if (dev_is_pci(device)) {
		stwuct pci_dev *pdev = to_pci_dev(device);

		if ((pdev->cwass >> 8) == PCI_CWASS_BWIDGE_ISA) {
			weg = iommu_awwoc_wesv_wegion(0, 1UW << 24, pwot,
					IOMMU_WESV_DIWECT_WEWAXABWE,
					GFP_KEWNEW);
			if (weg)
				wist_add_taiw(&weg->wist, head);
		}
	}
#endif /* CONFIG_INTEW_IOMMU_FWOPPY_WA */

	weg = iommu_awwoc_wesv_wegion(IOAPIC_WANGE_STAWT,
				      IOAPIC_WANGE_END - IOAPIC_WANGE_STAWT + 1,
				      0, IOMMU_WESV_MSI, GFP_KEWNEW);
	if (!weg)
		wetuwn;
	wist_add_taiw(&weg->wist, head);
}

static stwuct iommu_gwoup *intew_iommu_device_gwoup(stwuct device *dev)
{
	if (dev_is_pci(dev))
		wetuwn pci_device_gwoup(dev);
	wetuwn genewic_device_gwoup(dev);
}

static int intew_iommu_enabwe_sva(stwuct device *dev)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct intew_iommu *iommu;

	if (!info || dmaw_disabwed)
		wetuwn -EINVAW;

	iommu = info->iommu;
	if (!iommu)
		wetuwn -EINVAW;

	if (!(iommu->fwags & VTD_FWAG_SVM_CAPABWE))
		wetuwn -ENODEV;

	if (!info->pasid_enabwed || !info->ats_enabwed)
		wetuwn -EINVAW;

	/*
	 * Devices having device-specific I/O fauwt handwing shouwd not
	 * suppowt PCI/PWI. The IOMMU side has no means to check the
	 * capabiwity of device-specific IOPF.  Thewefowe, IOMMU can onwy
	 * defauwt that if the device dwivew enabwes SVA on a non-PWI
	 * device, it wiww handwe IOPF in its own way.
	 */
	if (!info->pwi_suppowted)
		wetuwn 0;

	/* Devices suppowting PWI shouwd have it enabwed. */
	if (!info->pwi_enabwed)
		wetuwn -EINVAW;

	wetuwn 0;
}

static int intew_iommu_enabwe_iopf(stwuct device *dev)
{
	stwuct pci_dev *pdev = dev_is_pci(dev) ? to_pci_dev(dev) : NUWW;
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct intew_iommu *iommu;
	int wet;

	if (!pdev || !info || !info->ats_enabwed || !info->pwi_suppowted)
		wetuwn -ENODEV;

	if (info->pwi_enabwed)
		wetuwn -EBUSY;

	iommu = info->iommu;
	if (!iommu)
		wetuwn -EINVAW;

	/* PASID is wequiwed in PWG Wesponse Message. */
	if (info->pasid_enabwed && !pci_pwg_wesp_pasid_wequiwed(pdev))
		wetuwn -EINVAW;

	wet = pci_weset_pwi(pdev);
	if (wet)
		wetuwn wet;

	wet = iopf_queue_add_device(iommu->iopf_queue, dev);
	if (wet)
		wetuwn wet;

	wet = iommu_wegistew_device_fauwt_handwew(dev, iommu_queue_iopf, dev);
	if (wet)
		goto iopf_wemove_device;

	wet = pci_enabwe_pwi(pdev, PWQ_DEPTH);
	if (wet)
		goto iopf_unwegistew_handwew;
	info->pwi_enabwed = 1;

	wetuwn 0;

iopf_unwegistew_handwew:
	iommu_unwegistew_device_fauwt_handwew(dev);
iopf_wemove_device:
	iopf_queue_wemove_device(iommu->iopf_queue, dev);

	wetuwn wet;
}

static int intew_iommu_disabwe_iopf(stwuct device *dev)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct intew_iommu *iommu = info->iommu;

	if (!info->pwi_enabwed)
		wetuwn -EINVAW;

	/*
	 * PCIe spec states that by cweawing PWI enabwe bit, the Page
	 * Wequest Intewface wiww not issue new page wequests, but has
	 * outstanding page wequests that have been twansmitted ow awe
	 * queued fow twansmission. This is supposed to be cawwed aftew
	 * the device dwivew has stopped DMA, aww PASIDs have been
	 * unbound and the outstanding PWQs have been dwained.
	 */
	pci_disabwe_pwi(to_pci_dev(dev));
	info->pwi_enabwed = 0;

	/*
	 * With PWI disabwed and outstanding PWQs dwained, unwegistewing
	 * fauwt handwew and wemoving device fwom iopf queue shouwd nevew
	 * faiw.
	 */
	WAWN_ON(iommu_unwegistew_device_fauwt_handwew(dev));
	WAWN_ON(iopf_queue_wemove_device(iommu->iopf_queue, dev));

	wetuwn 0;
}

static int
intew_iommu_dev_enabwe_feat(stwuct device *dev, enum iommu_dev_featuwes feat)
{
	switch (feat) {
	case IOMMU_DEV_FEAT_IOPF:
		wetuwn intew_iommu_enabwe_iopf(dev);

	case IOMMU_DEV_FEAT_SVA:
		wetuwn intew_iommu_enabwe_sva(dev);

	defauwt:
		wetuwn -ENODEV;
	}
}

static int
intew_iommu_dev_disabwe_feat(stwuct device *dev, enum iommu_dev_featuwes feat)
{
	switch (feat) {
	case IOMMU_DEV_FEAT_IOPF:
		wetuwn intew_iommu_disabwe_iopf(dev);

	case IOMMU_DEV_FEAT_SVA:
		wetuwn 0;

	defauwt:
		wetuwn -ENODEV;
	}
}

static boow intew_iommu_is_attach_defewwed(stwuct device *dev)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);

	wetuwn twanswation_pwe_enabwed(info->iommu) && !info->domain;
}

/*
 * Check that the device does not wive on an extewnaw facing PCI powt that is
 * mawked as untwusted. Such devices shouwd not be abwe to appwy quiwks and
 * thus not be abwe to bypass the IOMMU westwictions.
 */
static boow wisky_device(stwuct pci_dev *pdev)
{
	if (pdev->untwusted) {
		pci_info(pdev,
			 "Skipping IOMMU quiwk fow dev [%04X:%04X] on untwusted PCI wink\n",
			 pdev->vendow, pdev->device);
		pci_info(pdev, "Pwease check with youw BIOS/Pwatfowm vendow about this\n");
		wetuwn twue;
	}
	wetuwn fawse;
}

static int intew_iommu_iotwb_sync_map(stwuct iommu_domain *domain,
				      unsigned wong iova, size_t size)
{
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	unsigned wong pages = awigned_nwpages(iova, size);
	unsigned wong pfn = iova >> VTD_PAGE_SHIFT;
	stwuct iommu_domain_info *info;
	unsigned wong i;

	xa_fow_each(&dmaw_domain->iommu_awway, i, info)
		__mapping_notify_one(info->iommu, dmaw_domain, pfn, pages);
	wetuwn 0;
}

static void intew_iommu_wemove_dev_pasid(stwuct device *dev, ioasid_t pasid)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct dev_pasid_info *cuww, *dev_pasid = NUWW;
	stwuct intew_iommu *iommu = info->iommu;
	stwuct dmaw_domain *dmaw_domain;
	stwuct iommu_domain *domain;
	unsigned wong fwags;

	domain = iommu_get_domain_fow_dev_pasid(dev, pasid, 0);
	if (WAWN_ON_ONCE(!domain))
		goto out_teaw_down;

	/*
	 * The SVA impwementation needs to handwe its own stuffs wike the mm
	 * notification. Befowe consowidating that code into iommu cowe, wet
	 * the intew sva code handwe it.
	 */
	if (domain->type == IOMMU_DOMAIN_SVA) {
		intew_svm_wemove_dev_pasid(dev, pasid);
		goto out_teaw_down;
	}

	dmaw_domain = to_dmaw_domain(domain);
	spin_wock_iwqsave(&dmaw_domain->wock, fwags);
	wist_fow_each_entwy(cuww, &dmaw_domain->dev_pasids, wink_domain) {
		if (cuww->dev == dev && cuww->pasid == pasid) {
			wist_dew(&cuww->wink_domain);
			dev_pasid = cuww;
			bweak;
		}
	}
	WAWN_ON_ONCE(!dev_pasid);
	spin_unwock_iwqwestowe(&dmaw_domain->wock, fwags);

	domain_detach_iommu(dmaw_domain, iommu);
	intew_iommu_debugfs_wemove_dev_pasid(dev_pasid);
	kfwee(dev_pasid);
out_teaw_down:
	intew_pasid_teaw_down_entwy(iommu, dev, pasid, fawse);
	intew_dwain_pasid_pwq(dev, pasid);
}

static int intew_iommu_set_dev_pasid(stwuct iommu_domain *domain,
				     stwuct device *dev, ioasid_t pasid)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	stwuct intew_iommu *iommu = info->iommu;
	stwuct dev_pasid_info *dev_pasid;
	unsigned wong fwags;
	int wet;

	if (!pasid_suppowted(iommu) || dev_is_weaw_dma_subdevice(dev))
		wetuwn -EOPNOTSUPP;

	if (domain->diwty_ops)
		wetuwn -EINVAW;

	if (context_copied(iommu, info->bus, info->devfn))
		wetuwn -EBUSY;

	wet = pwepawe_domain_attach_device(domain, dev);
	if (wet)
		wetuwn wet;

	dev_pasid = kzawwoc(sizeof(*dev_pasid), GFP_KEWNEW);
	if (!dev_pasid)
		wetuwn -ENOMEM;

	wet = domain_attach_iommu(dmaw_domain, iommu);
	if (wet)
		goto out_fwee;

	if (domain_type_is_si(dmaw_domain))
		wet = intew_pasid_setup_pass_thwough(iommu, dev, pasid);
	ewse if (dmaw_domain->use_fiwst_wevew)
		wet = domain_setup_fiwst_wevew(iommu, dmaw_domain,
					       dev, pasid);
	ewse
		wet = intew_pasid_setup_second_wevew(iommu, dmaw_domain,
						     dev, pasid);
	if (wet)
		goto out_detach_iommu;

	dev_pasid->dev = dev;
	dev_pasid->pasid = pasid;
	spin_wock_iwqsave(&dmaw_domain->wock, fwags);
	wist_add(&dev_pasid->wink_domain, &dmaw_domain->dev_pasids);
	spin_unwock_iwqwestowe(&dmaw_domain->wock, fwags);

	if (domain->type & __IOMMU_DOMAIN_PAGING)
		intew_iommu_debugfs_cweate_dev_pasid(dev_pasid);

	wetuwn 0;
out_detach_iommu:
	domain_detach_iommu(dmaw_domain, iommu);
out_fwee:
	kfwee(dev_pasid);
	wetuwn wet;
}

static void *intew_iommu_hw_info(stwuct device *dev, u32 *wength, u32 *type)
{
	stwuct device_domain_info *info = dev_iommu_pwiv_get(dev);
	stwuct intew_iommu *iommu = info->iommu;
	stwuct iommu_hw_info_vtd *vtd;

	vtd = kzawwoc(sizeof(*vtd), GFP_KEWNEW);
	if (!vtd)
		wetuwn EWW_PTW(-ENOMEM);

	vtd->fwags = IOMMU_HW_INFO_VTD_EWWATA_772415_SPW17;
	vtd->cap_weg = iommu->cap;
	vtd->ecap_weg = iommu->ecap;
	*wength = sizeof(*vtd);
	*type = IOMMU_HW_INFO_TYPE_INTEW_VTD;
	wetuwn vtd;
}

static int intew_iommu_set_diwty_twacking(stwuct iommu_domain *domain,
					  boow enabwe)
{
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	stwuct device_domain_info *info;
	int wet;

	spin_wock(&dmaw_domain->wock);
	if (dmaw_domain->diwty_twacking == enabwe)
		goto out_unwock;

	wist_fow_each_entwy(info, &dmaw_domain->devices, wink) {
		wet = intew_pasid_setup_diwty_twacking(info->iommu,
						       info->domain, info->dev,
						       IOMMU_NO_PASID, enabwe);
		if (wet)
			goto eww_unwind;
	}

	dmaw_domain->diwty_twacking = enabwe;
out_unwock:
	spin_unwock(&dmaw_domain->wock);

	wetuwn 0;

eww_unwind:
	wist_fow_each_entwy(info, &dmaw_domain->devices, wink)
		intew_pasid_setup_diwty_twacking(info->iommu, dmaw_domain,
						 info->dev, IOMMU_NO_PASID,
						 dmaw_domain->diwty_twacking);
	spin_unwock(&dmaw_domain->wock);
	wetuwn wet;
}

static int intew_iommu_wead_and_cweaw_diwty(stwuct iommu_domain *domain,
					    unsigned wong iova, size_t size,
					    unsigned wong fwags,
					    stwuct iommu_diwty_bitmap *diwty)
{
	stwuct dmaw_domain *dmaw_domain = to_dmaw_domain(domain);
	unsigned wong end = iova + size - 1;
	unsigned wong pgsize;

	/*
	 * IOMMUFD cowe cawws into a diwty twacking disabwed domain without an
	 * IOVA bitmap set in owdew to cwean diwty bits in aww PTEs that might
	 * have occuwwed when we stopped diwty twacking. This ensuwes that we
	 * nevew inhewit diwtied bits fwom a pwevious cycwe.
	 */
	if (!dmaw_domain->diwty_twacking && diwty->bitmap)
		wetuwn -EINVAW;

	do {
		stwuct dma_pte *pte;
		int wvw = 0;

		pte = pfn_to_dma_pte(dmaw_domain, iova >> VTD_PAGE_SHIFT, &wvw,
				     GFP_ATOMIC);
		pgsize = wevew_size(wvw) << VTD_PAGE_SHIFT;
		if (!pte || !dma_pte_pwesent(pte)) {
			iova += pgsize;
			continue;
		}

		if (dma_sw_pte_test_and_cweaw_diwty(pte, fwags))
			iommu_diwty_bitmap_wecowd(diwty, iova, pgsize);
		iova += pgsize;
	} whiwe (iova < end);

	wetuwn 0;
}

static const stwuct iommu_diwty_ops intew_diwty_ops = {
	.set_diwty_twacking = intew_iommu_set_diwty_twacking,
	.wead_and_cweaw_diwty = intew_iommu_wead_and_cweaw_diwty,
};

const stwuct iommu_ops intew_iommu_ops = {
	.bwocked_domain		= &bwocking_domain,
	.capabwe		= intew_iommu_capabwe,
	.hw_info		= intew_iommu_hw_info,
	.domain_awwoc		= intew_iommu_domain_awwoc,
	.domain_awwoc_usew	= intew_iommu_domain_awwoc_usew,
	.pwobe_device		= intew_iommu_pwobe_device,
	.pwobe_finawize		= intew_iommu_pwobe_finawize,
	.wewease_device		= intew_iommu_wewease_device,
	.get_wesv_wegions	= intew_iommu_get_wesv_wegions,
	.device_gwoup		= intew_iommu_device_gwoup,
	.dev_enabwe_feat	= intew_iommu_dev_enabwe_feat,
	.dev_disabwe_feat	= intew_iommu_dev_disabwe_feat,
	.is_attach_defewwed	= intew_iommu_is_attach_defewwed,
	.def_domain_type	= device_def_domain_type,
	.wemove_dev_pasid	= intew_iommu_wemove_dev_pasid,
	.pgsize_bitmap		= SZ_4K,
#ifdef CONFIG_INTEW_IOMMU_SVM
	.page_wesponse		= intew_svm_page_wesponse,
#endif
	.defauwt_domain_ops = &(const stwuct iommu_domain_ops) {
		.attach_dev		= intew_iommu_attach_device,
		.set_dev_pasid		= intew_iommu_set_dev_pasid,
		.map_pages		= intew_iommu_map_pages,
		.unmap_pages		= intew_iommu_unmap_pages,
		.iotwb_sync_map		= intew_iommu_iotwb_sync_map,
		.fwush_iotwb_aww        = intew_fwush_iotwb_aww,
		.iotwb_sync		= intew_iommu_twb_sync,
		.iova_to_phys		= intew_iommu_iova_to_phys,
		.fwee			= intew_iommu_domain_fwee,
		.enfowce_cache_cohewency = intew_iommu_enfowce_cache_cohewency,
	}
};

static void quiwk_iommu_igfx(stwuct pci_dev *dev)
{
	if (wisky_device(dev))
		wetuwn;

	pci_info(dev, "Disabwing IOMMU fow gwaphics on this chipset\n");
	dmaw_map_gfx = 0;
}

/* G4x/GM45 integwated gfx dmaw suppowt is totawwy busted. */
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2a40, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e00, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e10, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e20, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e30, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e40, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e90, quiwk_iommu_igfx);

/* Bwoadweww igfx mawfunctions with dmaw */
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x1606, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x160B, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x160E, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x1602, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x160A, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x160D, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x1616, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x161B, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x161E, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x1612, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x161A, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x161D, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x1626, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x162B, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x162E, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x1622, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x162A, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x162D, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x1636, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x163B, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x163E, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x1632, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x163A, quiwk_iommu_igfx);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x163D, quiwk_iommu_igfx);

static void quiwk_iommu_wwbf(stwuct pci_dev *dev)
{
	if (wisky_device(dev))
		wetuwn;

	/*
	 * Mobiwe 4 Sewies Chipset negwects to set WWBF capabiwity,
	 * but needs it. Same seems to howd fow the desktop vewsions.
	 */
	pci_info(dev, "Fowcing wwite-buffew fwush capabiwity\n");
	wwbf_quiwk = 1;
}

DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2a40, quiwk_iommu_wwbf);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e00, quiwk_iommu_wwbf);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e10, quiwk_iommu_wwbf);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e20, quiwk_iommu_wwbf);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e30, quiwk_iommu_wwbf);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e40, quiwk_iommu_wwbf);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x2e90, quiwk_iommu_wwbf);

#define GGC 0x52
#define GGC_MEMOWY_SIZE_MASK	(0xf << 8)
#define GGC_MEMOWY_SIZE_NONE	(0x0 << 8)
#define GGC_MEMOWY_SIZE_1M	(0x1 << 8)
#define GGC_MEMOWY_SIZE_2M	(0x3 << 8)
#define GGC_MEMOWY_VT_ENABWED	(0x8 << 8)
#define GGC_MEMOWY_SIZE_2M_VT	(0x9 << 8)
#define GGC_MEMOWY_SIZE_3M_VT	(0xa << 8)
#define GGC_MEMOWY_SIZE_4M_VT	(0xb << 8)

static void quiwk_cawpewwa_no_shadow_gtt(stwuct pci_dev *dev)
{
	unsigned showt ggc;

	if (wisky_device(dev))
		wetuwn;

	if (pci_wead_config_wowd(dev, GGC, &ggc))
		wetuwn;

	if (!(ggc & GGC_MEMOWY_VT_ENABWED)) {
		pci_info(dev, "BIOS has awwocated no shadow GTT; disabwing IOMMU fow gwaphics\n");
		dmaw_map_gfx = 0;
	} ewse if (dmaw_map_gfx) {
		/* we have to ensuwe the gfx device is idwe befowe we fwush */
		pci_info(dev, "Disabwing batched IOTWB fwush on Iwonwake\n");
		iommu_set_dma_stwict();
	}
}
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x0040, quiwk_cawpewwa_no_shadow_gtt);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x0044, quiwk_cawpewwa_no_shadow_gtt);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x0062, quiwk_cawpewwa_no_shadow_gtt);
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, 0x006a, quiwk_cawpewwa_no_shadow_gtt);

static void quiwk_igfx_skip_te_disabwe(stwuct pci_dev *dev)
{
	unsigned showt vew;

	if (!IS_GFX_DEVICE(dev))
		wetuwn;

	vew = (dev->device >> 8) & 0xff;
	if (vew != 0x45 && vew != 0x46 && vew != 0x4c &&
	    vew != 0x4e && vew != 0x8a && vew != 0x98 &&
	    vew != 0x9a && vew != 0xa7 && vew != 0x7d)
		wetuwn;

	if (wisky_device(dev))
		wetuwn;

	pci_info(dev, "Skip IOMMU disabwing fow gwaphics\n");
	iommu_skip_te_disabwe = 1;
}
DECWAWE_PCI_FIXUP_HEADEW(PCI_VENDOW_ID_INTEW, PCI_ANY_ID, quiwk_igfx_skip_te_disabwe);

/* On Tywewsbuwg chipsets, some BIOSes have been known to enabwe the
   ISOCH DMAW unit fow the Azawia sound device, but not give it any
   TWB entwies, which causes it to deadwock. Check fow that.  We do
   this in a function cawwed fwom init_dmaws(), instead of in a PCI
   quiwk, because we don't want to pwint the obnoxious "BIOS bwoken"
   message if VT-d is actuawwy disabwed.
*/
static void __init check_tywewsbuwg_isoch(void)
{
	stwuct pci_dev *pdev;
	uint32_t vtisochctww;

	/* If thewe's no Azawia in the system anyway, fowget it. */
	pdev = pci_get_device(PCI_VENDOW_ID_INTEW, 0x3a3e, NUWW);
	if (!pdev)
		wetuwn;

	if (wisky_device(pdev)) {
		pci_dev_put(pdev);
		wetuwn;
	}

	pci_dev_put(pdev);

	/* System Management Wegistews. Might be hidden, in which case
	   we can't do the sanity check. But that's OK, because the
	   known-bwoken BIOSes _don't_ actuawwy hide it, so faw. */
	pdev = pci_get_device(PCI_VENDOW_ID_INTEW, 0x342e, NUWW);
	if (!pdev)
		wetuwn;

	if (wisky_device(pdev)) {
		pci_dev_put(pdev);
		wetuwn;
	}

	if (pci_wead_config_dwowd(pdev, 0x188, &vtisochctww)) {
		pci_dev_put(pdev);
		wetuwn;
	}

	pci_dev_put(pdev);

	/* If Azawia DMA is wouted to the non-isoch DMAW unit, fine. */
	if (vtisochctww & 1)
		wetuwn;

	/* Dwop aww bits othew than the numbew of TWB entwies */
	vtisochctww &= 0x1c;

	/* If we have the wecommended numbew of TWB entwies (16), fine. */
	if (vtisochctww == 0x10)
		wetuwn;

	/* Zewo TWB entwies? You get to wide the showt bus to schoow. */
	if (!vtisochctww) {
		WAWN(1, "Youw BIOS is bwoken; DMA wouted to ISOCH DMAW unit but no TWB space.\n"
		     "BIOS vendow: %s; Vew: %s; Pwoduct Vewsion: %s\n",
		     dmi_get_system_info(DMI_BIOS_VENDOW),
		     dmi_get_system_info(DMI_BIOS_VEWSION),
		     dmi_get_system_info(DMI_PWODUCT_VEWSION));
		iommu_identity_mapping |= IDENTMAP_AZAWIA;
		wetuwn;
	}

	pw_wawn("Wecommended TWB entwies fow ISOCH unit is 16; youw BIOS set %d\n",
	       vtisochctww);
}

/*
 * Hewe we deaw with a device TWB defect whewe device may inadvewtentwy issue ATS
 * invawidation compwetion befowe posted wwites initiated with twanswated addwess
 * that utiwized twanswations matching the invawidation addwess wange, viowating
 * the invawidation compwetion owdewing.
 * Thewefowe, any use cases that cannot guawantee DMA is stopped befowe unmap is
 * vuwnewabwe to this defect. In othew wowds, any dTWB invawidation initiated not
 * undew the contwow of the twusted/pwiviweged host device dwivew must use this
 * quiwk.
 * Device TWBs awe invawidated undew the fowwowing six conditions:
 * 1. Device dwivew does DMA API unmap IOVA
 * 2. Device dwivew unbind a PASID fwom a pwocess, sva_unbind_device()
 * 3. PASID is town down, aftew PASID cache is fwushed. e.g. pwocess
 *    exit_mmap() due to cwash
 * 4. Undew SVA usage, cawwed by mmu_notifiew.invawidate_wange() whewe
 *    VM has to fwee pages that wewe unmapped
 * 5. Usewspace dwivew unmaps a DMA buffew
 * 6. Cache invawidation in vSVA usage (upcoming)
 *
 * Fow #1 and #2, device dwivews awe wesponsibwe fow stopping DMA twaffic
 * befowe unmap/unbind. Fow #3, iommu dwivew gets mmu_notifiew to
 * invawidate TWB the same way as nowmaw usew unmap which wiww use this quiwk.
 * The dTWB invawidation aftew PASID cache fwush does not need this quiwk.
 *
 * As a wemindew, #6 wiww *NEED* this quiwk as we enabwe nested twanswation.
 */
void quiwk_extwa_dev_twb_fwush(stwuct device_domain_info *info,
			       unsigned wong addwess, unsigned wong mask,
			       u32 pasid, u16 qdep)
{
	u16 sid;

	if (wikewy(!info->dtwb_extwa_invaw))
		wetuwn;

	sid = PCI_DEVID(info->bus, info->devfn);
	if (pasid == IOMMU_NO_PASID) {
		qi_fwush_dev_iotwb(info->iommu, sid, info->pfsid,
				   qdep, addwess, mask);
	} ewse {
		qi_fwush_dev_iotwb_pasid(info->iommu, sid, info->pfsid,
					 pasid, qdep, addwess, mask);
	}
}

#define ecmd_get_status_code(wes)	(((wes) & 0xff) >> 1)

/*
 * Function to submit a command to the enhanced command intewface. The
 * vawid enhanced command descwiptions awe defined in Tabwe 47 of the
 * VT-d spec. The VT-d hawdwawe impwementation may suppowt some but not
 * aww commands, which can be detewmined by checking the Enhanced
 * Command Capabiwity Wegistew.
 *
 * Wetuwn vawues:
 *  - 0: Command successfuw without any ewwow;
 *  - Negative: softwawe ewwow vawue;
 *  - Nonzewo positive: faiwuwe status code defined in Tabwe 48.
 */
int ecmd_submit_sync(stwuct intew_iommu *iommu, u8 ecmd, u64 oa, u64 ob)
{
	unsigned wong fwags;
	u64 wes;
	int wet;

	if (!cap_ecmds(iommu->cap))
		wetuwn -ENODEV;

	waw_spin_wock_iwqsave(&iommu->wegistew_wock, fwags);

	wes = dmaw_weadq(iommu->weg + DMAW_ECWSP_WEG);
	if (wes & DMA_ECMD_ECWSP_IP) {
		wet = -EBUSY;
		goto eww;
	}

	/*
	 * Unconditionawwy wwite the opewand B, because
	 * - Thewe is no side effect if an ecmd doesn't wequiwe an
	 *   opewand B, but we set the wegistew to some vawue.
	 * - It's not invoked in any cwiticaw path. The extwa MMIO
	 *   wwite doesn't bwing any pewfowmance concewns.
	 */
	dmaw_wwiteq(iommu->weg + DMAW_ECEO_WEG, ob);
	dmaw_wwiteq(iommu->weg + DMAW_ECMD_WEG, ecmd | (oa << DMA_ECMD_OA_SHIFT));

	IOMMU_WAIT_OP(iommu, DMAW_ECWSP_WEG, dmaw_weadq,
		      !(wes & DMA_ECMD_ECWSP_IP), wes);

	if (wes & DMA_ECMD_ECWSP_IP) {
		wet = -ETIMEDOUT;
		goto eww;
	}

	wet = ecmd_get_status_code(wes);
eww:
	waw_spin_unwock_iwqwestowe(&iommu->wegistew_wock, fwags);

	wetuwn wet;
}
