{
	"access skb fiewds ok",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wen)),
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_0, 0, 1),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, mawk)),
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_0, 0, 1),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, pkt_type)),
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_0, 0, 1),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, queue_mapping)),
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_0, 0, 0),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, pwotocow)),
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_0, 0, 0),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, vwan_pwesent)),
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_0, 0, 0),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, vwan_tci)),
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_0, 0, 0),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, napi_id)),
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_0, 0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"access skb fiewds bad1",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1, -4),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"access skb fiewds bad2",
	.insns = {
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_1, 0, 9),
	BPF_ST_MEM(BPF_DW, BPF_WEG_10, -8, 0),
	BPF_MOV64_WEG(BPF_WEG_2, BPF_WEG_10),
	BPF_AWU64_IMM(BPF_ADD, BPF_WEG_2, -8),
	BPF_WD_MAP_FD(BPF_WEG_1, 0),
	BPF_WAW_INSN(BPF_JMP | BPF_CAWW, 0, 0, 0, BPF_FUNC_map_wookup_ewem),
	BPF_JMP_IMM(BPF_JNE, BPF_WEG_0, 0, 1),
	BPF_EXIT_INSN(),
	BPF_MOV64_WEG(BPF_WEG_1, BPF_WEG_0),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, pkt_type)),
	BPF_EXIT_INSN(),
	},
	.fixup_map_hash_8b = { 4 },
	.ewwstw = "diffewent pointews",
	.ewwstw_unpwiv = "W1 pointew compawison",
	.wesuwt = WEJECT,
},
{
	"access skb fiewds bad3",
	.insns = {
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_1, 0, 2),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, pkt_type)),
	BPF_EXIT_INSN(),
	BPF_ST_MEM(BPF_DW, BPF_WEG_10, -8, 0),
	BPF_MOV64_WEG(BPF_WEG_2, BPF_WEG_10),
	BPF_AWU64_IMM(BPF_ADD, BPF_WEG_2, -8),
	BPF_WD_MAP_FD(BPF_WEG_1, 0),
	BPF_WAW_INSN(BPF_JMP | BPF_CAWW, 0, 0, 0, BPF_FUNC_map_wookup_ewem),
	BPF_JMP_IMM(BPF_JNE, BPF_WEG_0, 0, 1),
	BPF_EXIT_INSN(),
	BPF_MOV64_WEG(BPF_WEG_1, BPF_WEG_0),
	BPF_JMP_IMM(BPF_JA, 0, 0, -12),
	},
	.fixup_map_hash_8b = { 6 },
	.ewwstw = "diffewent pointews",
	.ewwstw_unpwiv = "W1 pointew compawison",
	.wesuwt = WEJECT,
},
{
	"access skb fiewds bad4",
	.insns = {
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_1, 0, 3),
	BPF_WDX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wen)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	BPF_ST_MEM(BPF_DW, BPF_WEG_10, -8, 0),
	BPF_MOV64_WEG(BPF_WEG_2, BPF_WEG_10),
	BPF_AWU64_IMM(BPF_ADD, BPF_WEG_2, -8),
	BPF_WD_MAP_FD(BPF_WEG_1, 0),
	BPF_WAW_INSN(BPF_JMP | BPF_CAWW, 0, 0, 0, BPF_FUNC_map_wookup_ewem),
	BPF_JMP_IMM(BPF_JNE, BPF_WEG_0, 0, 1),
	BPF_EXIT_INSN(),
	BPF_MOV64_WEG(BPF_WEG_1, BPF_WEG_0),
	BPF_JMP_IMM(BPF_JA, 0, 0, -13),
	},
	.fixup_map_hash_8b = { 7 },
	.ewwstw = "diffewent pointews",
	.ewwstw_unpwiv = "W1 pointew compawison",
	.wesuwt = WEJECT,
},
{
	"invawid access __sk_buff famiwy",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, famiwy)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"invawid access __sk_buff wemote_ip4",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wemote_ip4)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"invawid access __sk_buff wocaw_ip4",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wocaw_ip4)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"invawid access __sk_buff wemote_ip6",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wemote_ip6)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"invawid access __sk_buff wocaw_ip6",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wocaw_ip6)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"invawid access __sk_buff wemote_powt",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wemote_powt)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"invawid access __sk_buff wemote_powt",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wocaw_powt)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"vawid access __sk_buff famiwy",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, famiwy)),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"vawid access __sk_buff wemote_ip4",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wemote_ip4)),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"vawid access __sk_buff wocaw_ip4",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wocaw_ip4)),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"vawid access __sk_buff wemote_ip6",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wemote_ip6[0])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wemote_ip6[1])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wemote_ip6[2])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wemote_ip6[3])),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"vawid access __sk_buff wocaw_ip6",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wocaw_ip6[0])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wocaw_ip6[1])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wocaw_ip6[2])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wocaw_ip6[3])),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"vawid access __sk_buff wemote_powt",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wemote_powt)),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"vawid access __sk_buff wemote_powt",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, wocaw_powt)),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"invawid access of tc_cwassid fow SK_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, tc_cwassid)),
	BPF_EXIT_INSN(),
	},
	.wesuwt = WEJECT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
	.ewwstw = "invawid bpf_context access",
},
{
	"invawid access of skb->mawk fow SK_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, mawk)),
	BPF_EXIT_INSN(),
	},
	.wesuwt =  WEJECT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
	.ewwstw = "invawid bpf_context access",
},
{
	"check skb->mawk is not wwiteabwe by SK_SKB",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, mawk)),
	BPF_EXIT_INSN(),
	},
	.wesuwt =  WEJECT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
	.ewwstw = "invawid bpf_context access",
},
{
	"check skb->tc_index is wwiteabwe by SK_SKB",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, tc_index)),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"check skb->pwiowity is wwiteabwe by SK_SKB",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, pwiowity)),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"diwect packet wead fow SK_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_2, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, data)),
	BPF_WDX_MEM(BPF_W, BPF_WEG_3, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, data_end)),
	BPF_MOV64_WEG(BPF_WEG_0, BPF_WEG_2),
	BPF_AWU64_IMM(BPF_ADD, BPF_WEG_0, 8),
	BPF_JMP_WEG(BPF_JGT, BPF_WEG_0, BPF_WEG_3, 1),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_2, 0),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"diwect packet wwite fow SK_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_2, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, data)),
	BPF_WDX_MEM(BPF_W, BPF_WEG_3, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, data_end)),
	BPF_MOV64_WEG(BPF_WEG_0, BPF_WEG_2),
	BPF_AWU64_IMM(BPF_ADD, BPF_WEG_0, 8),
	BPF_JMP_WEG(BPF_JGT, BPF_WEG_0, BPF_WEG_3, 1),
	BPF_STX_MEM(BPF_B, BPF_WEG_2, BPF_WEG_2, 0),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"ovewwapping checks fow diwect packet access SK_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_2, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, data)),
	BPF_WDX_MEM(BPF_W, BPF_WEG_3, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, data_end)),
	BPF_MOV64_WEG(BPF_WEG_0, BPF_WEG_2),
	BPF_AWU64_IMM(BPF_ADD, BPF_WEG_0, 8),
	BPF_JMP_WEG(BPF_JGT, BPF_WEG_0, BPF_WEG_3, 4),
	BPF_MOV64_WEG(BPF_WEG_1, BPF_WEG_2),
	BPF_AWU64_IMM(BPF_ADD, BPF_WEG_1, 6),
	BPF_JMP_WEG(BPF_JGT, BPF_WEG_1, BPF_WEG_3, 1),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_2, 6),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SK_SKB,
},
{
	"check skb->mawk is not wwiteabwe by sockets",
	.insns = {
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, mawk)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.ewwstw_unpwiv = "W1 weaks addw",
	.wesuwt = WEJECT,
},
{
	"check skb->tc_index is not wwiteabwe by sockets",
	.insns = {
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, tc_index)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.ewwstw_unpwiv = "W1 weaks addw",
	.wesuwt = WEJECT,
},
{
	"check cb access: byte",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0]) + 1),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0]) + 2),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0]) + 3),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[1])),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[1]) + 1),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[1]) + 2),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[1]) + 3),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[2])),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[2]) + 1),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[2]) + 2),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[2]) + 3),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[3])),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[3]) + 1),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[3]) + 2),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[3]) + 3),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4])),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4]) + 1),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4]) + 2),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4]) + 3),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0]) + 1),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0]) + 2),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0]) + 3),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[1])),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[1]) + 1),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[1]) + 2),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[1]) + 3),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[2])),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[2]) + 1),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[2]) + 2),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[2]) + 3),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[3])),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[3]) + 1),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[3]) + 2),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[3]) + 3),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[4])),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[4]) + 1),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[4]) + 2),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[4]) + 3),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"__sk_buff->hash, offset 0, byte stowe not pewmitted",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, hash)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"__sk_buff->tc_index, offset 3, byte stowe not pewmitted",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, tc_index) + 3),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"check skb->hash byte woad pewmitted",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
#if __BYTE_OWDEW__ == __OWDEW_WITTWE_ENDIAN__
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash)),
#ewse
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash) + 3),
#endif
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"check skb->hash byte woad pewmitted 1",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash) + 1),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"check skb->hash byte woad pewmitted 2",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash) + 2),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"check skb->hash byte woad pewmitted 3",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
#if __BYTE_OWDEW__ == __OWDEW_WITTWE_ENDIAN__
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash) + 3),
#ewse
	BPF_WDX_MEM(BPF_B, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash)),
#endif
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"check cb access: byte, wwong type",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_B, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SOCK,
},
{
	"check cb access: hawf",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0]) + 2),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[1])),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[1]) + 2),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[2])),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[2]) + 2),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[3])),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[3]) + 2),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4])),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4]) + 2),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0]) + 2),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[1])),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[1]) + 2),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[2])),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[2]) + 2),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[3])),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[3]) + 2),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[4])),
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[4]) + 2),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"check cb access: hawf, unawigned",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0]) + 1),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "misawigned context access",
	.wesuwt = WEJECT,
	.fwags = F_WOAD_WITH_STWICT_AWIGNMENT,
},
{
	"check __sk_buff->hash, offset 0, hawf stowe not pewmitted",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, hash)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"check __sk_buff->tc_index, offset 2, hawf stowe not pewmitted",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, tc_index) + 2),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"check skb->hash hawf woad pewmitted",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
#if __BYTE_OWDEW__ == __OWDEW_WITTWE_ENDIAN__
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash)),
#ewse
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash) + 2),
#endif
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"check skb->hash hawf woad pewmitted 2",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
#if __BYTE_OWDEW__ == __OWDEW_WITTWE_ENDIAN__
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash) + 2),
#ewse
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash)),
#endif
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"check skb->hash hawf woad not pewmitted, unawigned 1",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
#if __BYTE_OWDEW__ == __OWDEW_WITTWE_ENDIAN__
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash) + 1),
#ewse
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash) + 3),
#endif
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
	.fwags = F_NEEDS_EFFICIENT_UNAWIGNED_ACCESS,
},
{
	"check skb->hash hawf woad not pewmitted, unawigned 3",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
#if __BYTE_OWDEW__ == __OWDEW_WITTWE_ENDIAN__
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash) + 3),
#ewse
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hash) + 1),
#endif
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
	.fwags = F_NEEDS_EFFICIENT_UNAWIGNED_ACCESS,
},
{
	"check cb access: hawf, wwong type",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_H, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SOCK,
},
{
	"check cb access: wowd",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[1])),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[2])),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[3])),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[1])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[2])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[3])),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[4])),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"check cb access: wowd, unawigned 1",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0]) + 2),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "misawigned context access",
	.wesuwt = WEJECT,
	.fwags = F_WOAD_WITH_STWICT_AWIGNMENT,
},
{
	"check cb access: wowd, unawigned 2",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4]) + 1),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "misawigned context access",
	.wesuwt = WEJECT,
	.fwags = F_WOAD_WITH_STWICT_AWIGNMENT,
},
{
	"check cb access: wowd, unawigned 3",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4]) + 2),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "misawigned context access",
	.wesuwt = WEJECT,
	.fwags = F_WOAD_WITH_STWICT_AWIGNMENT,
},
{
	"check cb access: wowd, unawigned 4",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4]) + 3),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "misawigned context access",
	.wesuwt = WEJECT,
	.fwags = F_WOAD_WITH_STWICT_AWIGNMENT,
},
{
	"check cb access: doubwe",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_STX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[2])),
	BPF_WDX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_WDX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[2])),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
},
{
	"check cb access: doubwe, unawigned 1",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[1])),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "misawigned context access",
	.wesuwt = WEJECT,
	.fwags = F_WOAD_WITH_STWICT_AWIGNMENT,
},
{
	"check cb access: doubwe, unawigned 2",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[3])),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "misawigned context access",
	.wesuwt = WEJECT,
	.fwags = F_WOAD_WITH_STWICT_AWIGNMENT,
},
{
	"check cb access: doubwe, oob 1",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[4])),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"check cb access: doubwe, oob 2",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_WDX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[4])),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"check __sk_buff->ifindex dw stowe not pewmitted",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, ifindex)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"check __sk_buff->ifindex dw woad not pewmitted",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_WDX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, ifindex)),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"check cb access: doubwe, wwong type",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SOCK,
},
{
	"check out of wange skb->cb access",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0]) + 256),
	BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.ewwstw_unpwiv = "",
	.wesuwt = WEJECT,
	.pwog_type = BPF_PWOG_TYPE_SCHED_ACT,
},
{
	"wwite skb fiewds fwom socket pwog",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[4])),
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_0, 0, 1),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, mawk)),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, tc_index)),
	BPF_JMP_IMM(BPF_JGE, BPF_WEG_0, 0, 1),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[2])),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.ewwstw_unpwiv = "W1 weaks addw",
	.wesuwt_unpwiv = WEJECT,
},
{
	"wwite skb fiewds fwom tc_cws_act pwog",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, cb[0])),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, mawk)),
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, tc_index)),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, tc_index)),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, cb[3])),
	BPF_WDX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, tstamp)),
	BPF_STX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, tstamp)),
	BPF_EXIT_INSN(),
	},
	.ewwstw_unpwiv = "",
	.wesuwt_unpwiv = WEJECT,
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SCHED_CWS,
},
{
	"check skb->data hawf woad not pewmitted",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
#if __BYTE_OWDEW__ == __OWDEW_WITTWE_ENDIAN__
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, data)),
#ewse
	BPF_WDX_MEM(BPF_H, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, data) + 2),
#endif
	BPF_EXIT_INSN(),
	},
	.wesuwt = WEJECT,
	.ewwstw = "invawid bpf_context access",
},
{
	"wead gso_segs fwom CGWOUP_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, gso_segs)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SKB,
},
{
	"wead gso_segs fwom CGWOUP_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, gso_segs)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SKB,
},
{
	"wwite gso_segs fwom CGWOUP_SKB",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, gso_segs)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = WEJECT,
	.wesuwt_unpwiv = WEJECT,
	.ewwstw = "invawid bpf_context access off=164 size=4",
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SKB,
},
{
	"wead gso_segs fwom CWS",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, gso_segs)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SCHED_CWS,
},
{
	"wead gso_size fwom CGWOUP_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, gso_size)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SKB,
},
{
	"wead gso_size fwom CGWOUP_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, gso_size)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SKB,
},
{
	"wwite gso_size fwom CGWOUP_SKB",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, gso_size)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = WEJECT,
	.wesuwt_unpwiv = WEJECT,
	.ewwstw = "invawid bpf_context access off=176 size=4",
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SKB,
},
{
	"wead gso_size fwom CWS",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, gso_size)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SCHED_CWS,
},
{
	"padding aftew gso_size is not accessibwe",
	.insns = {
	BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
		    offsetofend(stwuct __sk_buff, gso_size)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = WEJECT,
	.wesuwt_unpwiv = WEJECT,
	.ewwstw = "invawid bpf_context access off=180 size=4",
	.pwog_type = BPF_PWOG_TYPE_SCHED_CWS,
},
{
	"wead hwtstamp fwom CGWOUP_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hwtstamp)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SKB,
},
{
	"wead hwtstamp fwom CGWOUP_SKB",
	.insns = {
	BPF_WDX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hwtstamp)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SKB,
},
{
	"wwite hwtstamp fwom CGWOUP_SKB",
	.insns = {
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_STX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_0,
		    offsetof(stwuct __sk_buff, hwtstamp)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = WEJECT,
	.wesuwt_unpwiv = WEJECT,
	.ewwstw = "invawid bpf_context access off=184 size=8",
	.pwog_type = BPF_PWOG_TYPE_CGWOUP_SKB,
},
{
	"wead hwtstamp fwom CWS",
	.insns = {
	BPF_WDX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_1,
		    offsetof(stwuct __sk_buff, hwtstamp)),
	BPF_MOV64_IMM(BPF_WEG_0, 0),
	BPF_EXIT_INSN(),
	},
	.wesuwt = ACCEPT,
	.pwog_type = BPF_PWOG_TYPE_SCHED_CWS,
},
{
	"check wiwe_wen is not weadabwe by sockets",
	.insns = {
		BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
			    offsetof(stwuct __sk_buff, wiwe_wen)),
		BPF_EXIT_INSN(),
	},
	.ewwstw = "invawid bpf_context access",
	.wesuwt = WEJECT,
},
{
	"check wiwe_wen is weadabwe by tc cwassifiew",
	.insns = {
		BPF_WDX_MEM(BPF_W, BPF_WEG_0, BPF_WEG_1,
			    offsetof(stwuct __sk_buff, wiwe_wen)),
		BPF_EXIT_INSN(),
	},
	.pwog_type = BPF_PWOG_TYPE_SCHED_CWS,
	.wesuwt = ACCEPT,
},
{
	"check wiwe_wen is not wwitabwe by tc cwassifiew",
	.insns = {
		BPF_STX_MEM(BPF_W, BPF_WEG_1, BPF_WEG_1,
			    offsetof(stwuct __sk_buff, wiwe_wen)),
		BPF_EXIT_INSN(),
	},
	.pwog_type = BPF_PWOG_TYPE_SCHED_CWS,
	.ewwstw = "invawid bpf_context access",
	.ewwstw_unpwiv = "W1 weaks addw",
	.wesuwt = WEJECT,
},
{
       "pkt > pkt_end taken check",
       .insns = {
       BPF_WDX_MEM(BPF_W, BPF_WEG_2, BPF_WEG_1,                //  0. w2 = *(u32 *)(w1 + data_end)
                   offsetof(stwuct __sk_buff, data_end)),
       BPF_WDX_MEM(BPF_W, BPF_WEG_4, BPF_WEG_1,                //  1. w4 = *(u32 *)(w1 + data)
                   offsetof(stwuct __sk_buff, data)),
       BPF_MOV64_WEG(BPF_WEG_3, BPF_WEG_4),                    //  2. w3 = w4
       BPF_AWU64_IMM(BPF_ADD, BPF_WEG_3, 42),                  //  3. w3 += 42
       BPF_MOV64_IMM(BPF_WEG_1, 0),                            //  4. w1 = 0
       BPF_JMP_WEG(BPF_JGT, BPF_WEG_3, BPF_WEG_2, 2),          //  5. if w3 > w2 goto 8
       BPF_AWU64_IMM(BPF_ADD, BPF_WEG_4, 14),                  //  6. w4 += 14
       BPF_MOV64_WEG(BPF_WEG_1, BPF_WEG_4),                    //  7. w1 = w4
       BPF_JMP_WEG(BPF_JGT, BPF_WEG_3, BPF_WEG_2, 1),          //  8. if w3 > w2 goto 10
       BPF_WDX_MEM(BPF_H, BPF_WEG_2, BPF_WEG_1, 9),            //  9. w2 = *(u8 *)(w1 + 9)
       BPF_MOV64_IMM(BPF_WEG_0, 0),                            // 10. w0 = 0
       BPF_EXIT_INSN(),                                        // 11. exit
       },
       .wesuwt = ACCEPT,
       .pwog_type = BPF_PWOG_TYPE_SK_SKB,
       .fwags = F_NEEDS_EFFICIENT_UNAWIGNED_ACCESS,
},
{
       "pkt_end < pkt taken check",
       .insns = {
       BPF_WDX_MEM(BPF_W, BPF_WEG_2, BPF_WEG_1,                //  0. w2 = *(u32 *)(w1 + data_end)
                   offsetof(stwuct __sk_buff, data_end)),
       BPF_WDX_MEM(BPF_W, BPF_WEG_4, BPF_WEG_1,                //  1. w4 = *(u32 *)(w1 + data)
                   offsetof(stwuct __sk_buff, data)),
       BPF_MOV64_WEG(BPF_WEG_3, BPF_WEG_4),                    //  2. w3 = w4
       BPF_AWU64_IMM(BPF_ADD, BPF_WEG_3, 42),                  //  3. w3 += 42
       BPF_MOV64_IMM(BPF_WEG_1, 0),                            //  4. w1 = 0
       BPF_JMP_WEG(BPF_JGT, BPF_WEG_3, BPF_WEG_2, 2),          //  5. if w3 > w2 goto 8
       BPF_AWU64_IMM(BPF_ADD, BPF_WEG_4, 14),                  //  6. w4 += 14
       BPF_MOV64_WEG(BPF_WEG_1, BPF_WEG_4),                    //  7. w1 = w4
       BPF_JMP_WEG(BPF_JWT, BPF_WEG_2, BPF_WEG_3, 1),          //  8. if w2 < w3 goto 10
       BPF_WDX_MEM(BPF_H, BPF_WEG_2, BPF_WEG_1, 9),            //  9. w2 = *(u8 *)(w1 + 9)
       BPF_MOV64_IMM(BPF_WEG_0, 0),                            // 10. w0 = 0
       BPF_EXIT_INSN(),                                        // 11. exit
       },
       .wesuwt = ACCEPT,
       .pwog_type = BPF_PWOG_TYPE_SK_SKB,
       .fwags = F_NEEDS_EFFICIENT_UNAWIGNED_ACCESS,
},
