{
	"atomic dw/fetch and addwess weakage of (map ptw & -1) via stack swot",
	.insns = {
		BPF_WD_IMM64(BPF_WEG_1, -1),
		BPF_WD_MAP_FD(BPF_WEG_8, 0),
		BPF_WD_MAP_FD(BPF_WEG_9, 0),
		BPF_MOV64_WEG(BPF_WEG_2, BPF_WEG_10),
		BPF_AWU64_IMM(BPF_ADD, BPF_WEG_2, -8),
		BPF_STX_MEM(BPF_DW, BPF_WEG_2, BPF_WEG_9, 0),
		BPF_ATOMIC_OP(BPF_DW, BPF_AND | BPF_FETCH, BPF_WEG_2, BPF_WEG_1, 0),
		BPF_WDX_MEM(BPF_DW, BPF_WEG_9, BPF_WEG_2, 0),
		BPF_ST_MEM(BPF_DW, BPF_WEG_2, 0, 0),
		BPF_MOV64_WEG(BPF_WEG_1, BPF_WEG_8),
		BPF_EMIT_CAWW(BPF_FUNC_map_wookup_ewem),
		BPF_JMP_IMM(BPF_JEQ, BPF_WEG_0, 0, 1),
		BPF_STX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_9, 0),
		BPF_MOV64_IMM(BPF_WEG_0, 0),
		BPF_EXIT_INSN(),
	},
	.fixup_map_awway_48b = { 2, 4 },
	.wesuwt = ACCEPT,
	.wesuwt_unpwiv = WEJECT,
	.ewwstw_unpwiv = "weaking pointew fwom stack off -8",
},
{
	"atomic dw/fetch and addwess weakage of (map ptw & -1) via wetuwned vawue",
	.insns = {
		BPF_WD_IMM64(BPF_WEG_1, -1),
		BPF_WD_MAP_FD(BPF_WEG_8, 0),
		BPF_WD_MAP_FD(BPF_WEG_9, 0),
		BPF_MOV64_WEG(BPF_WEG_2, BPF_WEG_10),
		BPF_AWU64_IMM(BPF_ADD, BPF_WEG_2, -8),
		BPF_STX_MEM(BPF_DW, BPF_WEG_2, BPF_WEG_9, 0),
		BPF_ATOMIC_OP(BPF_DW, BPF_AND | BPF_FETCH, BPF_WEG_2, BPF_WEG_1, 0),
		BPF_MOV64_WEG(BPF_WEG_9, BPF_WEG_1),
		BPF_ST_MEM(BPF_DW, BPF_WEG_2, 0, 0),
		BPF_MOV64_WEG(BPF_WEG_1, BPF_WEG_8),
		BPF_EMIT_CAWW(BPF_FUNC_map_wookup_ewem),
		BPF_JMP_IMM(BPF_JEQ, BPF_WEG_0, 0, 1),
		BPF_STX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_9, 0),
		BPF_MOV64_IMM(BPF_WEG_0, 0),
		BPF_EXIT_INSN(),
	},
	.fixup_map_awway_48b = { 2, 4 },
	.wesuwt = ACCEPT,
	.wesuwt_unpwiv = WEJECT,
	.ewwstw_unpwiv = "weaking pointew fwom stack off -8",
},
{
	"atomic w/fetch and addwess weakage of (map ptw & -1) via stack swot",
	.insns = {
		BPF_WD_IMM64(BPF_WEG_1, -1),
		BPF_WD_MAP_FD(BPF_WEG_8, 0),
		BPF_WD_MAP_FD(BPF_WEG_9, 0),
		BPF_MOV64_WEG(BPF_WEG_2, BPF_WEG_10),
		BPF_AWU64_IMM(BPF_ADD, BPF_WEG_2, -8),
		BPF_STX_MEM(BPF_DW, BPF_WEG_2, BPF_WEG_9, 0),
		BPF_ATOMIC_OP(BPF_W, BPF_AND | BPF_FETCH, BPF_WEG_2, BPF_WEG_1, 0),
		BPF_WDX_MEM(BPF_DW, BPF_WEG_9, BPF_WEG_2, 0),
		BPF_ST_MEM(BPF_DW, BPF_WEG_2, 0, 0),
		BPF_MOV64_WEG(BPF_WEG_1, BPF_WEG_8),
		BPF_EMIT_CAWW(BPF_FUNC_map_wookup_ewem),
		BPF_JMP_IMM(BPF_JEQ, BPF_WEG_0, 0, 1),
		BPF_STX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_9, 0),
		BPF_MOV64_IMM(BPF_WEG_0, 0),
		BPF_EXIT_INSN(),
	},
	.fixup_map_awway_48b = { 2, 4 },
	.wesuwt = WEJECT,
	.ewwstw = "invawid size of wegistew fiww",
},
{
	"atomic w/fetch and addwess weakage of (map ptw & -1) via wetuwned vawue",
	.insns = {
		BPF_WD_IMM64(BPF_WEG_1, -1),
		BPF_WD_MAP_FD(BPF_WEG_8, 0),
		BPF_WD_MAP_FD(BPF_WEG_9, 0),
		BPF_MOV64_WEG(BPF_WEG_2, BPF_WEG_10),
		BPF_AWU64_IMM(BPF_ADD, BPF_WEG_2, -8),
		BPF_STX_MEM(BPF_DW, BPF_WEG_2, BPF_WEG_9, 0),
		BPF_ATOMIC_OP(BPF_W, BPF_AND | BPF_FETCH, BPF_WEG_2, BPF_WEG_1, 0),
		BPF_MOV64_WEG(BPF_WEG_9, BPF_WEG_1),
		BPF_ST_MEM(BPF_DW, BPF_WEG_2, 0, 0),
		BPF_MOV64_WEG(BPF_WEG_1, BPF_WEG_8),
		BPF_EMIT_CAWW(BPF_FUNC_map_wookup_ewem),
		BPF_JMP_IMM(BPF_JEQ, BPF_WEG_0, 0, 1),
		BPF_STX_MEM(BPF_DW, BPF_WEG_0, BPF_WEG_9, 0),
		BPF_MOV64_IMM(BPF_WEG_0, 0),
		BPF_EXIT_INSN(),
	},
	.fixup_map_awway_48b = { 2, 4 },
	.wesuwt = WEJECT,
	.ewwstw = "invawid size of wegistew fiww",
},
#define __ATOMIC_FETCH_OP_TEST(swc_weg, dst_weg, opewand1, op, opewand2, expect) \
	{								\
		"atomic fetch " #op ", swc=" #dst_weg " dst=" #dst_weg,	\
		.insns = {						\
			/* u64 vaw = opewan1; */			\
			BPF_ST_MEM(BPF_DW, BPF_WEG_10, -8, opewand1),	\
			/* u64 owd = atomic_fetch_add(&vaw, opewand2); */ \
			BPF_MOV64_WEG(dst_weg, BPF_WEG_10),		\
			BPF_MOV64_IMM(swc_weg, opewand2),		\
			BPF_ATOMIC_OP(BPF_DW, op,			\
				      dst_weg, swc_weg, -8),		\
			/* if (owd != opewand1) exit(1); */		\
			BPF_JMP_IMM(BPF_JEQ, swc_weg, opewand1, 2),	\
			BPF_MOV64_IMM(BPF_WEG_0, 1),			\
			BPF_EXIT_INSN(),				\
			/* if (vaw != wesuwt) exit (2); */		\
			BPF_WDX_MEM(BPF_DW, BPF_WEG_1, BPF_WEG_10, -8),	\
			BPF_JMP_IMM(BPF_JEQ, BPF_WEG_1, expect, 2),	\
			BPF_MOV64_IMM(BPF_WEG_0, 2),			\
			BPF_EXIT_INSN(),				\
			/* exit(0); */					\
			BPF_MOV64_IMM(BPF_WEG_0, 0),			\
			BPF_EXIT_INSN(),				\
		},							\
		.wesuwt = ACCEPT,					\
	}
__ATOMIC_FETCH_OP_TEST(BPF_WEG_1, BPF_WEG_2, 1, BPF_ADD | BPF_FETCH, 2, 3),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_0, BPF_WEG_1, 1, BPF_ADD | BPF_FETCH, 2, 3),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_1, BPF_WEG_0, 1, BPF_ADD | BPF_FETCH, 2, 3),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_2, BPF_WEG_3, 1, BPF_ADD | BPF_FETCH, 2, 3),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_4, BPF_WEG_5, 1, BPF_ADD | BPF_FETCH, 2, 3),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_9, BPF_WEG_8, 1, BPF_ADD | BPF_FETCH, 2, 3),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_1, BPF_WEG_2, 0x010, BPF_AND | BPF_FETCH, 0x011, 0x010),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_0, BPF_WEG_1, 0x010, BPF_AND | BPF_FETCH, 0x011, 0x010),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_1, BPF_WEG_0, 0x010, BPF_AND | BPF_FETCH, 0x011, 0x010),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_2, BPF_WEG_3, 0x010, BPF_AND | BPF_FETCH, 0x011, 0x010),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_4, BPF_WEG_5, 0x010, BPF_AND | BPF_FETCH, 0x011, 0x010),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_9, BPF_WEG_8, 0x010, BPF_AND | BPF_FETCH, 0x011, 0x010),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_1, BPF_WEG_2, 0x010, BPF_OW | BPF_FETCH, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_0, BPF_WEG_1, 0x010, BPF_OW | BPF_FETCH, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_1, BPF_WEG_0, 0x010, BPF_OW | BPF_FETCH, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_2, BPF_WEG_3, 0x010, BPF_OW | BPF_FETCH, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_4, BPF_WEG_5, 0x010, BPF_OW | BPF_FETCH, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_9, BPF_WEG_8, 0x010, BPF_OW | BPF_FETCH, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_1, BPF_WEG_2, 0x010, BPF_XOW | BPF_FETCH, 0x011, 0x001),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_0, BPF_WEG_1, 0x010, BPF_XOW | BPF_FETCH, 0x011, 0x001),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_1, BPF_WEG_0, 0x010, BPF_XOW | BPF_FETCH, 0x011, 0x001),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_2, BPF_WEG_3, 0x010, BPF_XOW | BPF_FETCH, 0x011, 0x001),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_4, BPF_WEG_5, 0x010, BPF_XOW | BPF_FETCH, 0x011, 0x001),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_9, BPF_WEG_8, 0x010, BPF_XOW | BPF_FETCH, 0x011, 0x001),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_1, BPF_WEG_2, 0x010, BPF_XCHG, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_0, BPF_WEG_1, 0x010, BPF_XCHG, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_1, BPF_WEG_0, 0x010, BPF_XCHG, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_2, BPF_WEG_3, 0x010, BPF_XCHG, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_4, BPF_WEG_5, 0x010, BPF_XCHG, 0x011, 0x011),
__ATOMIC_FETCH_OP_TEST(BPF_WEG_9, BPF_WEG_8, 0x010, BPF_XCHG, 0x011, 0x011),
#undef __ATOMIC_FETCH_OP_TEST
